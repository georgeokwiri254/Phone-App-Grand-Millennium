"""
Enhanced Gemini AI Backend for Interactive Revenue Analytics
Provides conversational AI with context awareness, insights, and dynamic suggestions
"""

import sqlite3
import pandas as pd
import google.generativeai as genai
import os
import re
import json
from typing import Tuple, Optional, Dict, Any, List
import traceback
from datetime import datetime, timedelta
import numpy as np


class EnhancedGeminiBackend:
    """Enhanced conversational AI backend with context awareness and intelligent insights"""
    
    def __init__(self, api_key: str, db_path: str = "db/revenue.db"):
        """Initialize the Enhanced Gemini backend"""
        self.api_key = api_key
        self.db_path = db_path
        self.model = None
        self.conversation_history = []
        self.context_memory = {}
        self.user_preferences = {}
        
        # Configure Gemini
        try:
            genai.configure(api_key=api_key)
            self.model = genai.GenerativeModel('gemini-2.0-flash-lite')
            self.connected = True
        except Exception as e:
            self.connected = False
            self.error_message = f"Failed to initialize Gemini: {str(e)}"
    
    def get_enhanced_database_schema(self) -> str:
        """Get comprehensive database schema with sample data and insights"""
        try:
            conn = sqlite3.connect(self.db_path)
            cursor = conn.cursor()
            
            schema_info = """ğŸ“Š GRAND MILLENNIUM HOTEL REVENUE DATABASE SCHEMA

ğŸ¨ MAIN BUSINESS TABLES:
======================

ğŸ“ˆ DAILY PERFORMANCE:
- hotel_data_combined: Complete daily metrics with 60+ advanced features
  Key columns: Date, Rooms_Sold, Revenue, ADR, RevPAR, Occupancy_Pct
  Advanced: Moving averages (7/14/30 day), lag features, scaled/normalized data
  
- occupancy_analysis: Core daily occupancy metrics
  Columns: Date, DOW, Rms, Daily_Revenue, Occ_Pct, Rm_Sold, Revenue, ADR, RevPar

ğŸ“Š HISTORICAL DATA (2022-2024):
- historical_occupancy_YYYY: Year-specific occupancy and revenue data
  Columns: Date, DOW, "Rm Sold", Revenue, ADR, RevPar, Year
  
- historical_segment_YYYY: Business segment performance by year
  Columns: Month, Segment, Business_on_the_Books_Rooms, Business_on_the_Books_Revenue, Business_on_the_Books_ADR, MergedSegment, Year
  âš ï¸ CRITICAL: Use "Business_on_the_Books_Revenue" NOT "Revenue"
  
ğŸ¯ SEGMENT ANALYSIS:
- segment_analysis: Current segment performance with forecasting
  Revenue Columns: Business_on_the_Books_Revenue, Daily_Pick_up_Revenue, Month_to_Date_Revenue
  ADR Columns: Business_on_the_Books_ADR, Daily_Pick_up_ADR, Month_to_Date_ADR
  âš ï¸ CRITICAL: NO simple "Revenue" column exists - must use specific revenue types
  
ğŸš€ RESERVATIONS & ARRIVALS:
- entered_on: Future reservations and booking patterns
  Key columns: COMPANY_CLEAN (company name), C_T_S_NAME (travel agent), AMOUNT (revenue), TOTAL, NET, ADR
  âš ï¸ CRITICAL: Use "COMPANY_CLEAN" NOT "Company", use "AMOUNT" NOT "Revenue"
  Lead time: BOOKING_LEAD_TIME, Season: SEASON
  
- arrivals: Guest arrival details and patterns
  Key columns: COMPANY_NAME, COMPANY_NAME_CLEAN, CALCULATED_ADR, AMOUNT
  Fields: Company analysis, deposit status, rate codes, seasonal flags

ğŸ¢ BLOCK BUSINESS:
- block_analysis: Group bookings and corporate blocks
  
ğŸ“ˆ FORECASTING:
- forecasts: AI-generated predictions with confidence intervals
- combined_forecast_data: Integrated forecast results

ğŸ’¡ KEY REVENUE METRICS:
- ADR: Average Daily Rate
- RevPAR: Revenue Per Available Room  
- BOB: Business on the Books (future reservations)
- STL: Same Time Last Year comparisons
- YoY: Year over Year performance

ğŸ” BUSINESS INTELLIGENCE FEATURES:
- Seasonal analysis (high/low seasons)
- Day-of-week patterns
- Lead time analysis
- Company/segment performance
- Forecasting with multiple horizons
"""
            
            # Get recent data samples for context
            cursor.execute("SELECT COUNT(*) FROM hotel_data_combined")
            total_days = cursor.fetchone()[0]
            
            cursor.execute("SELECT MIN(Date), MAX(Date) FROM hotel_data_combined")
            date_range = cursor.fetchone()
            
            schema_info += f"\nğŸ“… DATA COVERAGE: {total_days} days from {date_range[0]} to {date_range[1]}\n"
            
            conn.close()
            return schema_info
            
        except Exception as e:
            return f"Error getting enhanced schema: {str(e)}"
    
    def analyze_data_patterns(self, df: pd.DataFrame, question: str) -> Dict[str, Any]:
        """Analyze data for patterns, trends, and insights"""
        if df.empty:
            return {"insights": [], "patterns": [], "recommendations": []}
        
        insights = []
        patterns = []
        recommendations = []
        
        try:
            # Revenue analysis
            if 'Revenue' in df.columns or 'Daily_Revenue' in df.columns:
                revenue_col = 'Revenue' if 'Revenue' in df.columns else 'Daily_Revenue'
                total_revenue = df[revenue_col].sum()
                avg_revenue = df[revenue_col].mean()
                
                insights.append(f"ğŸ’° Total Revenue: AED {total_revenue:,.0f}")
                insights.append(f"ğŸ“Š Average Daily Revenue: AED {avg_revenue:,.0f}")
                
                # Trend analysis
                if len(df) > 1:
                    revenue_trend = "increasing" if df[revenue_col].iloc[-1] > df[revenue_col].iloc[0] else "decreasing"
                    patterns.append(f"ğŸ“ˆ Revenue trend is {revenue_trend}")
            
            # Occupancy analysis
            if 'Occupancy_Pct' in df.columns or 'Occ_Pct' in df.columns:
                occ_col = 'Occupancy_Pct' if 'Occupancy_Pct' in df.columns else 'Occ_Pct'
                avg_occ = df[occ_col].mean()
                max_occ = df[occ_col].max()
                min_occ = df[occ_col].min()
                
                insights.append(f"ğŸ¨ Average Occupancy: {avg_occ:.1f}%")
                
                if avg_occ > 80:
                    patterns.append("ğŸ”¥ High occupancy period - strong demand")
                    recommendations.append("Consider dynamic pricing strategies")
                elif avg_occ < 60:
                    patterns.append("ğŸ“‰ Lower occupancy - opportunity for improvement")
                    recommendations.append("Review marketing strategies and rate positioning")
            
            # ADR analysis
            if 'ADR' in df.columns:
                avg_adr = df['ADR'].mean()
                insights.append(f"ğŸ’µ Average ADR: AED {avg_adr:.0f}")
                
                if avg_adr > 200:
                    patterns.append("ğŸ’ Premium rate positioning")
                elif avg_adr < 150:
                    patterns.append("ğŸ¯ Value-focused pricing")
            
            # Day of week patterns
            if 'DOW' in df.columns:
                dow_performance = df.groupby('DOW').agg({
                    col: 'mean' for col in df.columns if col in ['Revenue', 'Daily_Revenue', 'Occupancy_Pct', 'Occ_Pct', 'ADR']
                })
                if not dow_performance.empty:
                    best_dow = dow_performance.iloc[:, 0].idxmax()
                    patterns.append(f"ğŸ“… Best performing day: {best_dow}")
            
            # Segment analysis
            if 'Segment' in df.columns:
                if 'Business_on_the_Books_Revenue' in df.columns:
                    top_segment = df.loc[df['Business_on_the_Books_Revenue'].idxmax(), 'Segment']
                    patterns.append(f"ğŸ¯ Top revenue segment: {top_segment}")
                    
                elif 'Business_on_the_Books_Rooms' in df.columns:
                    top_segment = df.loc[df['Business_on_the_Books_Rooms'].idxmax(), 'Segment']
                    patterns.append(f"ğŸ¨ Top volume segment: {top_segment}")
            
            # General recommendations
            if not recommendations:
                if 'question' in question.lower() and any(word in question.lower() for word in ['forecast', 'predict', 'future']):
                    recommendations.append("ğŸ“ˆ Consider reviewing forecasting models for better accuracy")
                elif any(word in question.lower() for word in ['segment', 'market']):
                    recommendations.append("ğŸ¯ Analyze segment mix optimization opportunities")
                elif any(word in question.lower() for word in ['revenue', 'adr', 'rate']):
                    recommendations.append("ğŸ’° Review pricing strategies and revenue optimization")
        
        except Exception as e:
            insights.append(f"âš ï¸ Analysis error: {str(e)}")
        
        return {
            "insights": insights,
            "patterns": patterns,
            "recommendations": recommendations
        }
    
    def generate_follow_up_suggestions(self, question: str, results: pd.DataFrame) -> List[str]:
        """Generate intelligent follow-up questions based on context"""
        suggestions = []
        
        try:
            question_lower = question.lower()
            
            # Revenue-focused follow-ups
            if any(word in question_lower for word in ['revenue', 'sales', 'income']):
                suggestions.extend([
                    "ğŸ’¡ What's driving the revenue trends?",
                    "ğŸ“Š How does this compare to last year?",
                    "ğŸ¯ Which segments contribute most to revenue?",
                    "ğŸ“ˆ Show me revenue by day of week patterns"
                ])
            
            # Occupancy-focused follow-ups
            elif any(word in question_lower for word in ['occupancy', 'rooms', 'sold']):
                suggestions.extend([
                    "ğŸ¨ What's the average length of stay?",
                    "ğŸ“… Show seasonal occupancy patterns",
                    "ğŸ¯ Which rate codes have highest occupancy?",
                    "ğŸ’° How does occupancy correlate with ADR?"
                ])
            
            # Segment-focused follow-ups
            elif any(word in question_lower for word in ['segment', 'market', 'business']):
                suggestions.extend([
                    "ğŸ“Š Compare segment performance year-over-year",
                    "ğŸ¯ What's the ADR by segment?",
                    "ğŸ“ˆ Show segment booking lead times",
                    "ğŸ’¼ Which segments have strongest growth?"
                ])
            
            # Time-based follow-ups
            elif any(word in question_lower for word in ['month', 'year', 'quarter', 'week']):
                suggestions.extend([
                    "ğŸ“… Compare with same period last year",
                    "ğŸ“Š Show monthly trending patterns",
                    "ğŸ” Analyze weekend vs weekday performance",
                    "ğŸ“ˆ What are the seasonal variations?"
                ])
            
            # Forecasting follow-ups
            elif any(word in question_lower for word in ['forecast', 'predict', 'future']):
                suggestions.extend([
                    "ğŸ”® Show confidence intervals for forecasts",
                    "ğŸ“Š Compare forecast accuracy over time",
                    "ğŸ¯ What factors influence forecast accuracy?",
                    "ğŸ“ˆ Generate longer-term forecasts"
                ])
            
            # General business intelligence
            else:
                suggestions.extend([
                    "ğŸ¯ Analyze top performing segments",
                    "ğŸ“Š Show revenue optimization opportunities",
                    "ğŸ“ˆ Compare current vs budget performance",
                    "ğŸ’¡ Identify booking pattern insights"
                ])
            
            # Add data-driven suggestions based on results
            if not results.empty:
                if 'Segment' in results.columns and len(results['Segment'].unique()) > 1:
                    suggestions.append("ğŸ” Deep dive into segment performance")
                
                if any(col in results.columns for col in ['ADR', 'RevPAR']):
                    suggestions.append("ğŸ’° Analyze pricing optimization opportunities")
                
                if 'Date' in results.columns and len(results) > 7:
                    suggestions.append("ğŸ“Š Show trend analysis and patterns")
        
        except Exception:
            suggestions = [
                "ğŸ“Š Show overall performance summary",
                "ğŸ¯ Analyze segment breakdown",
                "ğŸ“ˆ Display trending patterns",
                "ğŸ’¡ Generate business insights"
            ]
        
        return suggestions[:6]  # Limit to 6 suggestions
    
    def generate_enhanced_response(self, question: str, sql_query: str, results: pd.DataFrame) -> Dict[str, Any]:
        """Generate comprehensive response with insights and suggestions"""
        
        # Analyze data patterns
        analysis = self.analyze_data_patterns(results, question)
        
        # Generate follow-up suggestions
        suggestions = self.generate_follow_up_suggestions(question, results)
        
        # Create natural language summary
        summary = self.create_intelligent_summary(question, results, analysis)
        
        return {
            "sql_query": sql_query,
            "results": results,
            "summary": summary,
            "insights": analysis["insights"],
            "patterns": analysis["patterns"],
            "recommendations": analysis["recommendations"],
            "follow_up_suggestions": suggestions,
            "row_count": len(results)
        }
    
    def create_intelligent_summary(self, question: str, results: pd.DataFrame, analysis: Dict) -> str:
        """Create intelligent natural language summary of results"""
        if results.empty:
            return "ğŸ” Your query executed successfully but returned no data. This might indicate:\nâ€¢ The specified criteria don't match any records\nâ€¢ The time period might not have data\nâ€¢ Consider adjusting filters or date ranges"
        
        summary_parts = []
        
        # Question context
        summary_parts.append(f"ğŸ“‹ **Analysis Results for**: {question}")
        
        # Data overview
        if len(results) == 1:
            summary_parts.append(f"ğŸ¯ Found **1 record** matching your criteria")
        else:
            summary_parts.append(f"ğŸ“Š Found **{len(results)} records** matching your criteria")
        
        # Key insights
        if analysis["insights"]:
            summary_parts.append("ğŸ’¡ **Key Metrics**:")
            for insight in analysis["insights"][:3]:  # Top 3 insights
                summary_parts.append(f"  â€¢ {insight}")
        
        # Important patterns
        if analysis["patterns"]:
            summary_parts.append("ğŸ” **Key Patterns**:")
            for pattern in analysis["patterns"][:2]:  # Top 2 patterns
                summary_parts.append(f"  â€¢ {pattern}")
        
        # Business recommendations
        if analysis["recommendations"]:
            summary_parts.append("ğŸ’¡ **Recommendations**:")
            for rec in analysis["recommendations"][:2]:  # Top 2 recommendations
                summary_parts.append(f"  â€¢ {rec}")
        
        return "\n".join(summary_parts)
    
    def generate_contextual_sql(self, question: str) -> Tuple[bool, str, str]:
        """Generate SQL with enhanced context awareness"""
        try:
            if not self.connected:
                return False, "", "Gemini AI not connected"
            
            # Get enhanced schema
            schema = self.get_enhanced_database_schema()
            
            # Build conversation context
            context = ""
            if self.conversation_history:
                context = "\n\nğŸ“ CONVERSATION CONTEXT:\n"
                for i, msg in enumerate(self.conversation_history[-3:]):  # Last 3 messages
                    context += f"{i+1}. User: {msg.get('question', '')}\n"
                    if msg.get('successful_sql'):
                        context += f"   SQL: {msg['successful_sql'][:100]}...\n"
            
            # Create enhanced prompt
            prompt = f"""
You are an expert AI assistant for Grand Millennium Hotel's revenue analytics. You have deep knowledge of hospitality industry KPIs and hotel operations.

{schema}

{context}

CONVERSATION INTELLIGENCE:
- Remember previous queries and build upon them
- Suggest related insights and deeper analysis
- Use hospitality domain expertise
- Focus on actionable business intelligence

ADVANCED SQL GENERATION RULES:
1. ONLY generate SELECT queries (no INSERT, UPDATE, DELETE, DROP)
2. Use appropriate JOINs when connecting related data
3. Apply proper date filtering with SQLite date functions
4. Use aggregations (SUM, COUNT, AVG, MAX, MIN) for business metrics
5. Include ORDER BY for meaningful result ranking
6. Use proper GROUP BY for segment/time-based analysis
7. Apply LIMIT when appropriate to prevent overwhelming results
8. Consider seasonal patterns and business cycles
9. Format dates properly for display
10. Use meaningful column aliases for clarity

âš ï¸ CRITICAL COLUMN NAME RULES:
- For segment analysis: Use "Business_on_the_Books_Revenue" NOT "Revenue"
- For historical segments: Use "Business_on_the_Books_Revenue" NOT "Revenue"  
- For entered_on table: Use "COMPANY_CLEAN" NOT "Company_Name", use "AMOUNT" NOT "Revenue"
- For arrivals table: Use "COMPANY_NAME_CLEAN" NOT "Company"
- Column names with spaces must be quoted: "Rm Sold" not Rm_Sold
- When joining tables, ensure column names match exactly
- segment_analysis does NOT have simple "Revenue" column
- historical_segment_YYYY tables only have "Business_on_the_Books_Revenue"
- entered_on table does NOT have "Company", "Company_Name" or "Revenue" columns
- âŒ NEVER use: Company_Name, Revenue (these columns DO NOT EXIST in entered_on table)
- âœ… ALWAYS use: COMPANY_CLEAN for company, AMOUNT for revenue in entered_on table
- Use table aliases when joining: T1.MergedSegment, T2.MergedSegment to avoid ambiguity
- Replace YYYY with actual years: historical_segment_2022, historical_segment_2023, historical_segment_2024

ğŸ“ RECOMMENDED QUERY PATTERNS:
- For top segments single year: SELECT MergedSegment, SUM(Business_on_the_Books_Revenue) FROM historical_segment_2024 GROUP BY MergedSegment ORDER BY SUM(Business_on_the_Books_Revenue) DESC
- For multi-year segments: Use UNION ALL approach, not complex JOINs
- For top companies from entered_on: SELECT COMPANY_CLEAN AS Company_Name, SUM(AMOUNT) AS Total_Revenue FROM entered_on GROUP BY COMPANY_CLEAN ORDER BY SUM(AMOUNT) DESC LIMIT 5
- For company revenue by year from entered_on: SELECT COMPANY_CLEAN, SUM(CASE WHEN strftime('%Y', ARRIVAL) = '2024' THEN AMOUNT ELSE 0 END) AS Revenue_2024, SUM(CASE WHEN strftime('%Y', ARRIVAL) = '2023' THEN AMOUNT ELSE 0 END) AS Revenue_2023 FROM entered_on GROUP BY COMPANY_CLEAN ORDER BY Revenue_2024 DESC LIMIT 5
- For company revenue from arrivals: SELECT COMPANY_NAME_CLEAN, SUM(AMOUNT) FROM arrivals GROUP BY COMPANY_NAME_CLEAN ORDER BY SUM(AMOUNT) DESC
- Avoid JOINs between historical_segment tables - use UNION instead

HOSPITALITY DOMAIN KNOWLEDGE:
- ADR = Revenue / Rooms Sold
- RevPAR = Revenue / Available Rooms = ADR Ã— Occupancy%
- Occupancy% = Rooms Sold / Available Rooms Ã— 100
- Business on Books (BOB) = Future confirmed revenue
- Lead time = Days between booking and arrival
- High season typically: Oct-Apr for Dubai
- Weekend = Friday-Saturday in Middle East
- ğŸ’° CURRENCY: All revenue amounts are in AED (United Arab Emirates Dirham)
- When displaying currency, always use "AED" not "$" or "USD"

QUESTION: {question}

CRITICAL INSTRUCTIONS:
- Generate ONLY ONE SQL query
- Do NOT include multiple queries 
- Do NOT include comments or explanations
- Return ONLY the SQL SELECT statement
- No markdown formatting or code blocks

Generate a precise SQL query that provides actionable business intelligence:
"""
            
            # Generate response
            response = self.model.generate_content(prompt)
            sql_query = response.text.strip()
            
            # Clean up the response
            sql_query = sql_query.replace('```sql', '').replace('```', '').strip()
            
            # If multiple statements, take only the first SELECT statement
            if '--' in sql_query:
                # Split by comment lines and take the first part
                sql_query = sql_query.split('--')[0].strip()
            
            # If multiple queries separated by semicolons, take the first
            if ';' in sql_query:
                statements = sql_query.split(';')
                for stmt in statements:
                    stmt = stmt.strip()
                    if stmt.upper().startswith('SELECT'):
                        sql_query = stmt
                        break
            
            # Final safety check
            if not self.is_safe_query(sql_query):
                return False, "", "Generated query is not safe"
            
            return True, sql_query, ""
            
        except Exception as e:
            error_msg = f"Enhanced SQL generation error: {str(e)}"
            return False, "", error_msg
    
    def is_safe_query(self, sql_query: str) -> bool:
        """Enhanced safety check for SQL queries"""
        # Remove comments and normalize whitespace
        query_clean = re.sub(r'--.*?$', '', sql_query, flags=re.MULTILINE)
        query_clean = re.sub(r'/\*.*?\*/', '', query_clean, flags=re.DOTALL)
        query_clean = query_clean.strip().upper()
        
        # Must start with SELECT
        if not query_clean.startswith('SELECT'):
            return False
        
        # Check for dangerous keywords (excluding UNION which is safe in SELECT context)
        dangerous_keywords = [
            'DELETE', 'UPDATE', 'INSERT', 'DROP', 'CREATE', 'ALTER',
            'TRUNCATE', 'REPLACE', 'EXEC', 'EXECUTE', 'PRAGMA',
            'ATTACH', 'DETACH'
        ]
        
        for keyword in dangerous_keywords:
            if keyword in query_clean:
                return False
        
        # Additional check: if UNION is present, ensure it's only in SELECT context
        if 'UNION' in query_clean:
            # Split by UNION and check that each part starts with SELECT
            union_parts = query_clean.split('UNION')
            for i, part in enumerate(union_parts):
                part = part.strip()
                if part.startswith('ALL'):
                    part = part[3:].strip()  # Remove "ALL" from "UNION ALL"
                if i == 0:  # First part
                    if not part.startswith('SELECT'):
                        return False
                else:  # Subsequent parts after UNION
                    if not part.startswith('SELECT'):
                        return False
        
        return True
    
    def query_database(self, sql_query: str) -> Tuple[bool, pd.DataFrame, str]:
        """Execute SQL query with enhanced error handling"""
        try:
            if not self.is_safe_query(sql_query):
                return False, pd.DataFrame(), "Query not allowed. Only SELECT statements are permitted."
            
            conn = sqlite3.connect(self.db_path)
            df = pd.read_sql_query(sql_query, conn)
            conn.close()
            
            return True, df, ""
            
        except Exception as e:
            error_msg = f"Database query error: {str(e)}"
            return False, pd.DataFrame(), error_msg
    
    def process_enhanced_question(self, question: str) -> Dict[str, Any]:
        """Process question with full conversational intelligence"""
        result = {
            'success': False,
            'sql_query': '',
            'results': pd.DataFrame(),
            'summary': '',
            'insights': [],
            'patterns': [],
            'recommendations': [],
            'follow_up_suggestions': [],
            'error_message': '',
            'row_count': 0,
            'processing_time': datetime.now()
        }
        
        try:
            # Validate input
            if not question or question.strip() == "":
                result['error_message'] = "Please enter a question"
                return result
            
            # Generate contextual SQL
            sql_success, sql_query, sql_error = self.generate_contextual_sql(question)
            
            if not sql_success:
                result['error_message'] = f"SQL generation failed: {sql_error}"
                return result
            
            # Execute query
            query_success, df, query_error = self.query_database(sql_query)
            
            if not query_success:
                result['error_message'] = f"Query execution failed: {query_error}"
                return result
            
            # Generate enhanced response
            enhanced_response = self.generate_enhanced_response(question, sql_query, df)
            
            # Update result with enhanced data
            result.update(enhanced_response)
            result['success'] = True
            
            # Update conversation history
            self.conversation_history.append({
                'question': question,
                'successful_sql': sql_query,
                'result_count': len(df),
                'timestamp': datetime.now()
            })
            
            # Limit conversation history to last 10 interactions
            if len(self.conversation_history) > 10:
                self.conversation_history = self.conversation_history[-10:]
            
            return result
            
        except Exception as e:
            result['error_message'] = f"Unexpected error: {str(e)}"
            return result
    
    def get_conversation_insights(self) -> Dict[str, Any]:
        """Generate insights about the conversation patterns"""
        if not self.conversation_history:
            return {"total_queries": 0, "common_topics": [], "suggestions": []}
        
        topics = []
        total_queries = len(self.conversation_history)
        
        for conv in self.conversation_history:
            question = conv['question'].lower()
            if any(word in question for word in ['revenue', 'sales']):
                topics.append('Revenue Analysis')
            elif any(word in question for word in ['occupancy', 'rooms']):
                topics.append('Occupancy Analysis')
            elif any(word in question for word in ['segment', 'market']):
                topics.append('Segment Analysis')
            elif any(word in question for word in ['forecast', 'predict']):
                topics.append('Forecasting')
        
        from collections import Counter
        common_topics = [topic for topic, count in Counter(topics).most_common(3)]
        
        return {
            "total_queries": total_queries,
            "common_topics": common_topics,
            "suggestions": [
                "ğŸ” Try exploring different time periods",
                "ğŸ“Š Compare performance metrics across segments",
                "ğŸ“ˆ Analyze seasonal patterns and trends"
            ]
        }


def create_enhanced_gemini_backend(api_key: str, db_path: str = "db/revenue.db") -> EnhancedGeminiBackend:
    """Factory function to create Enhanced Gemini backend instance"""
    return EnhancedGeminiBackend(api_key, db_path)