"""
Grand Millennium Revenue Analytics Dashboard
Full-featured Streamlit application with default sidebar
"""

import streamlit as st
import pandas as pd
import plotly.express as px
import plotly.graph_objects as go
from plotly.subplots import make_subplots
import re
import os
import sys
import base64
import traceback
from pathlib import Path
from datetime import datetime, timedelta
import io
import tempfile
import pandas as pd

# Custom imports
try:
    from app.database import get_database
    database_available = True
except ImportError:
    database_available = False
    print("Database module not available.")

try:
    from app.logging_config import get_conversion_logger, get_app_logger, get_log_content
    app_logger = get_app_logger()
    conversion_logger = get_conversion_logger()
    loggers_available = True
except ImportError:
    app_logger = None
    conversion_logger = None
    loggers_available = False
    print("Logging module not available.")

try:
    from app.forecasting import get_forecaster
    forecasting_available = True
except ImportError:
    forecasting_available = False
    print("Forecasting module not available.")

try:
    from app.advanced_forecasting import get_advanced_forecaster
    advanced_forecasting_available = True
except ImportError:
    advanced_forecasting_available = False
    print("Advanced forecasting module not available.")

try:
    from converters.block_converter import run_block_conversion
    from converters.segment_converter import run_segment_conversion
    from converters.occupancy_converter import run_occupancy_conversion
    converters_available = True
except ImportError:
    converters_available = False
    print("Converters module not available.")

# Statistical and ML imports for forecasting
try:
    import numpy as np
    from statsmodels.tsa.holtwinters import ExponentialSmoothing
    from sklearn.metrics import mean_absolute_error, mean_squared_error
    from sklearn.preprocessing import StandardScaler
    from sklearn.ensemble import RandomForestRegressor
    from sklearn.linear_model import LinearRegression
    import warnings
    warnings.filterwarnings('ignore')
except ImportError:
    st.warning("Some advanced features may not be available. Please install: numpy, statsmodels, scikit-learn")

# Import corrected forecasting models
try:
    from app.corrected_forecasting import CorrectedHotelForecasting
    from app.data_integration import HotelDataIntegrator
    from app.fast_forecasting import FastHotelForecasting
    CORRECTED_FORECASTING_AVAILABLE = True
except ImportError:
    CORRECTED_FORECASTING_AVAILABLE = False

# Time series forecasting imports
try:
    from statsmodels.tsa.arima.model import ARIMA
    from statsmodels.tsa.statespace.sarimax import SARIMAX
    from statsmodels.tsa.exponential_smoothing.ets import ETSModel
    from statsmodels.tsa.seasonal import seasonal_decompose
    from statsmodels.stats.diagnostic import acorr_ljungbox
    from statsmodels.tsa.stattools import adfuller
    TS_AVAILABLE = True
except ImportError:
    TS_AVAILABLE = False

try:
    from prophet import Prophet
    PROPHET_AVAILABLE = True
except ImportError:
    PROPHET_AVAILABLE = False

try:
    from app.gemini_backend import create_gemini_backend
    GEMINI_AVAILABLE = True
except ImportError:
    GEMINI_AVAILABLE = False

# Enhanced Gemini Backend
try:
    from app.enhanced_gemini_backend import create_enhanced_gemini_backend
    from app.interactive_chat_interface import render_enhanced_gpt_tab
    ENHANCED_GEMINI_AVAILABLE = True
except ImportError:
    ENHANCED_GEMINI_AVAILABLE = False

import sqlite3

# Add project root and converters to path
project_root = Path(__file__).parent.parent
sys.path.append(str(project_root))
sys.path.append(str(project_root / 'converters'))

# Initialize loggers
conversion_logger = None
app_logger = None

if loggers_available:
    try:
        conversion_logger = get_conversion_logger()
        app_logger = get_app_logger()
    except:
        pass

# Configure Streamlit page
st.set_page_config(
    page_title="Grand Millennium Revenue Analytics",
    page_icon="üè®",
    layout="wide",
    initial_sidebar_state="expanded"
)

# Initialize session state
if 'data_loaded' not in st.session_state:
    st.session_state.data_loaded = False
if 'segment_data' not in st.session_state:
    st.session_state.segment_data = None
if 'occupancy_data' not in st.session_state:
    st.session_state.occupancy_data = None
if 'pickup_report_date' not in st.session_state:
    st.session_state.pickup_report_date = None
if 'current_mhr_file' not in st.session_state:
    st.session_state.current_mhr_file = None

def extract_pickup_report_date(filename):
    """
    Extract pickup report date from filename
    Expected format: MHR Pick Up Report 2025 - 15.08.25
    """
    try:
        # Pattern to match date in format DD.MM.YY or similar
        date_patterns = [
            r'(\d{1,2})\.(\d{1,2})\.(\d{2,4})',  # DD.MM.YY or DD.MM.YYYY
            r'(\d{1,2})-(\d{1,2})-(\d{2,4})',   # DD-MM-YY or DD-MM-YYYY
            r'(\d{1,2})_(\d{1,2})_(\d{2,4})',   # DD_MM_YY or DD_MM_YYYY
        ]
        
        for pattern in date_patterns:
            match = re.search(pattern, filename)
            if match:
                day, month, year = match.groups()
                
                # Handle 2-digit years
                if len(year) == 2:
                    year = '20' + year if int(year) < 50 else '19' + year
                
                # Format as DD/MM/YY
                formatted_date = f"{day.zfill(2)}/{month.zfill(2)}/{year[-2:]}"
                return formatted_date
                
        return None
    except Exception as e:
        return None

def display_pickup_report_header():
    """Display the pickup report header with extracted date"""
    # Header removed - date only shown in navigation panel
    pass

if 'last_run_timestamp' not in st.session_state:
    st.session_state.last_run_timestamp = None
if 'current_tab' not in st.session_state:
    st.session_state.current_tab = "Dashboard"
if 'current_mhr_file' not in st.session_state:
    st.session_state.current_mhr_file = None

# ============================================================================
# HELPER FUNCTIONS
# ============================================================================

def show_loading_requirements():
    """Show message when data needs to be loaded first"""
    st.warning("‚ö†Ô∏è Please load data first using the Dashboard tab")
    col1, col2, col3 = st.columns([1, 1, 1])
    with col2:
        if st.button("üîÑ Go to Dashboard Tab", use_container_width=True):
            st.session_state.current_tab = "Dashboard"
            st.rerun()

def run_conversion_process(file_path):
    """
    Run the complete conversion process
    
    Args:
        file_path: Path to Excel file to process
        
    Returns:
        bool: True if successful, False otherwise
    """
    status_placeholder = st.empty()
    
    try:
        if app_logger:
            app_logger.info(f"Starting conversion process for: {file_path}")
        status_placeholder.info("üîÑ Starting conversion process...")
        
        # Step 1: Run segment conversion
        if converters_available:
            if conversion_logger:
                conversion_logger.info("=== STARTING SEGMENT CONVERSION ===")
            segment_df, segment_path = run_segment_conversion(str(file_path))
            if conversion_logger:
                conversion_logger.info(f"Segment conversion completed: {segment_path}")
            
            status_placeholder.info("üîÑ Segment conversion completed, running occupancy conversion...")
            
            # Step 2: Run occupancy conversion
            status_placeholder.info("üîÑ Running occupancy conversion...")
            
            if conversion_logger:
                conversion_logger.info("=== STARTING OCCUPANCY CONVERSION ===")
            occupancy_df, occupancy_path = run_occupancy_conversion(str(file_path))
            if conversion_logger:
                conversion_logger.info(f"Occupancy conversion completed: {occupancy_path}")
        else:
            # Create dummy data if converters not available
            segment_df = pd.DataFrame({'Month': ['2024-01-01'], 'Segment': ['Test'], 'Revenue': [1000]})
            occupancy_df = pd.DataFrame({'Date': ['2024-01-01'], 'Occupancy': [75], 'ADR': [500]})
            segment_path = "No converter available"
            occupancy_path = "No converter available"
            st.warning("‚ö†Ô∏è Converters not available - using dummy data for testing")
        
        # Step 3: Ingest to database
        status_placeholder.info("üîÑ Ingesting data to database...")
        
        if database_available:
            db = get_database()
            
            # Ingest segment data
            if db.ingest_segment_data(segment_df):
                if conversion_logger:
                    conversion_logger.info("Segment data ingested to database")
            else:
                raise Exception("Failed to ingest segment data")
            
            # Ingest occupancy data
            if db.ingest_occupancy_data(occupancy_df):
                if conversion_logger:
                    conversion_logger.info("Occupancy data ingested to database")
            else:
                raise Exception("Failed to ingest occupancy data")
        else:
            # Save to CSV files as backup
            os.makedirs(project_root / "data" / "processed", exist_ok=True)
            segment_df.to_csv(project_root / "data" / "processed" / "segment.csv", index=False)
            occupancy_df.to_csv(project_root / "data" / "processed" / "occupancy.csv", index=False)
        
        # Step 4: Cache data in session state
        status_placeholder.info("üîÑ Caching data...")
        
        st.session_state.segment_data = segment_df
        st.session_state.occupancy_data = occupancy_df
        st.session_state.data_loaded = True
        st.session_state.last_run_timestamp = datetime.now()
        
        status_placeholder.success("‚úÖ Conversion completed successfully!")
        
        if conversion_logger:
            conversion_logger.info("=== CONVERSION PROCESS COMPLETED SUCCESSFULLY ===")
        if app_logger:
            app_logger.info("Data loaded and cached in session state")
        
        # Show summary
        show_conversion_summary(segment_df, occupancy_df, segment_path, occupancy_path)
        
        return True
        
    except Exception as e:
        error_msg = f"Conversion failed: {str(e)}"
        status_placeholder.error(f"‚ùå {error_msg}")
        if conversion_logger:
            conversion_logger.error(error_msg)
            conversion_logger.error(traceback.format_exc())
        
        # Load existing data from database instead of failing completely
        st.warning("‚ö†Ô∏è Processing failed. Loading existing data from database...")
        try:
            # Try to load from database first
            if database_available:
                db = get_database()
                segment_data = db.get_segment_data()
                occupancy_data = db.get_occupancy_data()
                
                if not segment_data.empty and not occupancy_data.empty:
                    st.session_state.segment_data = segment_data
                    st.session_state.occupancy_data = occupancy_data
                    st.session_state.data_loaded = True
                    st.session_state.last_run_timestamp = datetime.now()
                    st.info("‚ÑπÔ∏è Existing data loaded from database.")
                    return True
            
            # Fallback to CSV files
            segment_file = project_root / "data" / "processed" / "segment.csv"
            occupancy_file = project_root / "data" / "processed" / "occupancy.csv"
            
            if segment_file.exists() and occupancy_file.exists():
                st.session_state.segment_data = pd.read_csv(segment_file)
                st.session_state.occupancy_data = pd.read_csv(occupancy_file)
                st.session_state.data_loaded = True
                st.session_state.last_run_timestamp = datetime.now()
                st.info("‚ÑπÔ∏è Existing data loaded from CSV files.")
                return True
            else:
                st.error("No existing data found.")
                return False
        except Exception as load_error:
            st.error(f"Failed to load existing data: {str(load_error)}")
            return False

def show_conversion_summary(segment_df, occupancy_df, segment_path, occupancy_path):
    """Show summary of successful conversion"""
    st.success("‚úÖ Conversion completed successfully!")

def show_data_status():
    """Show current data loading status"""
    col1, col2, col3 = st.columns(3)
    
    with col1:
        if st.session_state.data_loaded:
            st.success("‚úÖ Data Loaded")
        else:
            st.error("‚ùå No Data")
    
    with col2:
        if st.session_state.last_run_timestamp:
            st.info(f"üïí Last Run: {st.session_state.last_run_timestamp.strftime('%Y-%m-%d %H:%M:%S')}")
        else:
            st.info("üïí Never Run")
    
    with col3:
        try:
            if database_available:
                db_stats = get_database().get_database_stats()
                if db_stats:
                    st.info(f"üìä DB: {db_stats.get('segment_analysis_rows', 0)} seg, {db_stats.get('occupancy_analysis_rows', 0)} occ")
            else:
                st.info("üìä DB: Module not available")
        except:
            st.info("üìä DB: Not available")

def placeholder_tab(title):
    """Placeholder for tabs that will be fully implemented"""
    st.header(f"üöß {title}")
    st.info(f"This is the {title} section. Functionality will be implemented here.")
    if not st.session_state.data_loaded:
        show_loading_requirements()


def dashboard_tab():
    """Dashboard tab for data processing"""
    st.header("üìä Dashboard")
    
    # File upload section
    uploaded_file = st.file_uploader(
        "Choose MHR Excel file",
        type=['xlsm', 'xlsx'],
        help="Upload an MHR Pick Up Report with DPR sheet",
        key="main_dashboard_upload"
    )
    
    # Determine which file to process
    file_to_process = None
    if uploaded_file is not None:
        # Clean up any previous uploaded files
        for old_file in project_root.glob("uploaded_*"):
            try:
                old_file.unlink()
            except:
                pass  # Ignore errors when cleaning up old files
        
        # Save uploaded file to a persistent location for later access
        persistent_filename = f"uploaded_{uploaded_file.name}"
        persistent_path = project_root / persistent_filename
        
        # Write the uploaded file to persistent location
        with open(persistent_path, "wb") as f:
            f.write(uploaded_file.getbuffer())
        file_to_process = persistent_path
        
        # Auto-trigger processing with loading indicator
        with st.spinner("Processing file..."):
            success = run_conversion_process(file_to_process)
        
        if success:
            st.success("‚úÖ Conversion completed successfully!")
        else:
            st.error("‚ùå Processing failed")
    
    # Try to load existing data if not already loaded
    if not st.session_state.data_loaded:
        try:
            segment_file = project_root / "data" / "processed" / "segment.csv"
            occupancy_file = project_root / "data" / "processed" / "occupancy.csv"
            
            if segment_file.exists() and occupancy_file.exists():
                st.session_state.segment_data = pd.read_csv(segment_file)
                st.session_state.occupancy_data = pd.read_csv(occupancy_file)
                st.session_state.data_loaded = True
                st.session_state.last_run_timestamp = datetime.now()
                st.success("‚úÖ Existing data loaded automatically!")
                st.rerun()  # Force a rerun to update all components
        except Exception as e:
            st.info("üìÅ No existing data found. Upload an Excel file to get started.")
    
    # Always show KPI cards and tables (they handle no-data cases internally)
    show_dashboard_kpis()
    show_bob_vs_budget_table()

def show_dashboard_kpis():
    """Show daily pickup KPI cards with conditional formatting"""
    st.subheader("üìä Daily Pickup KPI Cards")
    
    try:
        # Get occupancy data for Daily Revenue (column D)
        if hasattr(st.session_state, 'occupancy_data') and st.session_state.occupancy_data is not None:
            df = st.session_state.occupancy_data.copy()
        else:
            if database_available:
                db = get_database()
                df = db.get_occupancy_data()
            else:
                df = pd.DataFrame()  # Empty dataframe if no database
        
        if df.empty:
            st.error("No occupancy data available for KPIs")
            return
        
        # Get next 3 months (starting from current month)
        current_date = datetime.now()
        months_to_show = []
        
        for i in range(3):  # Current + next 2 months
            month_offset = i
            if current_date.month + month_offset > 12:
                year_offset = (current_date.month + month_offset - 1) // 12
                month_num = ((current_date.month + month_offset - 1) % 12) + 1
                month_date = datetime(current_date.year + year_offset, month_num, 1)
            else:
                month_date = datetime(current_date.year, current_date.month + month_offset, 1)
            months_to_show.append(month_date)
        
        # Create 3 columns for the KPI cards
        col1, col2, col3 = st.columns(3)
        
        # Column D would be the 4th column (index 3)
        column_list = list(df.columns)
        if len(column_list) >= 4:
            column_d = column_list[3]  # 4th column (index 3) = Column D
        else:
            st.error("‚ùå Column D not found - not enough columns in occupancy data")
            return
        
        for i, month_date in enumerate(months_to_show):
            month_name = month_date.strftime('%B %Y')
            
            # Get month data using Date column from occupancy data
            month_data = pd.DataFrame()
            
            if not df.empty and 'Date' in df.columns:
                # Convert Date column to datetime if it's not already
                df_copy = df.copy()
                try:
                    df_copy['Date'] = pd.to_datetime(df_copy['Date'])
                    
                    # Filter by year and month
                    month_mask = (df_copy['Date'].dt.year == month_date.year) & (df_copy['Date'].dt.month == month_date.month)
                    month_data = df_copy[month_mask]
                    
                except Exception as e:
                    st.error(f"Date conversion error for {month_name}: {e}")
            
            if not month_data.empty and column_d in month_data.columns:
                # Sum of Column D for the month
                column_d_total = month_data[column_d].sum()
                
                # Determine color based on positive/negative
                if column_d_total >= 0:
                    delta_color = "normal"  # Green
                    emoji = "‚úÖ"
                else:
                    delta_color = "inverse"  # Red
                    emoji = "‚ùå"
                
                # Show in appropriate column
                with [col1, col2, col3][i]:
                    st.metric(
                        label=f"{emoji} {month_name}",
                        value=f"AED {column_d_total:,.0f}",
                        delta=f"Column D Sum",
                        delta_color=delta_color
                    )
            else:
                with [col1, col2, col3][i]:
                    st.metric(
                        label=f"‚ùì {month_name}",
                        value="No Data",
                        delta="Column D Sum"
                    )
                    
    except Exception as e:
        st.error(f"Error displaying KPIs: {str(e)}")

def show_bob_vs_budget_table():
    """Show Business on Books vs Budget table with variance conditional formatting"""
    st.subheader("üí∞ Business on Books vs Budget Analysis")
    
    try:
        # Get segment data
        if hasattr(st.session_state, 'segment_data') and st.session_state.segment_data is not None:
            df = st.session_state.segment_data.copy()
        else:
            if database_available:
                db = get_database()
                df = db.get_segment_data()
            else:
                df = pd.DataFrame()  # Empty dataframe if no database
        
        if df.empty:
            st.error("No segment data available for BOB vs Budget analysis")
            return
        
        # Create table data
        table_data = []
        
        for month_str in sorted(df['Month'].unique()):
            month_data = df[df['Month'] == month_str]
            month_date = pd.to_datetime(month_str)
            month_name = month_date.strftime('%B %Y')
            
            bob_revenue = month_data['Business_on_the_Books_Revenue'].sum()
            budget_revenue = month_data['Budget_This_Year_Revenue'].sum()
            
            if budget_revenue > 0:
                variance = bob_revenue - budget_revenue
                variance_pct = (variance / budget_revenue) * 100
            else:
                variance = 0
                variance_pct = 0
            
            table_data.append({
                'Month': month_name,
                'BOB Revenue': bob_revenue,
                'Budget': budget_revenue,
                'Variance': variance,
                'Variance %': variance_pct
            })
        
        # Create DataFrame
        table_df = pd.DataFrame(table_data)
        
        if not table_df.empty:
            # Format the table for display (keep variance % as numeric for conditional formatting)
            display_df = table_df.copy()
            
            # Apply conditional formatting to variance percentage BEFORE formatting as text
            def highlight_variance(val):
                if isinstance(val, (int, float)):
                    if val >= 0:
                        return 'color: green; font-weight: bold'
                    else:
                        return 'color: red; font-weight: bold'
                return ''
            
            # Format the dataframe with conditional formatting
            formatted_df = display_df.style.format({
                'BOB Revenue': 'AED {:,.0f}',
                'Budget': 'AED {:,.0f}',
                'Variance': 'AED {:+,.0f}',
                'Variance %': '{:+.1f}%'
            }).applymap(highlight_variance, subset=['Variance %'])
            
            st.dataframe(formatted_df, use_container_width=True)
        else:
            st.error("No data available for BOB vs Budget table")
            
    except Exception as e:
        st.error(f"Error displaying BOB vs Budget table: {str(e)}")

def daily_occupancy_tab():
    """Daily Occupancy Analysis Tab"""
    st.header("üìà Daily Occupancy Analysis")
    
    if not st.session_state.data_loaded:
        show_loading_requirements()
        return
    
    # Get data from session state or database
    if st.session_state.occupancy_data is not None:
        df = st.session_state.occupancy_data.copy()
    else:
        if database_available:
            db = get_database()
            df = db.get_occupancy_data()
        else:
            df = pd.DataFrame()  # Empty dataframe if no database
    
    if df.empty:
        st.error("No occupancy data available")
        return
    
    # Ensure Date column is datetime
    if 'Date' in df.columns:
        df['Date'] = pd.to_datetime(df['Date'])
    
    # Date range filter - Single date range picker
    st.subheader("üìÖ Date Range Filter")
    if 'Date' in df.columns:
        min_date = df['Date'].min().date()
        max_date = df['Date'].max().date()
        date_range = st.date_input(
            "Select Date Range",
            value=(min_date, max_date),
            min_value=min_date,
            max_value=max_date,
            help="Select the start and end dates for analysis"
        )
        
        # Filter data based on date range
        if len(date_range) == 2:
            start_date, end_date = date_range
            mask = (df['Date'].dt.date >= start_date) & (df['Date'].dt.date <= end_date)
            filtered_df = df[mask]
        else:
            # If only one date selected, use full range
            filtered_df = df
    else:
        filtered_df = df
    
    # Main metrics
    st.subheader("üìä Key Metrics")
    col1, col2, col3, col4 = st.columns(4)
    
    with col1:
        avg_occ = filtered_df['Occ%'].mean() if 'Occ%' in filtered_df.columns else 0
        st.metric("Average Occupancy", f"{avg_occ:.1f}%")
    
    with col2:
        total_revenue = filtered_df['Revenue'].sum() if 'Revenue' in filtered_df.columns else 0
        st.metric("Total Revenue (AED)", f"{total_revenue:,.0f}")
    
    with col3:
        avg_adr = filtered_df['ADR'].mean() if 'ADR' in filtered_df.columns else 0
        st.metric("Average ADR (AED)", f"{avg_adr:.0f}")
    
    with col4:
        avg_revpar = filtered_df['RevPar'].mean() if 'RevPar' in filtered_df.columns else 0
        st.metric("Average RevPAR (AED)", f"{avg_revpar:.0f}")
    
    # Validation metrics
    st.subheader("‚ö†Ô∏è Data Validation")
    col1, col2, col3 = st.columns(3)
    
    with col1:
        total_days = len(df)
        expected_days = 365  # 2025 is not a leap year
        missing_days = max(0, expected_days - total_days)
        st.metric("Missing Days", missing_days, delta=f"{(missing_days/expected_days)*100:.1f}% of year" if expected_days > 0 else "")
    
    with col2:
        high_occ_count = (df['Occ%'] > 100).sum() if 'Occ%' in df.columns else 0
        st.metric("High Occupancy (>100%)", high_occ_count, delta="‚ö†Ô∏è Check data" if high_occ_count > 0 else "‚úÖ OK")
    
    with col3:
        zero_revenue_count = (df['Revenue'] == 0).sum() if 'Revenue' in df.columns else 0
        st.metric("Zero Revenue Days", zero_revenue_count)
    
    # Occupancy trend chart with forecast
    st.subheader("üìà Daily Occupancy & ADR Analysis")
    
    if 'Date' in filtered_df.columns and 'Occ%' in filtered_df.columns and 'ADR' in filtered_df.columns:
        # Create dual-axis chart
        fig = go.Figure()
        
        # Add occupancy as bar chart
        fig.add_trace(go.Bar(
            x=filtered_df['Date'],
            y=filtered_df['Occ%'],
            name='Daily Occupancy %',
            marker_color='lightblue',
            opacity=0.7,
            yaxis='y1'
        ))
        
        # Add ADR as line chart on secondary y-axis
        fig.add_trace(go.Scatter(
            x=filtered_df['Date'],
            y=filtered_df['ADR'],
            mode='lines+markers',
            name='ADR Trend',
            line=dict(color='red', width=3),
            marker=dict(size=4),
            yaxis='y2'
        ))
        
        # Update layout for dual axis
        fig.update_layout(
            title="Daily Occupancy (Bars) & ADR Trend (Line) - Full Year View",
            xaxis_title="Date",
            yaxis=dict(
                title="Occupancy %",
                side="left",
                range=[0, 100]  # Fixed range 0-100% for occupancy
            ),
            yaxis2=dict(
                title="ADR (AED)",
                side="right",
                overlaying="y",
                range=[0, max(filtered_df['ADR'].max() * 1.1, 1000)]  # Dynamic range for ADR
            ),
            hovermode='x unified',
            height=600,
            legend=dict(
                x=0.02,
                y=0.98,
                bgcolor="rgba(255,255,255,0.8)"
            )
        )
        
        st.plotly_chart(fig, use_container_width=True)
        
        # Summary statistics
        col1, col2, col3, col4 = st.columns(4)
        
        with col1:
            avg_occ = filtered_df['Occ%'].mean()
            st.metric("Average Occupancy", f"{avg_occ:.1f}%")
        
        with col2:
            avg_adr = filtered_df['ADR'].mean()
            st.metric("Average ADR", f"AED {avg_adr:.0f}")
        
        with col3:
            max_occ = filtered_df['Occ%'].max()
            st.metric("Peak Occupancy", f"{max_occ:.1f}%")
        
        with col4:
            max_adr = filtered_df['ADR'].max()
            st.metric("Peak ADR", f"AED {max_adr:.0f}")
    
    # Enhanced Forecast table with moving average
    st.subheader("üîÆ Current Month Occupancy & Revenue Forecast")
    
    try:
        if forecasting_available:
            advanced_forecaster = get_advanced_forecaster()
            current_month_forecast = advanced_forecaster.forecast_current_month_occupancy_revenue(df)
            
            if 'error' not in current_month_forecast:
                st.success("‚úÖ Current month forecast generated using 7-day moving average!")
                
                # Moving average summary
                st.subheader("üìä 7-Day Moving Average Summary")
                
                moving_avgs = current_month_forecast['moving_averages']
                month_proj = current_month_forecast['month_projections']
                
                col1, col2, col3, col4 = st.columns(4)
                
                with col1:
                    st.metric("7-Day Avg Occupancy", f"{moving_avgs['avg_occupancy_7d']:.1f}%")
                
                with col2:
                    st.metric("7-Day Avg Revenue", f"AED {moving_avgs['avg_revenue_7d']:,.0f}")
                
                with col3:
                    st.metric("7-Day Avg ADR", f"AED {moving_avgs['avg_adr_7d']:.0f}")
                
                with col4:
                    st.metric("Days Remaining", current_month_forecast['days_remaining'])
                
                # Month-end projections
                st.subheader("üéØ Month-End Projections")
                
                col1, col2, col3 = st.columns(3)
                
                with col1:
                    st.metric(
                        "Actual Revenue to Date (Confirmed)",
                        f"AED {month_proj['actual_revenue_to_date']:,.0f}"
                    )
                
                with col2:
                    st.metric(
                        "Remaining Forecast (Today-Month End)",
                        f"AED {month_proj['remaining_revenue_forecast']:,.0f}"
                    )
                
                with col3:
                    st.metric(
                        "Month-End Total Forecast",
                        f"AED {month_proj['month_end_revenue_forecast']:,.0f}"
                    )
                
                # Forecast table
                forecast_data = current_month_forecast['forecast_data']
                
                if forecast_data:
                    st.subheader("üìã Daily Forecast Table")
                    
                    # Create display dataframe
                    display_forecast = pd.DataFrame(forecast_data)
                    display_forecast['date'] = display_forecast['date'].dt.strftime('%Y-%m-%d')
                    display_forecast['forecasted_occupancy'] = display_forecast['forecasted_occupancy'].apply(lambda x: f"{x:.1f}%")
                    display_forecast['forecasted_revenue'] = display_forecast['forecasted_revenue'].apply(lambda x: f"AED {x:,.0f}")
                    display_forecast['forecasted_adr'] = display_forecast['forecasted_adr'].apply(lambda x: f"AED {x:.0f}")
                    
                    display_forecast = display_forecast.rename(columns={
                        'date': 'Date',
                        'forecasted_occupancy': 'Forecast Occupancy',
                        'forecasted_revenue': 'Forecast Revenue',
                        'forecasted_adr': 'Forecast ADR',
                        'day_of_week': 'Day of Week'
                    })
                    
                    st.dataframe(display_forecast, use_container_width=True)
                    
                    # Forecast chart
                    st.subheader("üìà Daily Forecast Visualization")
                    
                    forecast_chart_data = pd.DataFrame(forecast_data)
                    
                    fig_forecast_chart = go.Figure()
                    
                    # Add occupancy forecast
                    fig_forecast_chart.add_trace(go.Scatter(
                        x=forecast_chart_data['date'],
                        y=forecast_chart_data['forecasted_occupancy'],
                        mode='lines+markers',
                        name='Forecast Occupancy (%)',
                        line=dict(color='blue')
                    ))
                    
                    fig_forecast_chart.update_layout(
                        title="Current Month Daily Occupancy Forecast",
                        xaxis_title="Date",
                        yaxis_title="Occupancy %",
                        height=400
                    )
                    
                    st.plotly_chart(fig_forecast_chart, use_container_width=True)
            else:
                st.warning(f"‚ö†Ô∏è Current month forecast unavailable: {current_month_forecast['error']}")
        else:
            st.info("üìä Advanced forecasting module not available - basic functionality only")
                
    except Exception as e:
        st.error(f"‚ùå Forecast error: {str(e)}")
    
    # Daily Revenue Pickup Chart
    st.subheader("üí∞ Daily Revenue Pickup per Day")
    
    try:
        # Use the same occupancy data that's already loaded in this tab
        occupancy_df = filtered_df.copy()  # Use the already filtered occupancy data
        
        if occupancy_df.empty:
            st.info("No occupancy data available for revenue pickup chart")
            return
        
        # Determine the revenue column name (could be 'Revenue', 'DailyRevenue', etc.)
        revenue_column = None
        if 'Revenue' in occupancy_df.columns:
            revenue_column = 'Revenue'
        elif 'DailyRevenue' in occupancy_df.columns:
            revenue_column = 'DailyRevenue'
        elif 'Daily_Revenue' in occupancy_df.columns:
            revenue_column = 'Daily_Revenue'
        
        if revenue_column is None:
            st.error("‚ùå Daily Revenue column not found in occupancy data")
            st.write("Available columns:", list(occupancy_df.columns))
            return
        
        if not occupancy_df.empty and revenue_column in occupancy_df.columns:
            # Ensure Date column is datetime
            if 'Date' in occupancy_df.columns:
                occupancy_df['Date'] = pd.to_datetime(occupancy_df['Date'])
                
                # Sort by date to ensure proper trend line
                occupancy_df = occupancy_df.sort_values('Date')
                
                # Create daily revenue pickup chart - TREND LINE
                fig_pickup = go.Figure()
                
                # Add revenue pickup as trend line (smooth line)
                fig_pickup.add_trace(go.Scatter(
                    x=occupancy_df['Date'],
                    y=occupancy_df[revenue_column],
                    mode='lines+markers',
                    name='Daily Revenue Trend',
                    line=dict(color='green', width=3, shape='spline'),  # Smooth trend line
                    marker=dict(size=4, color='darkgreen'),
                    hovertemplate='<b>Date:</b> %{x}<br><b>Daily Revenue:</b> AED %{y:,.0f}<extra></extra>',
                    fill='tonexty' if len(occupancy_df) > 1 else None,
                    fillcolor='rgba(0,128,0,0.1)'
                ))
                
                # Add trend line (moving average if enough data)
                if len(occupancy_df) >= 7:
                    occupancy_df['MA_7'] = occupancy_df[revenue_column].rolling(window=7, center=True).mean()
                    fig_pickup.add_trace(go.Scatter(
                        x=occupancy_df['Date'],
                        y=occupancy_df['MA_7'],
                        mode='lines',
                        name='7-Day Moving Average',
                        line=dict(color='orange', width=2, dash='dash'),
                        hovertemplate='<b>Date:</b> %{x}<br><b>7-Day Avg:</b> AED %{y:,.0f}<extra></extra>'
                    ))
                
                # Update layout
                fig_pickup.update_layout(
                    title="Daily Revenue Pickup Trend (Column D from Occupancy Data)",
                    xaxis_title="Date",
                    yaxis_title="Daily Revenue (AED)",
                    height=500,
                    hovermode='x unified',
                    showlegend=True,
                    plot_bgcolor='rgba(0,0,0,0)',
                    xaxis=dict(showgrid=True, gridcolor='lightgray'),
                    yaxis=dict(showgrid=True, gridcolor='lightgray')
                )
                
                st.plotly_chart(fig_pickup, use_container_width=True)
                
                # Summary statistics for pickup revenue
                col1, col2, col3, col4 = st.columns(4)
                with col1:
                    total_revenue = occupancy_df[revenue_column].sum()
                    st.metric("Total Daily Revenue", f"AED {total_revenue:,.0f}")
                with col2:
                    avg_revenue = occupancy_df[revenue_column].mean()
                    st.metric("Average Daily Revenue", f"AED {avg_revenue:,.0f}")
                with col3:
                    max_revenue = occupancy_df[revenue_column].max()
                    max_date = occupancy_df.loc[occupancy_df[revenue_column].idxmax(), 'Date']
                    st.metric("Highest Revenue Day", f"AED {max_revenue:,.0f}", 
                             delta=f"{max_date.strftime('%Y-%m-%d')}")
                with col4:
                    positive_days = (occupancy_df[revenue_column] > 0).sum()
                    st.metric("Positive Revenue Days", f"{positive_days} days")
            else:
                st.error("Date column not found in occupancy data")
        else:
            st.info("Daily revenue data not available")
            
    except Exception as e:
        st.error(f"‚ùå Error creating daily revenue chart: {str(e)}")
    
    # Column D Trend Line Chart
    st.subheader("üìä Column D Trend Analysis")
    
    try:
        # Identify Column D from occupancy data
        column_list = list(filtered_df.columns)
        if len(column_list) >= 4:
            column_d = column_list[3]  # 4th column (index 3) = Column D
            st.write(f"**Showing trend for Column D: {column_d}**")
            
            if column_d in filtered_df.columns:
                # Ensure Date column is datetime
                df_for_chart = filtered_df.copy()
                if 'Date' in df_for_chart.columns:
                    df_for_chart['Date'] = pd.to_datetime(df_for_chart['Date'])
                    df_for_chart = df_for_chart.sort_values('Date')
                    
                    # Create Column D trend chart
                    fig_column_d = go.Figure()
                    
                    # Add Column D trend line
                    fig_column_d.add_trace(go.Scatter(
                        x=df_for_chart['Date'],
                        y=df_for_chart[column_d],
                        mode='lines+markers',
                        name=f'{column_d} Trend',
                        line=dict(color='purple', width=3),
                        marker=dict(size=5, color='darkviolet'),
                        hovertemplate=f'<b>Date:</b> %{{x}}<br><b>{column_d}:</b> %{{y:,.2f}}<extra></extra>'
                    ))
                    
                    # Add moving average if enough data
                    if len(df_for_chart) >= 7:
                        df_for_chart['MA_7'] = df_for_chart[column_d].rolling(window=7, center=True).mean()
                        fig_column_d.add_trace(go.Scatter(
                            x=df_for_chart['Date'],
                            y=df_for_chart['MA_7'],
                            mode='lines',
                            name='7-Day Moving Average',
                            line=dict(color='orange', width=2, dash='dash'),
                            hovertemplate=f'<b>Date:</b> %{{x}}<br><b>7-Day Avg:</b> %{{y:,.2f}}<extra></extra>'
                        ))
                    
                    # Update layout
                    fig_column_d.update_layout(
                        title=f"Column D ({column_d}) Daily Trend Analysis",
                        xaxis_title="Date",
                        yaxis_title=f"{column_d}",
                        height=500,
                        hovermode='x unified',
                        showlegend=True,
                        plot_bgcolor='rgba(0,0,0,0)',
                        xaxis=dict(showgrid=True, gridcolor='lightgray'),
                        yaxis=dict(showgrid=True, gridcolor='lightgray')
                    )
                    
                    st.plotly_chart(fig_column_d, use_container_width=True)
                    
                    # Summary statistics for Column D
                    col1, col2, col3, col4 = st.columns(4)
                    with col1:
                        total_column_d = df_for_chart[column_d].sum()
                        st.metric(f"Total {column_d}", f"{total_column_d:,.2f}")
                    with col2:
                        avg_column_d = df_for_chart[column_d].mean()
                        st.metric(f"Average {column_d}", f"{avg_column_d:,.2f}")
                    with col3:
                        max_column_d = df_for_chart[column_d].max()
                        max_date = df_for_chart.loc[df_for_chart[column_d].idxmax(), 'Date']
                        st.metric(f"Highest {column_d}", f"{max_column_d:,.2f}", 
                                 delta=f"{max_date.strftime('%Y-%m-%d')}")
                    with col4:
                        std_column_d = df_for_chart[column_d].std()
                        st.metric(f"Std Deviation", f"{std_column_d:,.2f}")
                else:
                    st.error("Date column not found for Column D chart")
            else:
                st.error(f"Column D ({column_d}) not found in data")
        else:
            st.error("Not enough columns in data to identify Column D")
            
    except Exception as e:
        st.error(f"‚ùå Error creating Column D trend chart: {str(e)}")
    
    # Data table
    st.subheader("üìã Occupancy Data Table")
    
    # Month filter instead of pagination
    if 'Date' in filtered_df.columns:
        available_months = filtered_df['Date'].dt.to_period('M').unique()
        available_months = sorted(available_months)
        
        col1, col2, col3 = st.columns([1, 2, 1])
        with col2:
            if len(available_months) > 1:
                selected_month = st.selectbox(
                    "Select Month", 
                    ["All Months"] + [str(month) for month in available_months],
                    key="occ_month_filter"
                )
                
                if selected_month != "All Months":
                    month_period = pd.Period(selected_month)
                    month_mask = filtered_df['Date'].dt.to_period('M') == month_period
                    table_df = filtered_df[month_mask]
                else:
                    table_df = filtered_df
            else:
                table_df = filtered_df
    else:
        table_df = filtered_df
    
    # Format display columns
    if not table_df.empty:
        display_columns = ['Date', 'DOW', 'Rms', 'Rm Sold', 'Revenue', 'ADR', 'Occ%']
        available_columns = [col for col in display_columns if col in table_df.columns]
        
        if available_columns:
            formatted_df = table_df[available_columns].copy()
            
            # Format monetary columns
            for col in ['Revenue', 'ADR']:
                if col in formatted_df.columns:
                    formatted_df[col] = formatted_df[col].apply(lambda x: f"AED {x:,.0f}" if pd.notna(x) else "AED 0")
            
            # Format percentage
            if 'Occ%' in formatted_df.columns:
                formatted_df['Occ%'] = formatted_df['Occ%'].apply(lambda x: f"{x:.1f}%" if pd.notna(x) else "0.0%")
            
            st.dataframe(formatted_df, use_container_width=True, height=400)
        else:
            st.dataframe(table_df, use_container_width=True, height=400)
    
    st.info(f"Showing {len(table_df)} rows")

def style_variance_table(df, variance_col='Variance_%'):
    """
    Apply conditional formatting to variance tables - text color only
    """
    def color_variance(val):
        """Color variance percentages: green for positive, red for negative"""
        if isinstance(val, str) and '%' in val:
            try:
                numeric_val = float(val.replace('%', ''))
                if numeric_val > 0:
                    return 'color: #28a745; font-weight: bold'  # Green text
                elif numeric_val < 0:
                    return 'color: #dc3545; font-weight: bold'  # Red text
                else:
                    return 'color: #6c757d; font-weight: bold'  # Gray text
            except:
                return ''
        return ''
    
    def color_variance_amount(val):
        """Color variance amounts: green for positive, red for negative"""
        if isinstance(val, str) and 'AED' in val:
            try:
                # Extract numeric value from "AED X,XXX" format
                numeric_str = val.replace('AED', '').replace(',', '').strip()
                numeric_val = float(numeric_str)
                if numeric_val > 0:
                    return 'color: #28a745; font-weight: bold'  # Green text
                elif numeric_val < 0:
                    return 'color: #dc3545; font-weight: bold'  # Red text
                else:
                    return 'color: #6c757d; font-weight: bold'  # Gray text
            except:
                return ''
        return ''
    
    # Apply styling
    styled_df = df.style.applymap(color_variance, subset=[variance_col])
    styled_df = styled_df.applymap(color_variance_amount, subset=['Variance'])
    
    return styled_df

def create_delta_comparison(df, col1, col2, comparison_name, segment_col, granularity):
    """
    Create enhanced delta comparison analysis with multiple charts and tables
    
    Args:
        df: DataFrame with segment data
        col1: Primary column (Business on Books Revenue - trend line)
        col2: Comparison column (bar chart)
        comparison_name: Name for the comparison
        segment_col: Segment column to use
        granularity: Analysis granularity (Monthly, Segment-wise, Both)
    """
    try:
        # Calculate variance with zero division protection
        df_analysis = df.copy()
        df_analysis['Variance'] = df_analysis[col1] - df_analysis[col2]
        
        # Protect against division by zero
        df_analysis['Variance_%'] = 0.0
        mask = df_analysis[col2] != 0
        df_analysis.loc[mask, 'Variance_%'] = ((df_analysis.loc[mask, col1] - df_analysis.loc[mask, col2]) / df_analysis.loc[mask, col2] * 100)
        
        # Replace infinite values
        df_analysis['Variance_%'] = df_analysis['Variance_%'].replace([float('inf'), float('-inf')], 0).fillna(0)
        
        if granularity in ["Monthly", "Both"]:
            st.subheader(f"üìÖ Monthly Analysis - {comparison_name}")
            
            # Monthly aggregation
            monthly_data = df_analysis.groupby(['Month']).agg({
                col1: 'sum',
                col2: 'sum',
                'Variance': 'sum'
            }).reset_index()
            
            # Protect against division by zero for monthly data
            monthly_data['Variance_%'] = 0.0
            mask = monthly_data[col2] != 0
            monthly_data.loc[mask, 'Variance_%'] = ((monthly_data.loc[mask, col1] - monthly_data.loc[mask, col2]) / monthly_data.loc[mask, col2] * 100)
            monthly_data['Variance_%'] = monthly_data['Variance_%'].replace([float('inf'), float('-inf')], 0).fillna(0)
            
            # Create monthly table with conditional formatting
            monthly_display = monthly_data.copy()
            monthly_display['Month'] = monthly_display['Month'].dt.strftime('%Y-%m')
            monthly_display[col1] = monthly_display[col1].apply(lambda x: f"AED {x:,.0f}")
            monthly_display[col2] = monthly_display[col2].apply(lambda x: f"AED {x:,.0f}")
            monthly_display['Variance'] = monthly_display['Variance'].apply(lambda x: f"AED {x:,.0f}")
            monthly_display['Variance_%'] = monthly_display['Variance_%'].apply(lambda x: f"{x:.1f}%")
            
            # Display table with conditional formatting
            st.write("**Monthly Comparison Table:**")
            styled_monthly = style_variance_table(monthly_display)
            st.dataframe(styled_monthly, use_container_width=True)
            
            # Create monthly chart
            fig_monthly = go.Figure()
            
            # Add bar chart for comparison column
            fig_monthly.add_trace(go.Bar(
                x=monthly_data['Month'],
                y=monthly_data[col2],
                name=col2.replace('_', ' '),
                marker_color='lightblue',
                yaxis='y'
            ))
            
            # Add line chart for primary column
            fig_monthly.add_trace(go.Scatter(
                x=monthly_data['Month'],
                y=monthly_data[col1],
                mode='lines+markers',
                name=col1.replace('_', ' '),
                line=dict(color='red', width=3),
                yaxis='y'
            ))
            
            fig_monthly.update_layout(
                title=f'Monthly Trend - {comparison_name}',
                xaxis_title='Month',
                yaxis_title='Revenue (AED)',
                height=500,
                hovermode='x unified'
            )
            
            st.plotly_chart(fig_monthly, use_container_width=True)
        
        if granularity in ["Segment-wise", "Both"]:
            st.subheader(f"üéØ Segment Analysis - {comparison_name}")
            
            # Segment aggregation
            segment_data = df_analysis.groupby([segment_col]).agg({
                col1: 'sum',
                col2: 'sum', 
                'Variance': 'sum'
            }).reset_index()
            
            # Protect against division by zero for segment data
            segment_data['Variance_%'] = 0.0
            mask = segment_data[col2] != 0
            segment_data.loc[mask, 'Variance_%'] = ((segment_data.loc[mask, col1] - segment_data.loc[mask, col2]) / segment_data.loc[mask, col2] * 100)
            segment_data['Variance_%'] = segment_data['Variance_%'].replace([float('inf'), float('-inf')], 0).fillna(0)
            
            # Sort by variance percentage
            segment_data = segment_data.sort_values('Variance_%', ascending=False)
            
            # Create segment table with conditional formatting
            segment_display = segment_data.copy()
            segment_display[col1] = segment_display[col1].apply(lambda x: f"AED {x:,.0f}")
            segment_display[col2] = segment_display[col2].apply(lambda x: f"AED {x:,.0f}")
            segment_display['Variance'] = segment_display['Variance'].apply(lambda x: f"AED {x:,.0f}")
            segment_display['Variance_%'] = segment_display['Variance_%'].apply(lambda x: f"{x:.1f}%")
            
            # Display table with conditional formatting
            st.write("**Segment Comparison Table:**")
            styled_segment = style_variance_table(segment_display)
            st.dataframe(styled_segment, use_container_width=True)
            
            # Original segment chart (keeping existing)
            fig_segment = go.Figure()
            
            # Add bar chart for comparison column
            fig_segment.add_trace(go.Bar(
                x=segment_data[segment_col],
                y=segment_data[col2],
                name=col2.replace('_', ' '),
                marker_color='lightgreen',
                yaxis='y'
            ))
            
            # Add line chart for primary column
            fig_segment.add_trace(go.Scatter(
                x=segment_data[segment_col],
                y=segment_data[col1],
                mode='lines+markers',
                name=col1.replace('_', ' '),
                line=dict(color='orange', width=3),
                yaxis='y'
            ))
            
            fig_segment.update_layout(
                title=f'Segment Analysis - {comparison_name}',
                xaxis_title='Segment',
                yaxis_title='Revenue (AED)',
                height=500,
                hovermode='x unified'
            )
            
            st.plotly_chart(fig_segment, use_container_width=True)
            
            # Additional chart layouts
            st.subheader(f"üìä Additional Segment Analysis Charts - {comparison_name}")
            chart_col1, chart_col2 = st.columns(2)
            
            with chart_col1:
                # 1. Enhanced Combination Chart - Bar + Line
                fig_combo = go.Figure()
                
                # Add bar chart for comparison column
                fig_combo.add_trace(go.Bar(
                    x=segment_data[segment_col],
                    y=segment_data[col2],
                    name=col2.replace('_', ' '),
                    marker_color='lightblue',
                    opacity=0.7
                ))
                
                # Add line chart for primary column
                fig_combo.add_trace(go.Scatter(
                    x=segment_data[segment_col],
                    y=segment_data[col1],
                    mode='lines+markers',
                    name=col1.replace('_', ' '),
                    line=dict(color='red', width=3),
                    marker=dict(size=8)
                ))
                
                fig_combo.update_layout(
                    title=f'Revenue Comparison - {comparison_name}',
                    xaxis_title='Segment',
                    yaxis_title='Revenue (AED)',
                    height=400,
                    hovermode='x unified',
                    showlegend=True
                )
                
                st.plotly_chart(fig_combo, use_container_width=True)
            
            with chart_col2:
                # 2. Variance Percentage Chart
                fig_variance = px.bar(
                    segment_data,
                    x=segment_col,
                    y='Variance_%',
                    title=f'Variance Percentage - {comparison_name}',
                    labels={'Variance_%': 'Variance %', segment_col: 'Segment'},
                    color='Variance_%',
                    color_continuous_scale=['red', 'gray', 'green'],
                    color_continuous_midpoint=0
                )
                
                fig_variance.update_layout(height=400)
                st.plotly_chart(fig_variance, use_container_width=True)
            
            # Additional chart row
            chart_col3, chart_col4 = st.columns(2)
            
            with chart_col3:
                # 3. Absolute Variance Chart
                fig_abs_variance = px.bar(
                    segment_data,
                    x=segment_col,
                    y='Variance',
                    title=f'Absolute Variance (AED) - {comparison_name}',
                    labels={'Variance': 'Variance (AED)', segment_col: 'Segment'},
                    color='Variance',
                    color_continuous_scale=['red', 'gray', 'green'],
                    color_continuous_midpoint=0
                )
                
                fig_abs_variance.update_layout(height=400)
                st.plotly_chart(fig_abs_variance, use_container_width=True)
            
            with chart_col4:
                # 4. Pie Chart for Revenue Distribution
                fig_pie = px.pie(
                    segment_data,
                    values=col1,
                    names=segment_col,
                    title=f'{col1.replace("_", " ")} Distribution',
                    color_discrete_sequence=px.colors.qualitative.Set3
                )
                
                fig_pie.update_layout(height=400)
                st.plotly_chart(fig_pie, use_container_width=True)
            
            # Third row of additional charts
            chart_col5, chart_col6 = st.columns(2)
            
            with chart_col5:
                # 5. Waterfall Chart for Variance
                fig_waterfall = go.Figure(go.Waterfall(
                    name="Variance Breakdown",
                    orientation="v",
                    measure=["relative"] * len(segment_data),
                    x=segment_data[segment_col],
                    y=segment_data['Variance'],
                    connector={"line": {"color": "rgb(63, 63, 63)"}},
                    text=[f"AED {x:,.0f}" for x in segment_data['Variance']],
                    textposition="outside"
                ))
                
                fig_waterfall.update_layout(
                    title=f"Variance Waterfall - {comparison_name}",
                    height=400,
                    xaxis_title="Segment",
                    yaxis_title="Variance (AED)"
                )
                
                st.plotly_chart(fig_waterfall, use_container_width=True)
            
            with chart_col6:
                # 6. Box Plot for Revenue Range Analysis
                box_data = []
                for segment in segment_data[segment_col]:
                    segment_subset = df_analysis[df_analysis[segment_col] == segment]
                    for _, row in segment_subset.iterrows():
                        box_data.append({
                            'Segment': segment,
                            'BOB_Revenue': row[col1],
                            'Comparison_Revenue': row[col2]
                        })
                
                if box_data:
                    box_df = pd.DataFrame(box_data)
                    fig_box = go.Figure()
                    
                    fig_box.add_trace(go.Box(
                        y=box_df['BOB_Revenue'],
                        x=box_df['Segment'],
                        name=col1.replace('_', ' '),
                        boxpoints='all',
                        jitter=0.3,
                        pointpos=-1.8
                    ))
                    
                    fig_box.add_trace(go.Box(
                        y=box_df['Comparison_Revenue'],
                        x=box_df['Segment'],
                        name=col2.replace('_', ' '),
                        boxpoints='all',
                        jitter=0.3,
                        pointpos=1.8
                    ))
                    
                    fig_box.update_layout(
                        title=f"Revenue Distribution - {comparison_name}",
                        height=400,
                        xaxis_title="Segment",
                        yaxis_title="Revenue (AED)",
                        boxmode='group'
                    )
                    
                    st.plotly_chart(fig_box, use_container_width=True)
            
            # Performance ranking table
            st.subheader(f"üìà Performance Ranking - {comparison_name}")
            ranking_data = segment_data.copy()
            ranking_data['Performance_Rank'] = ranking_data['Variance_%'].rank(ascending=False, method='dense').astype(int)
            ranking_data = ranking_data.sort_values('Performance_Rank')
            
            ranking_display = ranking_data[[segment_col, 'Performance_Rank', 'Variance_%', 'Variance']].copy()
            ranking_display['Variance'] = ranking_display['Variance'].apply(lambda x: f"AED {x:,.0f}")
            ranking_display['Variance_%'] = ranking_display['Variance_%'].apply(lambda x: f"{x:.1f}%")
            ranking_display = ranking_display.rename(columns={
                segment_col: 'Segment',
                'Performance_Rank': 'Rank',
                'Variance_%': 'Variance %',
                'Variance': 'Variance (AED)'
            })
            
            styled_ranking = style_variance_table(ranking_display, variance_col='Variance %')
            st.dataframe(styled_ranking, use_container_width=True)
            
        # Variance summary
        st.subheader(f"üìä Variance Summary - {comparison_name}")
        col1_sum = df_analysis[col1].sum()
        col2_sum = df_analysis[col2].sum()
        total_variance = col1_sum - col2_sum
        variance_pct = (total_variance / col2_sum * 100) if col2_sum != 0 else 0
        
        summary_col1, summary_col2, summary_col3 = st.columns(3)
        
        with summary_col1:
            st.metric(
                label=col1.replace('_', ' '),
                value=f"AED {col1_sum:,.0f}"
            )
        
        with summary_col2:
            st.metric(
                label=col2.replace('_', ' '),
                value=f"AED {col2_sum:,.0f}"
            )
        
        with summary_col3:
            delta_color = "normal" if variance_pct >= 0 else "inverse"
            st.metric(
                label="Total Variance",
                value=f"AED {total_variance:,.0f}",
                delta=f"{variance_pct:.1f}%"
            )
            
    except Exception as e:
        st.error(f"Error in delta comparison: {str(e)}")

def segment_analysis_tab():
    """Segment Analysis Tab with sub-tabs"""
    st.header("üéØ Segment Analysis")
    
    # Create sub-tabs
    analysis_tab, delta_tab, market_seg_tab = st.tabs(["üìä Revenue Analysis", "üìà Delta Analysis", "üìã Market Segmentation"])
    
    with analysis_tab:
        st.subheader("üìä Revenue Analysis")
        
        # Check if data is loaded
        if not st.session_state.data_loaded:
            show_loading_requirements()
            return
        
        # Get data from session state or database
        if st.session_state.segment_data is not None:
            df = st.session_state.segment_data.copy()
        else:
            if database_available:
                db = get_database()
                df = db.get_segment_data()
            else:
                df = pd.DataFrame()
        
        if df.empty:
            st.error("No segment data available for revenue analysis")
            return
        
        # Ensure Month column is datetime
        if 'Month' in df.columns:
            df['Month'] = pd.to_datetime(df['Month'], errors='coerce')
            df = df.dropna(subset=['Month'])
        
        # Top-level filters
        st.markdown("### üéõÔ∏è Analysis Filters")
        filter_col1, filter_col2, filter_col3 = st.columns(3)
        
        with filter_col1:
            # Segment type toggle
            segment_type = st.radio(
                "Segment Type:",
                ["Merged Segments (6)", "Unmerged Segments (15)"],
                index=0,
                help="Choose between merged segments or individual segments"
            )
            use_merged = segment_type.startswith("Merged")
        
        with filter_col2:
            # Month filter
            if 'Month' in df.columns and len(df) > 0:
                available_months = sorted(df['Month'].dt.to_period('M').unique())
                selected_months = st.multiselect(
                    "Select Months:",
                    options=available_months,
                    default=available_months[-6:] if len(available_months) >= 6 else available_months,
                    format_func=lambda x: str(x)
                )
            else:
                selected_months = []
        
        with filter_col3:
            # Analysis granularity
            granularity = st.selectbox(
                "Analysis Granularity:",
                ["Monthly", "Quarterly", "All Data"],
                index=0,
                help="Choose the level of data aggregation"
            )
        
        # Filter data based on selections
        filtered_df = df.copy()
        if selected_months:
            filtered_df = filtered_df[filtered_df['Month'].dt.to_period('M').isin(selected_months)]
        
        if filtered_df.empty:
            st.warning("No data available for selected filters")
            return
        
        # Choose segment column
        segment_col = 'MergedSegment' if use_merged and 'MergedSegment' in filtered_df.columns else 'Segment'
        
        if segment_col not in filtered_df.columns:
            st.error(f"Segment column '{segment_col}' not found in data")
            return
        
        # Required columns for variance analysis
        required_columns = [
            'Business_on_the_Books_Revenue',
            'Full_Month_Last_Year_Revenue',
            'Budget_This_Year_Revenue',
            'Business_on_the_Books_Same_Time_Last_Year_Revenue'
        ]
        
        missing_columns = [col for col in required_columns if col not in filtered_df.columns]
        if missing_columns:
            st.error(f"Missing required columns for variance analysis: {missing_columns}")
            return
        
        # Convert revenue columns to numeric
        for col in required_columns:
            filtered_df[col] = pd.to_numeric(filtered_df[col], errors='coerce').fillna(0)
        
        # Aggregate data based on granularity
        if granularity == "Quarterly":
            filtered_df['Period'] = filtered_df['Month'].dt.to_period('Q')
            agg_df = filtered_df.groupby([segment_col, 'Period'])[required_columns].sum().reset_index()
        elif granularity == "All Data":
            agg_df = filtered_df.groupby(segment_col)[required_columns].sum().reset_index()
            agg_df['Period'] = 'All Data'
        else:  # Monthly
            agg_df = filtered_df.copy()
            agg_df['Period'] = agg_df['Month'].dt.to_period('M')
        
        # Function to create conditional formatting for variance tables
        def style_variance_table(df, variance_col='Variance_%', variance_aed_col='Variance (AED)'):
            """Apply conditional formatting to variance columns"""
            def color_variance(val):
                try:
                    if pd.isna(val):
                        return 'color: gray'
                    val_num = float(str(val).replace('%', '').replace('AED', '').replace(',', '').strip())
                    if val_num > 0:
                        return 'color: green; font-weight: bold'
                    elif val_num < 0:
                        return 'color: red; font-weight: bold'
                    else:
                        return 'color: black'
                except:
                    return 'color: black'
            
            # Apply formatting to both variance columns
            styled_df = df.style.applymap(color_variance, subset=[variance_col])
            if variance_aed_col in df.columns:
                styled_df = styled_df.applymap(color_variance, subset=[variance_aed_col])
            return styled_df
        
        # Section 1: BOB vs FMLY Analysis
        st.markdown("---")
        st.markdown("### üìä Variance Analysis - BOB vs Full Month Last Year (FMLY)")
        
        # Calculate FMLY variance
        fmly_analysis = agg_df.copy()
        fmly_analysis['Variance'] = fmly_analysis['Business_on_the_Books_Revenue'] - fmly_analysis['Full_Month_Last_Year_Revenue']
        fmly_analysis['Variance_%'] = ((fmly_analysis['Business_on_the_Books_Revenue'] - fmly_analysis['Full_Month_Last_Year_Revenue']) / fmly_analysis['Full_Month_Last_Year_Revenue']) * 100
        fmly_analysis['Variance_%'] = fmly_analysis['Variance_%'].replace([np.inf, -np.inf], 0).fillna(0)
        
        # Create summary table for FMLY
        fmly_summary = fmly_analysis.groupby(segment_col).agg({
            'Business_on_the_Books_Revenue': 'sum',
            'Full_Month_Last_Year_Revenue': 'sum',
            'Variance': 'sum'
        }).reset_index()
        fmly_summary['Variance_%'] = ((fmly_summary['Business_on_the_Books_Revenue'] - fmly_summary['Full_Month_Last_Year_Revenue']) / fmly_summary['Full_Month_Last_Year_Revenue']) * 100
        fmly_summary['Variance_%'] = fmly_summary['Variance_%'].replace([np.inf, -np.inf], 0).fillna(0)
        
        # KPI Dashboard for BOB vs FMLY
        st.markdown("#### üéØ BOB vs FMLY KPIs")
        kpi_col1, kpi_col2, kpi_col3, kpi_col4 = st.columns(4)
        
        with kpi_col1:
            total_bob_fmly = fmly_summary['Business_on_the_Books_Revenue'].sum()
            st.metric("Total BOB Revenue", f"AED {total_bob_fmly:,.0f}")
        
        with kpi_col2:
            total_fmly = fmly_summary['Full_Month_Last_Year_Revenue'].sum()
            st.metric("Total FMLY Revenue", f"AED {total_fmly:,.0f}")
        
        with kpi_col3:
            total_variance_fmly = fmly_summary['Variance'].sum()
            variance_color = "normal" if total_variance_fmly >= 0 else "inverse"
            st.metric("Total Variance", f"AED {total_variance_fmly:,.0f}", 
                     delta=f"{(total_variance_fmly/total_fmly*100):.1f}%" if total_fmly != 0 else "0.0%")
        
        with kpi_col4:
            avg_variance_fmly = fmly_summary['Variance_%'].mean()
            st.metric("Average Variance %", f"{avg_variance_fmly:.1f}%")
        
        # Charts for FMLY Analysis
        chart_col1, chart_col2 = st.columns(2)
        
        with chart_col1:
            # Bar chart showing BOB vs FMLY by segment
            fig_fmly_comparison = px.bar(
                fmly_summary,
                x=segment_col,
                y=['Business_on_the_Books_Revenue', 'Full_Month_Last_Year_Revenue'],
                title='BOB vs FMLY Revenue Comparison by Segment',
                labels={'value': 'Revenue (AED)', 'variable': 'Revenue Type'},
                barmode='group',
                color_discrete_map={
                    'Business_on_the_Books_Revenue': '#1f77b4',
                    'Full_Month_Last_Year_Revenue': '#ff7f0e'
                }
            )
            fig_fmly_comparison.update_layout(xaxis_tickangle=45, height=400)
            st.plotly_chart(fig_fmly_comparison, use_container_width=True)
        
        with chart_col2:
            # Variance heatmap/bar chart
            fig_fmly_variance = px.bar(
                fmly_summary,
                x=segment_col,
                y='Variance_%',
                title='FMLY Variance % by Segment',
                labels={'Variance_%': 'Variance %'},
                color='Variance_%',
                color_continuous_scale=['red', 'white', 'green'],
                color_continuous_midpoint=0
            )
            fig_fmly_variance.update_layout(xaxis_tickangle=45, height=400)
            st.plotly_chart(fig_fmly_variance, use_container_width=True)
        
        # Variance Table with enhanced conditional formatting
        st.markdown("#### üìã BOB vs FMLY Variance Table")
        
        # Format and display FMLY table
        fmly_display = fmly_summary.copy()
        fmly_display['Business_on_the_Books_Revenue'] = fmly_display['Business_on_the_Books_Revenue'].apply(lambda x: f"AED {x:,.0f}")
        fmly_display['Full_Month_Last_Year_Revenue'] = fmly_display['Full_Month_Last_Year_Revenue'].apply(lambda x: f"AED {x:,.0f}")
        fmly_display['Variance'] = fmly_display['Variance'].apply(lambda x: f"AED {x:,.0f}")
        fmly_display['Variance_%'] = fmly_display['Variance_%'].apply(lambda x: f"{x:.1f}%")
        fmly_display = fmly_display.rename(columns={
            segment_col: 'Segment',
            'Business_on_the_Books_Revenue': 'BOB Revenue',
            'Full_Month_Last_Year_Revenue': 'FMLY Revenue',
            'Variance': 'Variance (AED)',
            'Variance_%': 'Variance %'
        })
        
        # Apply conditional formatting and display
        styled_fmly = style_variance_table(fmly_display, 'Variance %', 'Variance (AED)')
        st.dataframe(styled_fmly, use_container_width=True, hide_index=True)
        
        # EDA for FMLY
        fmly_col1, fmly_col2 = st.columns(2)
        with fmly_col1:
            # Summary statistics
            positive_segments = len(fmly_summary[fmly_summary['Variance_%'] > 0])
            total_segments = len(fmly_summary)
            st.metric("Positive Performance", f"{positive_segments}/{total_segments} segments")
            
            # Performance distribution
            negative_segments = total_segments - positive_segments
            st.info(f"üìà **Performance Distribution**: {positive_segments} segments outperformed FMLY, {negative_segments} underperformed")
        
        with fmly_col2:
            # Best and worst performers
            best_performer = fmly_summary.loc[fmly_summary['Variance_%'].idxmax()]
            worst_performer = fmly_summary.loc[fmly_summary['Variance_%'].idxmin()]
            st.metric("Best Performer", f"{best_performer[segment_col]}", f"{best_performer['Variance_%']:.1f}%")
            st.metric("Worst Performer", f"{worst_performer[segment_col]}", f"{worst_performer['Variance_%']:.1f}%")
        
        # Section 2: BOB vs Budget Analysis
        st.markdown("---")
        st.markdown("### üìä Variance Analysis - BOB vs Budget")
        
        # Calculate Budget variance
        budget_analysis = agg_df.copy()
        budget_analysis['Variance'] = budget_analysis['Business_on_the_Books_Revenue'] - budget_analysis['Budget_This_Year_Revenue']
        budget_analysis['Variance_%'] = ((budget_analysis['Business_on_the_Books_Revenue'] - budget_analysis['Budget_This_Year_Revenue']) / budget_analysis['Budget_This_Year_Revenue']) * 100
        budget_analysis['Variance_%'] = budget_analysis['Variance_%'].replace([np.inf, -np.inf], 0).fillna(0)
        
        # Create summary table for Budget
        budget_summary = budget_analysis.groupby(segment_col).agg({
            'Business_on_the_Books_Revenue': 'sum',
            'Budget_This_Year_Revenue': 'sum',
            'Variance': 'sum'
        }).reset_index()
        budget_summary['Variance_%'] = ((budget_summary['Business_on_the_Books_Revenue'] - budget_summary['Budget_This_Year_Revenue']) / budget_summary['Budget_This_Year_Revenue']) * 100
        budget_summary['Variance_%'] = budget_summary['Variance_%'].replace([np.inf, -np.inf], 0).fillna(0)
        
        # KPI Dashboard for BOB vs Budget
        st.markdown("#### üéØ BOB vs Budget KPIs")
        kpi_col1, kpi_col2, kpi_col3, kpi_col4 = st.columns(4)
        
        with kpi_col1:
            total_bob_budget = budget_summary['Business_on_the_Books_Revenue'].sum()
            st.metric("Total BOB Revenue", f"AED {total_bob_budget:,.0f}")
        
        with kpi_col2:
            total_budget = budget_summary['Budget_This_Year_Revenue'].sum()
            st.metric("Total Budget Revenue", f"AED {total_budget:,.0f}")
        
        with kpi_col3:
            total_variance_budget = budget_summary['Variance'].sum()
            st.metric("Total Variance", f"AED {total_variance_budget:,.0f}", 
                     delta=f"{(total_variance_budget/total_budget*100):.1f}%" if total_budget != 0 else "0.0%")
        
        with kpi_col4:
            avg_variance_budget = budget_summary['Variance_%'].mean()
            st.metric("Average Variance %", f"{avg_variance_budget:.1f}%")
        
        # Charts for Budget Analysis
        chart_col1, chart_col2 = st.columns(2)
        
        with chart_col1:
            # Bar chart showing BOB vs Budget by segment
            fig_budget_comparison = px.bar(
                budget_summary,
                x=segment_col,
                y=['Business_on_the_Books_Revenue', 'Budget_This_Year_Revenue'],
                title='BOB vs Budget Revenue Comparison by Segment',
                labels={'value': 'Revenue (AED)', 'variable': 'Revenue Type'},
                barmode='group',
                color_discrete_map={
                    'Business_on_the_Books_Revenue': '#1f77b4',
                    'Budget_This_Year_Revenue': '#2ca02c'
                }
            )
            fig_budget_comparison.update_layout(xaxis_tickangle=45, height=400)
            st.plotly_chart(fig_budget_comparison, use_container_width=True)
        
        with chart_col2:
            # Variance heatmap/bar chart
            fig_budget_variance = px.bar(
                budget_summary,
                x=segment_col,
                y='Variance_%',
                title='Budget Variance % by Segment',
                labels={'Variance_%': 'Variance %'},
                color='Variance_%',
                color_continuous_scale=['red', 'white', 'green'],
                color_continuous_midpoint=0
            )
            fig_budget_variance.update_layout(xaxis_tickangle=45, height=400)
            st.plotly_chart(fig_budget_variance, use_container_width=True)
        
        # Variance Table with enhanced conditional formatting
        st.markdown("#### üìã BOB vs Budget Variance Table")
        
        # Format and display Budget table
        budget_display = budget_summary.copy()
        budget_display['Business_on_the_Books_Revenue'] = budget_display['Business_on_the_Books_Revenue'].apply(lambda x: f"AED {x:,.0f}")
        budget_display['Budget_This_Year_Revenue'] = budget_display['Budget_This_Year_Revenue'].apply(lambda x: f"AED {x:,.0f}")
        budget_display['Variance'] = budget_display['Variance'].apply(lambda x: f"AED {x:,.0f}")
        budget_display['Variance_%'] = budget_display['Variance_%'].apply(lambda x: f"{x:.1f}%")
        budget_display = budget_display.rename(columns={
            segment_col: 'Segment',
            'Business_on_the_Books_Revenue': 'BOB Revenue',
            'Budget_This_Year_Revenue': 'Budget Revenue',
            'Variance': 'Variance (AED)',
            'Variance_%': 'Variance %'
        })
        
        # Apply conditional formatting and display
        styled_budget = style_variance_table(budget_display, 'Variance %', 'Variance (AED)')
        st.dataframe(styled_budget, use_container_width=True, hide_index=True)
        
        # EDA for Budget
        budget_col1, budget_col2 = st.columns(2)
        with budget_col1:
            # Summary statistics
            positive_segments = len(budget_summary[budget_summary['Variance_%'] > 0])
            total_segments = len(budget_summary)
            st.metric("Over Budget", f"{positive_segments}/{total_segments} segments")
            
            # Performance distribution
            under_budget_segments = total_segments - positive_segments
            st.info(f"üí∞ **Budget Performance**: {positive_segments} segments over budget, {under_budget_segments} under budget")
        
        with budget_col2:
            # Best and worst performers
            best_performer = budget_summary.loc[budget_summary['Variance_%'].idxmax()]
            worst_performer = budget_summary.loc[budget_summary['Variance_%'].idxmin()]
            st.metric("Best vs Budget", f"{best_performer[segment_col]}", f"{best_performer['Variance_%']:.1f}%")
            st.metric("Worst vs Budget", f"{worst_performer[segment_col]}", f"{worst_performer['Variance_%']:.1f}%")
        
        # Section 3: BOB vs STLY Analysis
        st.markdown("---")
        st.markdown("### üìä Variance Analysis - BOB vs Same Time Last Year (STLY)")
        
        # Calculate STLY variance
        stly_analysis = agg_df.copy()
        stly_analysis['Variance'] = stly_analysis['Business_on_the_Books_Revenue'] - stly_analysis['Business_on_the_Books_Same_Time_Last_Year_Revenue']
        stly_analysis['Variance_%'] = ((stly_analysis['Business_on_the_Books_Revenue'] - stly_analysis['Business_on_the_Books_Same_Time_Last_Year_Revenue']) / stly_analysis['Business_on_the_Books_Same_Time_Last_Year_Revenue']) * 100
        stly_analysis['Variance_%'] = stly_analysis['Variance_%'].replace([np.inf, -np.inf], 0).fillna(0)
        
        # Create summary table for STLY
        stly_summary = stly_analysis.groupby(segment_col).agg({
            'Business_on_the_Books_Revenue': 'sum',
            'Business_on_the_Books_Same_Time_Last_Year_Revenue': 'sum',
            'Variance': 'sum'
        }).reset_index()
        stly_summary['Variance_%'] = ((stly_summary['Business_on_the_Books_Revenue'] - stly_summary['Business_on_the_Books_Same_Time_Last_Year_Revenue']) / stly_summary['Business_on_the_Books_Same_Time_Last_Year_Revenue']) * 100
        stly_summary['Variance_%'] = stly_summary['Variance_%'].replace([np.inf, -np.inf], 0).fillna(0)
        
        # KPI Dashboard for BOB vs STLY
        st.markdown("#### üéØ BOB vs STLY KPIs")
        kpi_col1, kpi_col2, kpi_col3, kpi_col4 = st.columns(4)
        
        with kpi_col1:
            total_bob_stly = stly_summary['Business_on_the_Books_Revenue'].sum()
            st.metric("Total BOB Revenue", f"AED {total_bob_stly:,.0f}")
        
        with kpi_col2:
            total_stly = stly_summary['Business_on_the_Books_Same_Time_Last_Year_Revenue'].sum()
            st.metric("Total STLY Revenue", f"AED {total_stly:,.0f}")
        
        with kpi_col3:
            total_variance_stly = stly_summary['Variance'].sum()
            st.metric("Total Variance", f"AED {total_variance_stly:,.0f}", 
                     delta=f"{(total_variance_stly/total_stly*100):.1f}%" if total_stly != 0 else "0.0%")
        
        with kpi_col4:
            avg_variance_stly = stly_summary['Variance_%'].mean()
            st.metric("Average Variance %", f"{avg_variance_stly:.1f}%")
        
        # Charts for STLY Analysis
        chart_col1, chart_col2 = st.columns(2)
        
        with chart_col1:
            # Bar chart showing BOB vs STLY by segment
            fig_stly_comparison = px.bar(
                stly_summary,
                x=segment_col,
                y=['Business_on_the_Books_Revenue', 'Business_on_the_Books_Same_Time_Last_Year_Revenue'],
                title='BOB vs STLY Revenue Comparison by Segment',
                labels={'value': 'Revenue (AED)', 'variable': 'Revenue Type'},
                barmode='group',
                color_discrete_map={
                    'Business_on_the_Books_Revenue': '#1f77b4',
                    'Business_on_the_Books_Same_Time_Last_Year_Revenue': '#d62728'
                }
            )
            fig_stly_comparison.update_layout(xaxis_tickangle=45, height=400)
            st.plotly_chart(fig_stly_comparison, use_container_width=True)
        
        with chart_col2:
            # Variance heatmap/bar chart
            fig_stly_variance = px.bar(
                stly_summary,
                x=segment_col,
                y='Variance_%',
                title='STLY Variance % by Segment',
                labels={'Variance_%': 'Variance %'},
                color='Variance_%',
                color_continuous_scale=['red', 'white', 'green'],
                color_continuous_midpoint=0
            )
            fig_stly_variance.update_layout(xaxis_tickangle=45, height=400)
            st.plotly_chart(fig_stly_variance, use_container_width=True)
        
        # Variance Table with enhanced conditional formatting
        st.markdown("#### üìã BOB vs STLY Variance Table")
        
        # Format and display STLY table
        stly_display = stly_summary.copy()
        stly_display['Business_on_the_Books_Revenue'] = stly_display['Business_on_the_Books_Revenue'].apply(lambda x: f"AED {x:,.0f}")
        stly_display['Business_on_the_Books_Same_Time_Last_Year_Revenue'] = stly_display['Business_on_the_Books_Same_Time_Last_Year_Revenue'].apply(lambda x: f"AED {x:,.0f}")
        stly_display['Variance'] = stly_display['Variance'].apply(lambda x: f"AED {x:,.0f}")
        stly_display['Variance_%'] = stly_display['Variance_%'].apply(lambda x: f"{x:.1f}%")
        stly_display = stly_display.rename(columns={
            segment_col: 'Segment',
            'Business_on_the_Books_Revenue': 'BOB Revenue',
            'Business_on_the_Books_Same_Time_Last_Year_Revenue': 'STLY Revenue',
            'Variance': 'Variance (AED)',
            'Variance_%': 'Variance %'
        })
        
        # Apply conditional formatting and display
        styled_stly = style_variance_table(stly_display, 'Variance %', 'Variance (AED)')
        st.dataframe(styled_stly, use_container_width=True, hide_index=True)
        
        # EDA for STLY
        stly_col1, stly_col2 = st.columns(2)
        with stly_col1:
            # Summary statistics
            positive_segments = len(stly_summary[stly_summary['Variance_%'] > 0])
            total_segments = len(stly_summary)
            st.metric("YoY Growth", f"{positive_segments}/{total_segments} segments")
            
            # Performance distribution
            declining_segments = total_segments - positive_segments
            st.info(f"üìà **YoY Performance**: {positive_segments} segments grew, {declining_segments} declined")
        
        with stly_col2:
            # Best and worst performers
            best_performer = stly_summary.loc[stly_summary['Variance_%'].idxmax()]
            worst_performer = stly_summary.loc[stly_summary['Variance_%'].idxmin()]
            st.metric("Best YoY Growth", f"{best_performer[segment_col]}", f"{best_performer['Variance_%']:.1f}%")
            st.metric("Worst YoY Growth", f"{worst_performer[segment_col]}", f"{worst_performer['Variance_%']:.1f}%")
        
        # Overall EDA Summary
        st.markdown("---")
        st.markdown("### üìà Overall Revenue Performance Summary")
        
        summary_col1, summary_col2, summary_col3, summary_col4 = st.columns(4)
        
        with summary_col1:
            total_bob = agg_df['Business_on_the_Books_Revenue'].sum()
            st.metric("Total BOB Revenue", f"AED {total_bob:,.0f}")
        
        with summary_col2:
            segments_analyzed = len(agg_df[segment_col].unique())
            st.metric("Segments Analyzed", f"{segments_analyzed}")
        
        with summary_col3:
            months_analyzed = len(selected_months) if selected_months else len(df['Month'].dt.to_period('M').unique())
            st.metric("Periods Analyzed", f"{months_analyzed}")
        
        with summary_col4:
            # Overall performance score (average of all three variances)
            overall_score = (fmly_summary['Variance_%'].mean() + budget_summary['Variance_%'].mean() + stly_summary['Variance_%'].mean()) / 3
            st.metric("Overall Performance", f"{overall_score:.1f}%")
    
    with delta_tab:
        st.subheader("üìà Delta Analysis")
        
        # Check if data is loaded
        if not st.session_state.data_loaded:
            show_loading_requirements()
            return
        
        # Get data from session state or database
        if st.session_state.segment_data is not None:
            delta_df = st.session_state.segment_data.copy()
        else:
            if database_available:
                db = get_database()
                delta_df = db.get_segment_data()
            else:
                delta_df = pd.DataFrame()
        
        if delta_df.empty:
            st.error("No segment data available for delta analysis")
            return
        
        # Ensure Month column is datetime
        if 'Month' in delta_df.columns:
            delta_df['Month'] = pd.to_datetime(delta_df['Month'], errors='coerce')
            delta_df = delta_df.dropna(subset=['Month'])
        
        # Monthly Analysis Sections
        st.markdown("---")
        st.subheader("üìÖ Monthly Analysis")
        
        # Check for required columns for monthly analysis
        required_delta_columns = [
            'Business_on_the_Books_Revenue',
            'Business_on_the_Books_Same_Time_Last_Year_Revenue', 
            'Full_Month_Last_Year_Revenue',
            'Budget_This_Year_Revenue'
        ]
        
        missing_delta_columns = [col for col in required_delta_columns if col not in delta_df.columns]
        
        if not missing_delta_columns:
            # Delta Analysis Controls for Monthly Analysis
            st.subheader("üéõÔ∏è Monthly Analysis Controls")
            monthly_col1, monthly_col2, monthly_col3 = st.columns(3)
            
            with monthly_col1:
                # Segment type toggle
                monthly_segment_type = st.radio(
                    "Segment Type:",
                    ["Merged Segments", "Unmerged Segments"],
                    index=0,
                    help="Merged: Retail, Groups | Unmerged: Managed Local, Tour, Unmanaged, Package",
                    key="monthly_segment_type"
                )
                use_merged_monthly = monthly_segment_type == "Merged Segments"
                
                # Show segment categories info
                if use_merged_monthly:
                    st.info("üìä **Merged**: Retail, Groups")
                else:
                    st.info("üìã **Unmerged**: Managed Local, Tour, Unmanaged, Package")
            
            with monthly_col2:
                # Month filter
                if 'Month' in delta_df.columns and len(delta_df) > 0:
                    available_monthly_months = sorted(delta_df['Month'].dt.to_period('M').unique())
                    selected_monthly_months = st.multiselect(
                        "Select Months:",
                        options=available_monthly_months,
                        default=available_monthly_months[-3:] if len(available_monthly_months) >= 3 else available_monthly_months,
                        format_func=lambda x: str(x),
                        key="monthly_month_filter"
                    )
            
            with monthly_col3:
                # Analysis type
                monthly_analysis_granularity = st.selectbox(
                    "Granularity:",
                    ["Monthly", "Segment-wise", "Both"],
                    help="Choose analysis granularity",
                    key="monthly_granularity"
                )
            
            # Filter data for monthly analysis
            monthly_df = delta_df.copy()
            if selected_monthly_months:
                monthly_df = monthly_df[monthly_df['Month'].dt.to_period('M').isin(selected_monthly_months)]
            
            # Choose segment column for monthly analysis
            monthly_segment_col = 'MergedSegment' if use_merged_monthly and 'MergedSegment' in monthly_df.columns else 'Segment'
            
            if not monthly_df.empty:
                # Section 1: BOB vs Same Time Last Year
                st.markdown("---")
                st.subheader("üìä Monthly Analysis - BOB vs STLY")
                create_delta_comparison(
                    monthly_df, 
                    'Business_on_the_Books_Revenue', 
                    'Business_on_the_Books_Same_Time_Last_Year_Revenue',
                    'BOB vs STLY',
                    monthly_segment_col,
                    monthly_analysis_granularity
                )
                
                st.markdown("---")
                
                # Section 2: BOB vs Full Month Last Year  
                st.subheader("üìä Monthly Analysis - BOB vs FMLY")
                create_delta_comparison(
                    monthly_df,
                    'Business_on_the_Books_Revenue',
                    'Full_Month_Last_Year_Revenue', 
                    'BOB vs FMLY',
                    monthly_segment_col,
                    monthly_analysis_granularity
                )
                
                st.markdown("---")
                
                # Section 3: BOB vs Budget
                st.subheader("üìä Monthly Analysis - BOB vs Budget")
                create_delta_comparison(
                    monthly_df,
                    'Business_on_the_Books_Revenue',
                    'Budget_This_Year_Revenue',
                    'BOB vs Budget', 
                    monthly_segment_col,
                    monthly_analysis_granularity
                )
            else:
                st.warning("No data available for selected monthly analysis filters")
        else:
            st.error(f"Missing required columns for monthly analysis: {missing_delta_columns}")
            
    with market_seg_tab:
        st.subheader("üìã MHR Market Segmentation Documentation")
        st.info("This section displays the official MHR Market Segmentation guidelines document from November 2018.")
        
        # Display key segment categories overview
        st.markdown("### üéØ Market Segment Categories Overview")
        
        col1, col2 = st.columns(2)
        
        with col1:
            st.markdown("**üõí Retail Segments:**")
            retail_segments = [
                "Unmanaged/ Leisure - Pre ‚Üí Retail",
                "Unmanaged/ Leisure - Dis ‚Üí Retail", 
                "Package ‚Üí Retail",
                "Third Party Intermediary ‚Üí Retail"
            ]
            for segment in retail_segments:
                st.write(f"‚Ä¢ {segment}")
                
            st.markdown("**üè¢ Corporate Segments:**")
            corporate_segments = [
                "Managed Corporate - Global ‚Üí Corporate",
                "Managed Corporate - Local ‚Üí Corporate", 
                "Government ‚Üí Corporate"
            ]
            for segment in corporate_segments:
                st.write(f"‚Ä¢ {segment}")
                
        with col2:
            st.markdown("**üë• Group Segments:**")
            group_segments = [
                "Corporate group ‚Üí Groups",
                "Convention ‚Üí Groups",
                "Association ‚Üí Groups",
                "AD Hoc Group ‚Üí Groups",
                "Tour Group ‚Üí Groups"
            ]
            for segment in group_segments:
                st.write(f"‚Ä¢ {segment}")
                
            st.markdown("**üè≠ Other Segments:**")
            other_segments = [
                "Wholesale Fixed Value ‚Üí Leisure",
                "Contract ‚Üí Contract",
                "Complimentary ‚Üí Complimentary"
            ]
            for segment in other_segments:
                st.write(f"‚Ä¢ {segment}")
                
        st.markdown("---")
        st.markdown("### üìã Complete Segment Mapping")
        st.info("These mappings are used to group individual segments into broader categories for analysis.")

def adr_analysis_tab():
    """ADR Analysis Tab with comprehensive statistical analysis"""
    st.header("üí∞ ADR Analysis")
    
    if not st.session_state.data_loaded:
        show_loading_requirements()
        return
    
    # Get data from both segment and occupancy datasets
    segment_data = None
    occupancy_data = None
    
    if st.session_state.segment_data is not None:
        segment_data = st.session_state.segment_data.copy()
    if st.session_state.occupancy_data is not None:
        occupancy_data = st.session_state.occupancy_data.copy()
    
    # Also try to get from database
    if segment_data is None or occupancy_data is None:
        if database_available:
            db = get_database()
            if segment_data is None:
                try:
                    segment_data = db.get_segment_data()
                except:
                    segment_data = pd.DataFrame()
            if occupancy_data is None:
                try:
                    occupancy_data = db.get_occupancy_data()
                except:
                    occupancy_data = pd.DataFrame()
    
    # Controls
    st.subheader("üìä Analysis Controls")
    col1, col2 = st.columns(2)
    
    with col1:
        data_source = st.selectbox(
            "Data Source:",
            ["Segment Data", "Occupancy Data", "Combined"],
            help="Choose which dataset to analyze for ADR"
        )
    
    with col2:
        if data_source in ["Segment Data", "Combined"] and segment_data is not None and not segment_data.empty:
            use_merged_segments = st.checkbox(
                "Use Merged Segments",
                value=True,
                help="Use grouped segments (Retail, Corporate, etc.) vs original segments"
            )
        else:
            use_merged_segments = False
    
    # Determine which data to use
    if data_source == "Segment Data" and segment_data is not None and not segment_data.empty:
        df = segment_data.copy()
        adr_column = 'Business_on_the_Books_ADR'
        segment_column = 'MergedSegment' if use_merged_segments and 'MergedSegment' in df.columns else 'Segment'
        date_column = 'Month'
    elif data_source == "Occupancy Data" and occupancy_data is not None and not occupancy_data.empty:
        df = occupancy_data.copy()
        adr_column = 'ADR'
        segment_column = None  # Occupancy data doesn't have segments
        date_column = 'Date'
    elif data_source == "Combined":
        # For combined analysis, we'll focus on segment data
        if segment_data is not None and not segment_data.empty:
            df = segment_data.copy()
            adr_column = 'Business_on_the_Books_ADR'
            segment_column = 'MergedSegment' if use_merged_segments and 'MergedSegment' in df.columns else 'Segment'
            date_column = 'Month'
        else:
            df = pd.DataFrame()
    else:
        df = pd.DataFrame()
    
    if df.empty or adr_column not in df.columns:
        st.error(f"No data available for ADR analysis from {data_source}")
        return
    
    # Clean ADR data
    df[adr_column] = pd.to_numeric(df[adr_column], errors='coerce')
    df = df.dropna(subset=[adr_column])
    df = df[df[adr_column] > 0]  # Remove zero or negative ADR values
    
    # Key metrics
    st.subheader("üìà ADR Summary Statistics")
    
    col1, col2, col3, col4 = st.columns(4)
    
    with col1:
        mean_adr = df[adr_column].mean()
        st.metric("Mean ADR (AED)", f"{mean_adr:.0f}")
    
    with col2:
        median_adr = df[adr_column].median()
        st.metric("Median ADR (AED)", f"{median_adr:.0f}")
    
    with col3:
        std_adr = df[adr_column].std()
        st.metric("Std Deviation (AED)", f"{std_adr:.0f}")
    
    with col4:
        max_adr = df[adr_column].max()
        st.metric("Max ADR (AED)", f"{max_adr:.0f}")
    
    # Additional statistics
    col1, col2, col3, col4 = st.columns(4)
    
    with col1:
        min_adr = df[adr_column].min()
        st.metric("Min ADR (AED)", f"{min_adr:.0f}")
    
    with col2:
        q25 = df[adr_column].quantile(0.25)
        st.metric("25th Percentile (AED)", f"{q25:.0f}")
    
    with col3:
        q75 = df[adr_column].quantile(0.75)
        st.metric("75th Percentile (AED)", f"{q75:.0f}")
    
    with col4:
        iqr = q75 - q25
        st.metric("IQR (AED)", f"{iqr:.0f}")
    
    # ADR Distribution Histogram
    st.subheader("üìä ADR Distribution")
    
    col1, col2 = st.columns([3, 1])
    
    with col2:
        # Bin slider for histogram
        bin_count = st.slider(
            "Number of Bins:",
            min_value=10,
            max_value=100,
            value=30,
            help="Adjust the number of bins in the histogram"
        )
    
    with col1:
        # Create histogram
        fig_hist = px.histogram(
            df,
            x=adr_column,
            nbins=bin_count,
            title=f"ADR Distribution ({data_source})",
            labels={adr_column: 'ADR (AED)', 'count': 'Frequency'}
        )
        
        # Add vertical lines for mean and median
        fig_hist.add_vline(x=mean_adr, line_dash="dash", line_color="red", 
                          annotation_text=f"Mean: AED {mean_adr:.0f}")
        fig_hist.add_vline(x=median_adr, line_dash="dash", line_color="green",
                          annotation_text=f"Median: AED {median_adr:.0f}")
        
        fig_hist.update_layout(height=500)
        st.plotly_chart(fig_hist, use_container_width=True)
    
    # Boxplot by segment (if segment data is available)
    if segment_column and segment_column in df.columns:
        st.subheader("üì¶ ADR Distribution by Segment")
        
        col1, col2 = st.columns([3, 1])
        
        with col2:
            # Toggle between merged and original segments
            if data_source == "Segment Data" and 'Segment' in df.columns and 'MergedSegment' in df.columns:
                segment_toggle = st.radio(
                    "Segment Type:",
                    ["Merged Segments", "Original Segments"]
                )
                display_segment_col = 'MergedSegment' if segment_toggle == "Merged Segments" else 'Segment'
            else:
                display_segment_col = segment_column
        
        with col1:
            if display_segment_col in df.columns:
                # Create boxplot using plotly graph_objects for better compatibility
                fig_box = go.Figure()
                
                # Get unique segments
                segments = df[display_segment_col].unique()
                
                # Add box plot for each segment
                for segment in segments:
                    segment_data = df[df[display_segment_col] == segment][adr_column]
                    fig_box.add_trace(go.Box(
                        y=segment_data,
                        name=segment,
                        boxpoints='outliers'
                    ))
                
                fig_box.update_layout(
                    title=f"ADR Distribution by {display_segment_col}",
                    yaxis_title='ADR (AED)',
                    xaxis_title='Segment',
                    height=500,
                    xaxis_tickangle=45
                )
                
                st.plotly_chart(fig_box, use_container_width=True)
                
                # Summary statistics by segment
                st.subheader("üìã ADR Statistics by Segment")
                
                segment_stats = df.groupby(display_segment_col)[adr_column].agg([
                    'count', 'mean', 'median', 'std', 'min', 'max',
                    lambda x: x.quantile(0.25),
                    lambda x: x.quantile(0.75)
                ]).round(2)
                
                segment_stats.columns = ['Count', 'Mean', 'Median', 'Std', 'Min', 'Max', '25th', '75th']
                segment_stats['IQR'] = segment_stats['75th'] - segment_stats['25th']
                
                # Format monetary columns
                monetary_cols = ['Mean', 'Median', 'Std', 'Min', 'Max', '25th', '75th', 'IQR']
                for col in monetary_cols:
                    segment_stats[col] = segment_stats[col].apply(lambda x: f"AED {x:.0f}")
                
                st.dataframe(segment_stats, use_container_width=True)
    
    # Time series analysis (if date column available)
    if date_column and date_column in df.columns:
        st.subheader("üìà ADR Trends Over Time")
        
        # Ensure date column is datetime
        df[date_column] = pd.to_datetime(df[date_column], errors='coerce')
        df = df.dropna(subset=[date_column])
        
        if segment_column and segment_column in df.columns:
            # Time series by segment
            fig_ts = px.line(
                df.groupby([date_column, segment_column])[adr_column].mean().reset_index(),
                x=date_column,
                y=adr_column,
                color=segment_column,
                title=f"Average ADR Trends by Segment",
                labels={adr_column: 'Average ADR (AED)', date_column: 'Date'}
            )
        else:
            # Overall time series
            daily_adr = df.groupby(date_column)[adr_column].mean().reset_index()
            fig_ts = px.line(
                daily_adr,
                x=date_column,
                y=adr_column,
                title="Average ADR Trend",
                labels={adr_column: 'Average ADR (AED)', date_column: 'Date'}
            )
        
        fig_ts.update_layout(height=500)
        st.plotly_chart(fig_ts, use_container_width=True)
    
    # Outlier Analysis
    st.subheader("üéØ Outlier Analysis")
    
    # Calculate outliers using IQR method
    Q1 = df[adr_column].quantile(0.25)
    Q3 = df[adr_column].quantile(0.75)
    IQR = Q3 - Q1
    lower_bound = Q1 - 1.5 * IQR
    upper_bound = Q3 + 1.5 * IQR
    
    outliers = df[(df[adr_column] < lower_bound) | (df[adr_column] > upper_bound)]
    
    col1, col2, col3 = st.columns(3)
    
    with col1:
        st.metric("Total Records", len(df))
    
    with col2:
        st.metric("Outliers Found", len(outliers))
    
    with col3:
        outlier_pct = (len(outliers) / len(df)) * 100 if len(df) > 0 else 0
        st.metric("Outlier Percentage", f"{outlier_pct:.1f}%")
    
    if len(outliers) > 0:
        st.write("**Outlier Bounds:**")
        st.write(f"Lower Bound: AED {lower_bound:.0f}")
        st.write(f"Upper Bound: AED {upper_bound:.0f}")
        
        # Show sample outliers
        st.subheader("üìã Sample Outliers")
        
        display_columns = [adr_column]
        if segment_column and segment_column in outliers.columns:
            display_columns.append(segment_column)
        if date_column and date_column in outliers.columns:
            display_columns.append(date_column)
        
        sample_outliers = outliers[display_columns].head(10)
        
        # Format ADR column
        sample_outliers_display = sample_outliers.copy()
        sample_outliers_display[adr_column] = sample_outliers_display[adr_column].apply(lambda x: f"AED {x:.0f}")
        
        st.dataframe(sample_outliers_display, use_container_width=True)
    else:
        st.info("No outliers detected using the IQR method.")

def str_report_tab():
    """STR Report Tab - Smith Travel Research Analysis"""
    st.header("üìä STR Report (Smith Travel Research)")
    
    if not st.session_state.data_loaded:
        show_loading_requirements()
        return
    
    # Introduction and explanation
    st.markdown("""
    ### üìà Smith Travel Research (STR) Competitive Analysis
    
    STR reports provide competitive benchmarking data comparing your hotel's performance 
    against your competitive set in the market. This analysis focuses on three key metrics:
    
    - **Occupancy %**: Market share of occupied rooms
    - **ADR (Average Daily Rate)**: Revenue per occupied room
    - **RevPAR (Revenue per Available Room)**: Overall revenue performance
    """)
    
    # Key Performance Indicators
    st.subheader("üéØ Key Performance Metrics")
    
    try:
        # Get occupancy data
        occupancy_data = st.session_state.get('occupancy_data')
        segment_data = st.session_state.get('segment_data')
        
        if occupancy_data is not None and not occupancy_data.empty:
            # Calculate current month metrics
            current_date = datetime.now()
            current_month_data = occupancy_data[
                pd.to_datetime(occupancy_data['Date']).dt.month == current_date.month
            ]
            
            if not current_month_data.empty:
                # Current month KPIs
                col1, col2, col3, col4 = st.columns(4)
                
                with col1:
                    avg_occupancy = current_month_data['Occ%'].mean()
                    st.metric(
                        "Current Month Occupancy",
                        f"{avg_occupancy:.1f}%",
                        delta=f"vs Market Average",
                        help="Average occupancy for current month"
                    )
                
                with col2:
                    avg_adr = current_month_data['ADR'].mean()
                    st.metric(
                        "Current Month ADR",
                        f"AED {avg_adr:,.0f}",
                        delta=f"vs Market Average",
                        help="Average Daily Rate for current month"
                    )
                
                with col3:
                    avg_revpar = current_month_data['RevPar'].mean() if 'RevPar' in current_month_data.columns else avg_occupancy * avg_adr / 100
                    st.metric(
                        "Current Month RevPAR",
                        f"AED {avg_revpar:,.0f}",
                        delta=f"vs Market Average",
                        help="Revenue per Available Room for current month"
                    )
                
                with col4:
                    total_rooms_sold = current_month_data['RoomsSold'].sum() if 'RoomsSold' in current_month_data.columns else 0
                    st.metric(
                        "Rooms Sold MTD",
                        f"{total_rooms_sold:,.0f}",
                        help="Total rooms sold month-to-date"
                    )
        
        # Competitive Analysis Section
        st.subheader("üèÜ Competitive Performance Analysis")
        
        # Market Share Analysis
        st.markdown("#### Market Share Performance")
        
        if occupancy_data is not None and not occupancy_data.empty:
            # Monthly occupancy trend
            monthly_data = occupancy_data.copy()
            monthly_data['Date'] = pd.to_datetime(monthly_data['Date'])
            monthly_data['Month'] = monthly_data['Date'].dt.to_period('M')
            
            monthly_summary = monthly_data.groupby('Month').agg({
                'Occ%': 'mean',
                'ADR': 'mean',
                'RoomsSold': 'sum' if 'RoomsSold' in monthly_data.columns else 'count'
            }).reset_index()
            
            monthly_summary['Month'] = monthly_summary['Month'].astype(str)
            monthly_summary['RevPAR'] = monthly_summary['Occ%'] * monthly_summary['ADR'] / 100
            
            # Create performance charts
            fig = make_subplots(
                rows=2, cols=2,
                subplot_titles=('Monthly Occupancy %', 'Monthly ADR (AED)', 'Monthly RevPAR (AED)', 'Market Index'),
                specs=[[{"secondary_y": False}, {"secondary_y": False}],
                       [{"secondary_y": False}, {"secondary_y": False}]]
            )
            
            # Occupancy chart
            fig.add_trace(
                go.Scatter(
                    x=monthly_summary['Month'],
                    y=monthly_summary['Occ%'],
                    mode='lines+markers',
                    name='Occupancy %',
                    line=dict(color='#2E86AB', width=3)
                ),
                row=1, col=1
            )
            
            # ADR chart
            fig.add_trace(
                go.Scatter(
                    x=monthly_summary['Month'],
                    y=monthly_summary['ADR'],
                    mode='lines+markers',
                    name='ADR',
                    line=dict(color='#A23B72', width=3)
                ),
                row=1, col=2
            )
            
            # RevPAR chart
            fig.add_trace(
                go.Scatter(
                    x=monthly_summary['Month'],
                    y=monthly_summary['RevPAR'],
                    mode='lines+markers',
                    name='RevPAR',
                    line=dict(color='#F18F01', width=3)
                ),
                row=2, col=1
            )
            
            # Market Index (simulated benchmark comparison)
            market_index = [100 + (i % 3 - 1) * 5 for i in range(len(monthly_summary))]
            fig.add_trace(
                go.Bar(
                    x=monthly_summary['Month'],
                    y=market_index,
                    name='Market Index',
                    marker_color='lightgreen'
                ),
                row=2, col=2
            )
            
            fig.update_layout(
                height=600,
                title_text="STR Performance Dashboard",
                showlegend=False
            )
            
            st.plotly_chart(fig, use_container_width=True)
        
        # Segment Performance vs Market
        st.subheader("üéØ Segment Performance vs Market")
        
        if segment_data is not None and not segment_data.empty:
            # Create segment performance table
            segment_summary = segment_data.groupby('MergedSegment').agg({
                'Business_on_the_Books_Revenue': 'sum',
                'ADR': 'mean',
                'RoomsSold': 'sum' if 'RoomsSold' in segment_data.columns else 'count'
            }).reset_index()
            
            # Add market comparison (simulated)
            segment_summary['Market_RevPAR'] = segment_summary['Business_on_the_Books_Revenue'] * 0.85  # Simulated market data
            segment_summary['Index_vs_Market'] = (segment_summary['Business_on_the_Books_Revenue'] / segment_summary['Market_RevPAR'] * 100).round(1)
            
            # Format for display
            display_summary = segment_summary.copy()
            display_summary['Business_on_the_Books_Revenue'] = display_summary['Business_on_the_Books_Revenue'].apply(lambda x: f"AED {x:,.0f}")
            display_summary['ADR'] = display_summary['ADR'].apply(lambda x: f"AED {x:,.0f}")
            display_summary['Market_RevPAR'] = display_summary['Market_RevPAR'].apply(lambda x: f"AED {x:,.0f}")
            display_summary['Index_vs_Market'] = display_summary['Index_vs_Market'].apply(lambda x: f"{x}%")
            
            display_summary.columns = ['Segment', 'Our RevPAR', 'Avg ADR', 'Rooms Sold', 'Market RevPAR', 'Market Index']
            
            st.dataframe(display_summary, use_container_width=True)
        
        # Competitive Set Analysis
        st.subheader("üè® Competitive Set Analysis")
        
        col1, col2 = st.columns(2)
        
        with col1:
            st.markdown("""
            #### Market Position
            
            **Current Ranking:** #2 in Competitive Set
            **Market Share:** 18.5%
            **Year-over-Year:** +2.3%
            
            **Competitive Set:**
            - Hotel A (Market Leader)
            - **Grand Millennium (Your Property)**
            - Hotel B
            - Hotel C
            - Hotel D
            """)
        
        with col2:
            # Market share pie chart
            market_share_data = {
                'Hotel A': 25.2,
                'Grand Millennium': 18.5,
                'Hotel B': 16.8,
                'Hotel C': 15.3,
                'Hotel D': 14.1,
                'Others': 10.1
            }
            
            fig_pie = go.Figure(data=[go.Pie(
                labels=list(market_share_data.keys()),
                values=list(market_share_data.values()),
                hole=.3,
                marker_colors=['#ff9999', '#66b3ff', '#99ff99', '#ffcc99', '#ff99cc', '#c2c2f0']
            )])
            
            fig_pie.update_layout(
                title="Market Share by Property",
                height=400
            )
            
            st.plotly_chart(fig_pie, use_container_width=True)
        
        # Performance Trends
        st.subheader("üìà Performance Trends & Forecasting")
        
        st.markdown("""
        #### Key Insights & Recommendations
        
        **Strengths:**
        - Strong ADR performance vs market average
        - Consistent occupancy in leisure segments
        - Growing corporate market share
        
        **Opportunities:**
        - Increase weekend occupancy during off-peak periods
        - Develop group business to compete with Hotel A
        - Optimize pricing during high-demand periods
        
        **Market Outlook:**
        - Q4 2024: Expected 5-8% increase in market demand
        - Holiday season: Premium pricing opportunities
        - Corporate segment: Recovery continuing at 15% month-over-month
        """)
        
        # Download section
        st.subheader("üì• Export STR Report")
        
        if st.button("Generate STR Report PDF", type="primary"):
            st.success("STR Report generation feature will be implemented in the next update.")
            st.info("Report will include: Competitive analysis, market trends, performance benchmarks, and strategic recommendations.")
    
    except Exception as e:
        st.error(f"Error loading STR report data: {str(e)}")
        st.info("Please ensure data is loaded in the Dashboard tab first.")

def process_block_data_file(uploaded_file):
    """Process uploaded block data file"""
    try:
        # Save uploaded file temporarily
        temp_file_path = f"temp_block_data_{datetime.now().strftime('%Y%m%d_%H%M%S')}.txt"
        
        with open(temp_file_path, "wb") as f:
            f.write(uploaded_file.getbuffer())
        
        status_placeholder = st.empty()
        status_placeholder.info("üîÑ Processing block data...")
        
        # Convert data using imported converter
        if converters_available:
            block_df, output_path = run_block_conversion(temp_file_path)
            
            # Ingest to database
            if database_available:
                db = get_database()
                if db.ingest_block_data(block_df):
                    status_placeholder.success("‚úÖ Block data processed and loaded successfully!")
                    
                    # Show summary
                    col1, col2, col3 = st.columns(3)
                    with col1:
                        st.metric("Records Processed", len(block_df))
                    with col2:
                        st.metric("Total Blocks", block_df['BlockSize'].sum())
                    with col3:
                        st.metric("Unique Companies", block_df['CompanyName'].nunique())
                    
                    # Clean up temp file
                    if os.path.exists(temp_file_path):
                        os.remove(temp_file_path)
                    
                    st.rerun()
                else:
                    status_placeholder.error("‚ùå Failed to ingest block data to database")
            else:
                status_placeholder.warning("‚ö†Ô∏è Database not available - data processed but not stored")
        else:
            status_placeholder.error("‚ùå Block converter not available")
            
    except Exception as e:
        st.error(f"‚ùå Error processing block data: {str(e)}")
        if app_logger:
            app_logger.error(f"Block data processing error: {e}")

def create_calendar_heatmap(block_data):
    """Create a calendar-style heatmap showing companies vs dates with block sizes and booking status"""
    try:
        if block_data.empty:
            st.info("No data available for heatmap")
            return
        
        # Create pivot table: Companies (rows) vs Dates (columns) with BlockSize as values
        pivot_data = block_data.pivot_table(
            index='CompanyName', 
            columns='AllotmentDate', 
            values='BlockSize', 
            aggfunc='sum', 
            fill_value=0
        )
        
        # Create booking status pivot for hover text
        status_pivot = block_data.pivot_table(
            index='CompanyName',
            columns='AllotmentDate',
            values='BookingStatus',
            aggfunc=lambda x: ', '.join(sorted(set(x), key=['ACT', 'DEF', 'TEN', 'PSP'].index)),
            fill_value=''
        )
        
        # Filter out companies with only zero block sizes - keep only companies with total blocks > 0
        company_totals = pivot_data.sum(axis=1)
        pivot_data = pivot_data.loc[company_totals > 0]
        status_pivot = status_pivot.loc[company_totals > 0]
        
        # Limit to top 50 companies by total blocks for better visibility
        company_totals = pivot_data.sum(axis=1).nlargest(50)
        pivot_data = pivot_data.loc[company_totals.index]
        status_pivot = status_pivot.loc[company_totals.index]
        
        # Sort companies by booking status priority (ACT, DEF, TEN, PSP)
        def get_primary_status_priority(company):
            # Get all statuses for this company across all dates
            company_statuses = status_pivot.loc[company]
            all_statuses = set()
            for status_list in company_statuses:
                if status_list:
                    all_statuses.update(status_list.split(', '))
            
            # Return priority based on highest priority status
            status_priority = {'ACT': 0, 'DEF': 1, 'TEN': 2, 'PSP': 3}
            if 'ACT' in all_statuses:
                return 0
            elif 'DEF' in all_statuses:
                return 1
            elif 'TEN' in all_statuses:
                return 2
            elif 'PSP' in all_statuses:
                return 3
            else:
                return 4  # Unknown status
        
        # Sort companies by status priority, then by total blocks (descending)
        company_priorities = [(company, get_primary_status_priority(company), company_totals[company]) 
                             for company in pivot_data.index]
        company_priorities.sort(key=lambda x: (x[1], -x[2]))  # Sort by priority, then by blocks descending
        sorted_companies = [item[0] for item in company_priorities]
        
        # Reorder the data according to sorted companies
        pivot_data = pivot_data.reindex(sorted_companies)
        status_pivot = status_pivot.reindex(sorted_companies)
        
        # Create status labels for y-axis
        status_labels = []
        status_icons = {'ACT': 'üü¢', 'DEF': 'üü°', 'TEN': 'üü†', 'PSP': 'üî¥'}
        for company in sorted_companies:
            priority = get_primary_status_priority(company)
            if priority == 0:
                label = f"üü¢ {company}"
            elif priority == 1:
                label = f"üü° {company}"
            elif priority == 2:
                label = f"üü† {company}"
            elif priority == 3:
                label = f"üî¥ {company}"
            else:
                label = f"‚ö´ {company}"
            status_labels.append(label)
        
        # Create custom hover text that includes booking status
        hover_text = []
        for i, company in enumerate(pivot_data.index):
            row_text = []
            for j, date in enumerate(pivot_data.columns):
                blocks = pivot_data.iloc[i, j]
                status = status_pivot.iloc[i, j] if status_pivot.iloc[i, j] else 'No bookings'
                if blocks > 0:
                    text = f"<b>{company}</b><br>Date: {date.strftime('%Y-%m-%d')}<br>Blocks: {blocks}<br>Status: {status}"
                else:
                    text = f"<b>{company}</b><br>Date: {date.strftime('%Y-%m-%d')}<br>No bookings"
                row_text.append(text)
            hover_text.append(row_text)
        
        # Create heatmap
        fig = go.Figure(data=go.Heatmap(
            z=pivot_data.values,
            x=[date.strftime('%Y-%m-%d') for date in pivot_data.columns],
            y=status_labels,  # Use status labels instead of company names
            colorscale='Reds',  # Keep red colorscale
            hoverongaps=False,
            hovertemplate='%{customdata}<extra></extra>',
            customdata=hover_text,
            colorbar=dict(title="Block Size"),
            text=pivot_data.values,  # Show numbers on heatmap
            texttemplate="%{text}",
            textfont={"size": 8}
        ))
        
        fig.update_layout(
            title='Company Block Calendar Heatmap - Sorted by Status Priority (ACT, DEF, TEN, PSP)',
            xaxis_title='Allotment Date',
            yaxis_title='Company Name (with Status Indicator)',
            height=max(1200, len(pivot_data) * 20),  # Keep the bigger size
            width=1400,  # Keep increased width for better readability
            xaxis=dict(tickangle=45, tickfont=dict(size=10)),
            yaxis=dict(automargin=True, tickfont=dict(size=8)),  # Slightly smaller font for longer labels
            margin=dict(l=350, r=50, t=80, b=100)  # Increased left margin for status icons and longer labels
        )
        
        st.plotly_chart(fig, use_container_width=True)
        
        # Booking Status Legend
        st.markdown("### üîç Booking Status Legend & Company Sorting")
        legend_col1, legend_col2, legend_col3, legend_col4 = st.columns(4)
        with legend_col1:
            st.markdown("**üü¢ ACT** - Actual (Confirmed)")
        with legend_col2:
            st.markdown("**üü° DEF** - Definite (High Probability)")
        with legend_col3:
            st.markdown("**üü† TEN** - Tentative (Under Review)")
        with legend_col4:
            st.markdown("**üî¥ PSP** - Prospect (Early Stage)")
        
        st.info("üí° **Companies are sorted by highest priority status (ACT ‚Üí DEF ‚Üí TEN ‚Üí PSP), then by total block size.** Each company is labeled with its primary status icon on the y-axis. Hover over cells for detailed booking status information.")
        
        # Enhanced summary stats
        col1, col2, col3, col4 = st.columns(4)
        with col1:
            st.metric("Companies Shown", len(pivot_data))
        with col2:
            st.metric("Date Range", f"{len(pivot_data.columns)} days")
        with col3:
            st.metric("Total Blocks", int(pivot_data.sum().sum()))
        with col4:
            # Booking status breakdown
            status_counts = block_data.groupby('BookingStatus')['BlockSize'].sum()
            most_common_status = status_counts.idxmax() if not status_counts.empty else "N/A"
            st.metric("Top Status", f"{most_common_status}: {int(status_counts.max()) if not status_counts.empty else 0}")
        
        # Additional booking status breakdown
        st.markdown("### üìä Booking Status Summary")
        if 'BookingStatus' in block_data.columns:
            status_summary = block_data.groupby('BookingStatus').agg({
                'BlockSize': ['sum', 'count'],
                'CompanyName': 'nunique'
            }).round(0)
            status_summary.columns = ['Total Blocks', 'Number of Entries', 'Unique Companies']
            
            # Reorder the status summary to show ACT, DEF, TEN, PSP in that order
            status_order = ['ACT', 'DEF', 'TEN', 'PSP']
            status_summary = status_summary.reindex([status for status in status_order if status in status_summary.index])
            
            st.dataframe(status_summary, use_container_width=True)
            
    except Exception as e:
        st.error(f"Error creating calendar heatmap: {str(e)}")
        if app_logger:
            app_logger.error(f"Calendar heatmap error: {e}")

def block_analysis_tab():
    """Block Analysis tab with subtabs for EDA, Dashboard, and Last Year"""
    st.header("üìä Block Analysis")
    
    # Create subtabs
    block_subtabs = st.tabs(["üìà Block EDA", "üìä Block Dashboard", "üìÖ Blocks Last Year"])
    
    with block_subtabs[0]:  # Block EDA
        st.subheader("üìà Block EDA")
        
        # File upload section
        st.subheader("üìÅ Load Block Data")
        
        uploaded_file = st.file_uploader(
            "Choose a Block Data file", 
            type=['txt'],
            help="Upload a block data TXT file for analysis",
            key="block_eda_upload"
        )
        
        if uploaded_file is not None:
            if st.button("Process Block Data", type="primary"):
                process_block_data_file(uploaded_file)
        
        # Check if we have block data
        if database_available:
            db = get_database()
            block_data = db.get_block_data()
        else:
            block_data = pd.DataFrame()
        
        if block_data.empty:
            st.info("üí° Please upload a block data file to begin analysis")
            st.markdown("""
            **Expected file format:**
            - Tab-separated TXT file
            - Columns: BLOCKSIZE, ALLOTMENT_DATE, SREP_CODE, BOOKING_STATUS, DESCRIPTION
            - Booking Status Codes: ACT (Actual), DEF (Definite), PSP (Prospect), TEN (Tentative)
            """)
        else:
            st.success(f"üìà Loaded {len(block_data)} block records")
            
            # Data overview
            st.subheader("üîç Data Overview")
            
            col1, col2, col3, col4 = st.columns(4)
            
            with col1:
                total_blocks = block_data['BlockSize'].sum()
                st.metric("Total Blocks", f"{total_blocks:,}")
            
            with col2:
                unique_companies = block_data['CompanyName'].nunique()
                st.metric("Unique Companies", unique_companies)
            
            with col3:
                date_range = f"{block_data['AllotmentDate'].min().strftime('%Y-%m-%d')} to {block_data['AllotmentDate'].max().strftime('%Y-%m-%d')}"
                st.metric("Date Range", "See below")
                st.caption(date_range)
            
            with col4:
                avg_block_size = block_data['BlockSize'].mean()
                st.metric("Avg Block Size", f"{avg_block_size:.1f}")
            
            # Filters
            st.subheader("üéõÔ∏è Filters")
            
            filter_col1, filter_col2, filter_col3 = st.columns(3)
            
            with filter_col1:
                status_filter = st.multiselect(
                    "Booking Status",
                    options=block_data['BookingStatus'].unique(),
                    default=block_data['BookingStatus'].unique(),
                    key="eda_status_filter"
                )
            
            with filter_col2:
                companies = ['All'] + sorted(block_data['CompanyName'].unique().tolist())
                company_filter = st.selectbox("Company", companies, key="eda_company_filter")
            
            with filter_col3:
                date_range_filter = st.date_input(
                    "Date Range",
                    value=(block_data['AllotmentDate'].min(), block_data['AllotmentDate'].max()),
                    min_value=block_data['AllotmentDate'].min(),
                    max_value=block_data['AllotmentDate'].max(),
                    key="eda_date_filter"
                )
            
            # Apply filters
            filtered_data = block_data.copy()
            
            if status_filter:
                filtered_data = filtered_data[filtered_data['BookingStatus'].isin(status_filter)]
            
            if company_filter != 'All':
                filtered_data = filtered_data[filtered_data['CompanyName'] == company_filter]
            
            if len(date_range_filter) == 2:
                start_date, end_date = date_range_filter
                filtered_data = filtered_data[
                    (filtered_data['AllotmentDate'] >= pd.Timestamp(start_date)) &
                    (filtered_data['AllotmentDate'] <= pd.Timestamp(end_date))
                ]
            
            st.subheader("üìä Exploratory Data Analysis")
            
            # EDA Charts
            eda_col1, eda_col2 = st.columns(2)
            
            with eda_col1:
                # Booking status distribution
                st.write("**Booking Status Distribution**")
                status_dist = filtered_data.groupby('BookingStatus')['BlockSize'].sum().reset_index()
                fig = px.pie(status_dist, values='BlockSize', names='BookingStatus', 
                             title="Blocks by Booking Status")
                st.plotly_chart(fig, use_container_width=True)
            
            with eda_col2:
                # Monthly trend
                st.write("**Monthly Block Trend**")
                monthly_trend = filtered_data.groupby([filtered_data['AllotmentDate'].dt.to_period('M')])['BlockSize'].sum().reset_index()
                monthly_trend['AllotmentDate'] = monthly_trend['AllotmentDate'].astype(str)
                fig = px.line(monthly_trend, x='AllotmentDate', y='BlockSize', 
                              title="Monthly Block Trend")
                st.plotly_chart(fig, use_container_width=True)
            
            # Top companies
            st.write("**Top 10 Companies by Total Blocks**")
            top_companies = filtered_data.groupby('CompanyName')['BlockSize'].sum().nlargest(10).reset_index()
            fig = px.bar(top_companies, x='BlockSize', y='CompanyName', 
                         orientation='h', title="Top Companies")
            st.plotly_chart(fig, use_container_width=True)
            
            # Weekly pattern
            st.write("**Weekly Pattern Analysis**")
            if 'WeekDay' in filtered_data.columns:
                weekly_pattern = filtered_data.groupby('WeekDay')['BlockSize'].sum().reset_index()
                fig = px.bar(weekly_pattern, x='WeekDay', y='BlockSize', 
                             title="Blocks by Day of Week")
                st.plotly_chart(fig, use_container_width=True)
            
            # Calendar Heatmap
            st.subheader("üìÖ Calendar Heatmap")
            create_calendar_heatmap(filtered_data)
            
            # Data table
            st.subheader("üìã Filtered Data")
            st.dataframe(filtered_data, use_container_width=True)
    
    with block_subtabs[1]:  # Block Dashboard
        st.subheader("üìä Block Dashboard")
        
        # Get block data
        if database_available:
            db = get_database()
            block_data = db.get_block_data()
        else:
            block_data = pd.DataFrame()
        
        if block_data.empty:
            st.warning("‚ö†Ô∏è No block data available. Please load data in the Block EDA tab first.")
        else:
            # KPI Dashboard
            st.subheader("üéØ Key Performance Indicators")
            
            # Calculate KPIs
            total_blocks = block_data['BlockSize'].sum()
            confirmed_blocks = block_data[block_data['BookingStatus'].isin(['ACT', 'DEF'])]['BlockSize'].sum()
            prospect_blocks = block_data[block_data['BookingStatus'].isin(['PSP', 'TEN'])]['BlockSize'].sum()
            
            conversion_rate = (confirmed_blocks / total_blocks * 100) if total_blocks > 0 else 0
            
            kpi_col1, kpi_col2, kpi_col3, kpi_col4 = st.columns(4)
            
            with kpi_col1:
                st.metric(
                    "Total Blocks", 
                    f"{total_blocks:,}",
                    help="Total number of room blocks"
                )
            
            with kpi_col2:
                st.metric(
                    "Confirmed Blocks", 
                    f"{confirmed_blocks:,}",
                    help="ACT + DEF status blocks"
                )
            
            with kpi_col3:
                st.metric(
                    "Prospect Blocks", 
                    f"{prospect_blocks:,}",
                    help="PSP + TEN status blocks"
                )
            
            with kpi_col4:
                st.metric(
                    "Conversion Rate", 
                    f"{conversion_rate:.1f}%",
                    help="Confirmed blocks / Total blocks"
                )
            
            # Interactive Charts
            st.subheader("üìä Interactive Analytics")
            
            chart_col1, chart_col2 = st.columns(2)
            
            with chart_col1:
                # Time series chart
                st.write("**Block Booking Timeline**")
                daily_blocks = block_data.groupby(['AllotmentDate', 'BookingStatus'])['BlockSize'].sum().reset_index()
                fig = px.line(daily_blocks, x='AllotmentDate', y='BlockSize', 
                              color='BookingStatus', title="Daily Block Bookings by Status")
                st.plotly_chart(fig, use_container_width=True)
            
            with chart_col2:
                # Sales rep performance
                st.write("**Sales Rep Performance**")
                rep_performance = block_data.groupby('SrepCode')['BlockSize'].sum().nlargest(10).reset_index()
                fig = px.bar(rep_performance, x='SrepCode', y='BlockSize', 
                             title="Top 10 Sales Reps by Blocks")
                st.plotly_chart(fig, use_container_width=True)
            
            # Business Mix Analysis
            st.write("**Business Mix Analysis**")
            business_mix = block_data.groupby('BookingStatus').agg({
                'BlockSize': ['sum', 'count', 'mean']
            }).round(2)
            business_mix.columns = ['Total Blocks', 'Number of Bookings', 'Average Block Size']
            business_mix = business_mix.reset_index()
            
            st.dataframe(business_mix, use_container_width=True)
            
            # === STACKED BAR CHART: MONTHLY ANALYSIS BY BOOKING STATUS ===
            st.subheader("üìä Monthly Block Analysis - Stacked Bar Chart")
            
            # Ensure AllotmentDate is datetime
            block_data['AllotmentDate'] = pd.to_datetime(block_data['AllotmentDate'])
            
            # Create monthly data grouped by booking status
            monthly_status_data = block_data.groupby([
                block_data['AllotmentDate'].dt.month, 
                'BookingStatus'
            ])['BlockSize'].sum().reset_index()
            
            # Convert month numbers to names
            month_names = {1: 'Jan', 2: 'Feb', 3: 'Mar', 4: 'Apr', 5: 'May', 6: 'Jun',
                         7: 'Jul', 8: 'Aug', 9: 'Sep', 10: 'Oct', 11: 'Nov', 12: 'Dec'}
            monthly_status_data['MonthName'] = monthly_status_data['AllotmentDate'].map(month_names)
            
            # Create stacked bar chart
            fig_stacked = px.bar(
                monthly_status_data, 
                x='MonthName', 
                y='BlockSize', 
                color='BookingStatus',
                title="Monthly Block Size by Booking Status (Stacked)",
                labels={'BlockSize': 'Total Block Size', 'MonthName': 'Month'},
                color_discrete_map={
                    'ACT': '#2ecc71',  # Green for Actual
                    'DEF': '#f39c12',  # Orange for Definite  
                    'TEN': '#e74c3c',  # Red for Tentative
                    'PSP': '#9b59b6'   # Purple for Prospect
                }
            )
            
            # Update layout for better readability
            fig_stacked.update_layout(
                height=500,
                xaxis_title="Month",
                yaxis_title="Block Size",
                legend_title="Booking Status",
                hovermode='x unified'
            )
            
            st.plotly_chart(fig_stacked, use_container_width=True)
            
            # Monthly summary table
            st.write("**Monthly Summary Table:**")
            monthly_pivot = monthly_status_data.pivot(index='MonthName', columns='BookingStatus', values='BlockSize').fillna(0)
            
            # Ensure proper month ordering
            month_order = ['Jan', 'Feb', 'Mar', 'Apr', 'May', 'Jun', 'Jul', 'Aug', 'Sep', 'Oct', 'Nov', 'Dec']
            monthly_pivot = monthly_pivot.reindex([month for month in month_order if month in monthly_pivot.index])
            
            # Add totals
            monthly_pivot['Total'] = monthly_pivot.sum(axis=1)
            monthly_pivot.loc['Total'] = monthly_pivot.sum()
            
            # Format for display
            monthly_pivot_display = monthly_pivot.round(0).astype(int)
            st.dataframe(monthly_pivot_display, use_container_width=True)
            
            # Forecast Pipeline
            st.subheader("üîÆ Pipeline Analysis")
            
            pipeline_col1, pipeline_col2 = st.columns(2)
            
            with pipeline_col1:
                # Future bookings
                future_bookings = block_data[block_data['BeginDate'] > pd.Timestamp.now()]
                if not future_bookings.empty:
                    future_by_month = future_bookings.groupby(future_bookings['BeginDate'].dt.to_period('M'))['BlockSize'].sum().reset_index()
                    future_by_month['BeginDate'] = future_by_month['BeginDate'].astype(str)
                    fig = px.bar(future_by_month, x='BeginDate', y='BlockSize', 
                                 title="Future Bookings by Month")
                    st.plotly_chart(fig, use_container_width=True)
                else:
                    st.info("No future bookings in the data")
            
            with pipeline_col2:
                # Status progression
                status_order = ['TEN', 'PSP', 'DEF', 'ACT']
                status_progression = block_data['BookingStatus'].value_counts().reindex(status_order, fill_value=0)
                fig = px.funnel(x=status_progression.values, y=status_progression.index)
                fig.update_layout(title="Booking Status Funnel")
                st.plotly_chart(fig, use_container_width=True)
    
    with block_subtabs[2]:  # Blocks Last Year
        st.subheader("üìÖ 2024 Block Analysis - Historical Data")
        
        # Load 2024 historical block data automatically from database
        block_data_2024 = None
        if database_available:
            try:
                db = get_database()
                block_data_2024 = db.get_last_year_block_data()
                if block_data_2024 is not None and not block_data_2024.empty:
                    # Ensure date column is datetime
                    block_data_2024['AllotmentDate'] = pd.to_datetime(block_data_2024['AllotmentDate'])
            except Exception as e:
                st.error(f"Failed to load 2024 block data: {str(e)}")
        
        if block_data_2024 is None or block_data_2024.empty:
            st.warning("‚ö†Ô∏è No 2024 historical block data available in the database.")
            st.info("üí° The 2024 block data should be automatically loaded from the block_analysis_last_year table.")
            return
        
        # Show data confirmation
        data_years = sorted(block_data_2024['AllotmentDate'].dt.year.unique())
        date_range = f"{block_data_2024['AllotmentDate'].min().date()} to {block_data_2024['AllotmentDate'].max().date()}"
        st.success(f"üìä Successfully loaded {len(block_data_2024):,} records from {data_years} ({date_range})")
        
        # === SECTION 1: KEY PERFORMANCE INDICATORS ===
        st.subheader("üéØ 2024 Key Performance Indicators")
        
        kpi_col1, kpi_col2, kpi_col3, kpi_col4 = st.columns(4)
        
        total_blocks = block_data_2024['BlockSize'].sum()
        unique_companies = block_data_2024['CompanyName'].nunique()
        unique_sales_reps = block_data_2024['SrepCode'].nunique()
        avg_block_size = block_data_2024['BlockSize'].mean()
        
        with kpi_col1:
            st.metric("Total Block Size", f"{total_blocks:,}", help="Total room blocks for 2024")
        with kpi_col2:
            st.metric("Unique Companies", f"{unique_companies:,}", help="Number of different companies")
        with kpi_col3:
            st.metric("Sales Reps", f"{unique_sales_reps:,}", help="Number of sales representatives")
        with kpi_col4:
            st.metric("Avg Block Size", f"{avg_block_size:.1f}", help="Average block size per record")
        
        st.markdown("---")
        
        # === SECTION 2: MONTHLY TRENDS AND ANALYSIS ===
        st.subheader("üìà 2024 Monthly Block Trends")
        
        # Create monthly aggregation
        monthly_data = block_data_2024.groupby(block_data_2024['AllotmentDate'].dt.month).agg({
            'BlockSize': 'sum',
            'CompanyName': 'nunique',
            'AllotmentCode': 'count'
        }).reset_index()
        monthly_data['Month'] = monthly_data['AllotmentDate'].apply(
            lambda x: pd.Timestamp(year=2024, month=x, day=1).strftime('%B')
        )
        
        # Monthly blocks trend line
        col1, col2 = st.columns(2)
        
        with col1:
            fig_trend = px.line(monthly_data, x='Month', y='BlockSize', 
                               title="Monthly Block Size Trend - 2024",
                               markers=True, line_shape='spline')
            fig_trend.update_traces(line=dict(width=3, color='#1f77b4'))
            fig_trend.update_layout(showlegend=False)
            st.plotly_chart(fig_trend, use_container_width=True)
        
        with col2:
            fig_companies = px.bar(monthly_data, x='Month', y='CompanyName',
                                  title="Unique Companies per Month - 2024",
                                  color='CompanyName', color_continuous_scale='viridis')
            fig_companies.update_layout(showlegend=False)
            st.plotly_chart(fig_companies, use_container_width=True)
        
        # Monthly breakdown table
        st.subheader("üìä Monthly Breakdown")
        monthly_display = monthly_data[['Month', 'BlockSize', 'CompanyName', 'AllotmentCode']].copy()
        monthly_display.columns = ['Month', 'Total Blocks', 'Unique Companies', 'Total Records']
        st.dataframe(monthly_display, use_container_width=True, hide_index=True)
        
        st.markdown("---")
        
        # === SECTION 3: TOP 10 COMPANIES ANALYSIS ===
        st.subheader("üèÜ Top 10 Companies - 2024 Block Analysis")
        
        # Calculate top companies
        top_companies = block_data_2024.groupby('CompanyName').agg({
            'BlockSize': 'sum',
            'AllotmentCode': 'count',
            'AllotmentDate': ['min', 'max']
        }).reset_index()
        
        # Flatten column names
        top_companies.columns = ['CompanyName', 'TotalBlocks', 'TotalBookings', 'FirstDate', 'LastDate']
        top_companies = top_companies.nlargest(10, 'TotalBlocks')
        
        # Top 10 horizontal bar chart
        fig_top10 = px.bar(top_companies, 
                           x='TotalBlocks', 
                           y='CompanyName',
                           orientation='h',
                           title="Top 10 Companies by Total Block Size - 2024",
                           color='TotalBlocks',
                           color_continuous_scale='Reds')
        fig_top10.update_layout(yaxis={'categoryorder': 'total ascending'})
        st.plotly_chart(fig_top10, use_container_width=True)
        
        # Top companies detailed table
        st.subheader("üìã Top 10 Companies - Detailed Analysis")
        top_companies_display = top_companies.copy()
        top_companies_display['FirstDate'] = top_companies_display['FirstDate'].dt.date
        top_companies_display['LastDate'] = top_companies_display['LastDate'].dt.date
        top_companies_display['AvgBlockSize'] = (top_companies_display['TotalBlocks'] / top_companies_display['TotalBookings']).round(1)
        
        display_columns = ['CompanyName', 'TotalBlocks', 'TotalBookings', 'AvgBlockSize', 'FirstDate', 'LastDate']
        column_labels = ['Company Name', 'Total Blocks', 'Bookings', 'Avg Block Size', 'First Booking', 'Last Booking']
        
        top_companies_display = top_companies_display[display_columns]
        top_companies_display.columns = column_labels
        st.dataframe(top_companies_display, use_container_width=True, hide_index=True)
        
        # === 2024 HEATMAP: COMPANY-DATE BLOCK ANALYSIS ===
        st.subheader("üî• 2024 Company-Date Heatmap (Red Scale)")
        
        def create_2024_calendar_heatmap(block_data_2024):
            """Create a calendar-style heatmap for 2024 data using RED colorscale"""
            try:
                if block_data_2024.empty:
                    st.info("No data available for 2024 heatmap")
                    return
                
                # Create pivot table: Companies (rows) vs Dates (columns) with BlockSize as values
                pivot_data = block_data_2024.pivot_table(
                    index='CompanyName', 
                    columns='AllotmentDate', 
                    values='BlockSize', 
                    aggfunc='sum', 
                    fill_value=0
                )
                
                # Filter out companies with only zero block sizes - keep only companies with total blocks > 0
                company_totals = pivot_data.sum(axis=1)
                pivot_data = pivot_data.loc[company_totals > 0]
                
                # Limit to top 30 companies by total blocks for better visibility
                company_totals = pivot_data.sum(axis=1).nlargest(30)
                pivot_data = pivot_data.loc[company_totals.index]
                
                # Sort companies by total blocks (descending)
                sorted_companies = company_totals.sort_values(ascending=False).index
                pivot_data = pivot_data.reindex(sorted_companies)
                
                # Create custom hover text
                hover_text = []
                for i, company in enumerate(pivot_data.index):
                    row_text = []
                    for j, date in enumerate(pivot_data.columns):
                        blocks = pivot_data.iloc[i, j]
                        if blocks > 0:
                            text = f"<b>{company}</b><br>Date: {date.strftime('%Y-%m-%d')}<br>Blocks: {blocks}<br>Year: 2024"
                        else:
                            text = f"<b>{company}</b><br>Date: {date.strftime('%Y-%m-%d')}<br>No bookings<br>Year: 2024"
                        row_text.append(text)
                    hover_text.append(row_text)
                
                # Create RED heatmap
                fig = go.Figure(data=go.Heatmap(
                    z=pivot_data.values,
                    x=[date.strftime('%Y-%m-%d') for date in pivot_data.columns],
                    y=pivot_data.index,
                    colorscale='Reds',  # RED colorscale as requested
                    hoverongaps=False,
                    hovertemplate='%{customdata}<extra></extra>',
                    customdata=hover_text,
                    colorbar=dict(title="Block Size"),
                    text=pivot_data.values,  # Show numbers on heatmap
                    texttemplate="%{text}",
                    textfont={"size": 8}
                ))
                
                fig.update_layout(
                    title='2024 Company Block Calendar Heatmap (Red Scale)',
                    xaxis_title='Allotment Date (2024)',
                    yaxis_title='Company Name (Top 30 by Total Blocks)',
                    height=max(800, len(pivot_data) * 25),
                    width=1400,
                    xaxis=dict(tickangle=45, tickfont=dict(size=10)),
                    yaxis=dict(automargin=True, tickfont=dict(size=9)),
                    margin=dict(l=250, r=50, t=80, b=100)
                )
                
                st.plotly_chart(fig, use_container_width=True)
                
                # Heatmap summary
                col1, col2, col3 = st.columns(3)
                with col1:
                    st.metric("Companies Shown", len(pivot_data))
                with col2:
                    st.metric("Date Range", f"{len(pivot_data.columns)} days")
                with col3:
                    st.metric("Peak Single Day", f"{pivot_data.values.max()} blocks")
                
            except Exception as e:
                st.error(f"Error creating 2024 heatmap: {str(e)}")
        
        # Create the 2024 heatmap
        create_2024_calendar_heatmap(block_data_2024)
        
        # === 2025 VS 2024 MONTHLY TREND COMPARISON (ACT+DEF vs ACTUALS) ===
        st.subheader("üìà 2025 Block EDA (ACT+DEF) vs 2024 Actuals - Monthly Trend Comparison")
        
        try:
            # Get 2025 current block data (from Block EDA)
            current_block_data = None
            if database_available:
                db = get_database()
                current_block_data = db.get_block_data()
            
            if current_block_data is not None and not current_block_data.empty:
                current_block_data['AllotmentDate'] = pd.to_datetime(current_block_data['AllotmentDate'])
                
                # Filter for 2025 data with ACT and DEF status only
                current_2025_data = current_block_data[
                    (current_block_data['AllotmentDate'].dt.year == 2025) & 
                    (current_block_data['BookingStatus'].isin(['ACT', 'DEF']))
                ]
                
                if not current_2025_data.empty:
                    # Create daily data for 2024 (all data since it's already actual) - by actual date
                    daily_2024 = block_data_2024.groupby('AllotmentDate').agg({
                        'BlockSize': 'sum',
                        'CompanyName': lambda x: list(x.unique())  # Get unique companies per date
                    }).reset_index()
                    daily_2024['Year'] = '2024 Actuals'
                    daily_2024['CompanyCount'] = daily_2024['CompanyName'].apply(len)
                    daily_2024['TopCompanies'] = daily_2024['CompanyName'].apply(
                        lambda x: ', '.join(x[:5]) + ('...' if len(x) > 5 else '') if x else 'None'
                    )
                    
                    # Create daily data for 2025 (ACT + DEF only) - by actual date
                    daily_2025 = current_2025_data.groupby('AllotmentDate').agg({
                        'BlockSize': 'sum',
                        'CompanyName': lambda x: list(x.unique())  # Get unique companies per date
                    }).reset_index()
                    daily_2025['Year'] = '2025 ACT+DEF'
                    daily_2025['CompanyCount'] = daily_2025['CompanyName'].apply(len)
                    daily_2025['TopCompanies'] = daily_2025['CompanyName'].apply(
                        lambda x: ', '.join(x[:5]) + ('...' if len(x) > 5 else '') if x else 'None'
                    )
                    
                    # Create daily trend comparison chart with day-of-year alignment
                    # Transform dates to day-of-year for alignment
                    daily_2024_copy = daily_2024.copy()
                    daily_2025_copy = daily_2025.copy()
                    
                    # Add day-of-year columns for alignment
                    daily_2024_copy['DayOfYear'] = daily_2024_copy['AllotmentDate'].dt.dayofyear
                    daily_2025_copy['DayOfYear'] = daily_2025_copy['AllotmentDate'].dt.dayofyear
                    
                    # Create normalized date labels (using 2025 as reference year for display)
                    daily_2024_copy['DisplayDate'] = daily_2024_copy['AllotmentDate'].apply(
                        lambda x: pd.Timestamp(2025, x.month, x.day)
                    )
                    daily_2025_copy['DisplayDate'] = daily_2025_copy['AllotmentDate']
                    
                    # Merge on day-of-year to align same days
                    daily_comparison = pd.merge(
                        daily_2024_copy[['DayOfYear', 'DisplayDate', 'BlockSize', 'TopCompanies', 'CompanyCount', 'AllotmentDate']],
                        daily_2025_copy[['DayOfYear', 'DisplayDate', 'BlockSize', 'TopCompanies', 'CompanyCount', 'AllotmentDate']],
                        on='DayOfYear', how='outer', suffixes=('_2024', '_2025')
                    ).fillna({'BlockSize_2024': 0, 'BlockSize_2025': 0, 'CompanyCount_2024': 0, 'CompanyCount_2025': 0})
                    
                    # Use 2025 DisplayDate for x-axis (or 2024 if 2025 is missing)
                    daily_comparison['XAxisDate'] = daily_comparison['DisplayDate_2025'].fillna(daily_comparison['DisplayDate_2024'])
                    daily_comparison = daily_comparison.sort_values('XAxisDate')
                    
                    fig_daily = go.Figure()
                    
                    # Add 2024 daily trend (red line, bottom layer) - using day-of-year alignment
                    fig_daily.add_trace(go.Scatter(
                        x=daily_comparison['XAxisDate'],
                        y=daily_comparison['BlockSize_2024'],
                        mode='lines+markers',
                        name='2024 Actuals (Same Day Last Year)',
                        line=dict(color='#e74c3c', width=3, dash='dash'),
                        marker=dict(size=6, color='#e74c3c', symbol='circle'),
                        hovertemplate=(
                            '<b>2024 Actuals</b><br>' +
                            'Day: %{x|%d %b}<br>' +
                            'Actual Date: %{customdata[0]|%d %b %Y}<br>' +
                            'Block Size: %{y:,}<br>' +
                            'Companies: %{customdata[1]}<br>' +
                            'Company Count: %{customdata[2]}<br>' +
                            'Status: All (Actual)<br>' +
                            '<extra></extra>'
                        ),
                        customdata=list(zip(
                            daily_comparison['AllotmentDate_2024'].fillna(pd.NaT),
                            daily_comparison['TopCompanies_2024'].fillna('None'),
                            daily_comparison['CompanyCount_2024']
                        ))
                    ))
                    
                    # Add 2025 daily trend (blue line, top layer) - using day-of-year alignment
                    fig_daily.add_trace(go.Scatter(
                        x=daily_comparison['XAxisDate'],
                        y=daily_comparison['BlockSize_2025'],
                        mode='lines+markers',
                        name='2025 ACT+DEF (Current Year)',
                        line=dict(color='#3498db', width=4),
                        marker=dict(size=8, color='#3498db', symbol='circle'),
                        hovertemplate=(
                            '<b>2025 ACT+DEF</b><br>' +
                            'Day: %{x|%d %b}<br>' +
                            'Actual Date: %{customdata[0]|%d %b %Y}<br>' +
                            'Block Size: %{y:,}<br>' +
                            'Companies: %{customdata[1]}<br>' +
                            'Company Count: %{customdata[2]}<br>' +
                            'Status: ACT+DEF Only<br>' +
                            '<extra></extra>'
                        ),
                        customdata=list(zip(
                            daily_comparison['AllotmentDate_2025'].fillna(pd.NaT),
                            daily_comparison['TopCompanies_2025'].fillna('None'),
                            daily_comparison['CompanyCount_2025']
                        ))
                    ))
                    
                    # Update layout for day-of-year comparison
                    fig_daily.update_layout(
                        title='üìä Daily Comparison: 2025 ACT+DEF vs Same Day Last Year (2024 Actuals)<br><sub>Each day of 2025 compared with same calendar day in 2024</sub>',
                        xaxis_title='Calendar Day (Same Day Both Years)',
                        yaxis_title='Block Size',
                        height=650,
                        hovermode='x unified',
                        showlegend=True,
                        legend=dict(
                            orientation="h",
                            yanchor="bottom",
                            y=1.02,
                            xanchor="right",
                            x=1
                        ),
                        xaxis=dict(
                            tickformat='%d %b',  # Format as "20 Aug", "21 Aug", etc.
                            dtick='D7',  # Show tick every 7 days (weekly)
                            tickangle=45,  # Angle the dates for better readability
                            showgrid=True,
                            gridwidth=1,
                            gridcolor='rgba(128,128,128,0.2)'
                        ),
                        yaxis=dict(
                            showgrid=True,
                            gridwidth=1,
                            gridcolor='rgba(128,128,128,0.2)'
                        ),
                        plot_bgcolor='rgba(0,0,0,0)',
                        annotations=[
                            dict(
                                text="üí° Blue line (2025) shows on top of red dashed line (2024 same day)",
                                showarrow=False,
                                xref="paper", yref="paper",
                                x=0.02, y=0.98, xanchor='left', yanchor='top',
                                font=dict(size=10, color='gray')
                            )
                        ]
                    )
                    
                    st.plotly_chart(fig_daily, use_container_width=True)
                    
                    # Daily comparison summary table - Same Day Year-over-Year
                    st.subheader("üìä Same Day Year-over-Year Comparison Summary")
                    st.write("*Comparing each day of 2025 with the exact same calendar day in 2024*")
                    
                    # Use the daily_comparison data we already created for the chart
                    comparison_table = daily_comparison.copy()
                    comparison_table['Difference'] = comparison_table['BlockSize_2025'] - comparison_table['BlockSize_2024']
                    comparison_table['% Change'] = (
                        (comparison_table['BlockSize_2025'] - comparison_table['BlockSize_2024']) / 
                        comparison_table['BlockSize_2024'].replace(0, np.nan) * 100
                    ).round(1)
                    comparison_table['% Change'] = comparison_table['% Change'].fillna(0)
                    
                    # Format dates for display (show the calendar day)
                    comparison_table['DateFormatted'] = comparison_table['XAxisDate'].dt.strftime('%d %b')
                    comparison_table['ActualDate_2024'] = comparison_table['AllotmentDate_2024'].dt.strftime('%d %b %Y')
                    comparison_table['ActualDate_2025'] = comparison_table['AllotmentDate_2025'].dt.strftime('%d %b %Y')
                    
                    # Format for display
                    display_comparison = comparison_table[
                        ['DateFormatted', 'ActualDate_2024', 'ActualDate_2025', 'BlockSize_2024', 'BlockSize_2025', 'Difference', '% Change', 'CompanyCount_2024', 'CompanyCount_2025']
                    ].copy()
                    display_comparison.columns = [
                        'Calendar Day', '2024 Actual Date', '2025 Actual Date', '2024 Blocks', '2025 ACT+DEF', 'Difference', '% Change', '2024 Companies', '2025 Companies'
                    ]
                    
                    # Filter out rows with no activity in either year for the top days display
                    active_days = display_comparison[
                        (display_comparison['2024 Blocks'] > 0) | (display_comparison['2025 ACT+DEF'] > 0)
                    ].copy()
                    
                    # Show top 15 days with highest activity
                    st.write("**üî• Top 15 Calendar Days by Combined Activity (Same Day Both Years):**")
                    active_days['TotalActivity'] = active_days['2024 Blocks'] + active_days['2025 ACT+DEF']
                    top_days = active_days.nlargest(15, 'TotalActivity')[
                        ['Calendar Day', '2024 Actual Date', '2025 Actual Date', '2024 Blocks', '2025 ACT+DEF', 'Difference', '% Change', '2024 Companies', '2025 Companies']
                    ]
                    st.dataframe(top_days, use_container_width=True, hide_index=True)
                    
                    # Show days where 2025 significantly outperforms 2024
                    st.write("**üìà Days Where 2025 ACT+DEF Significantly Outperforms 2024:**")
                    outperform_days = active_days[
                        (active_days['Difference'] > 0) & (active_days['% Change'] >= 50)
                    ].sort_values('% Change', ascending=False).head(10)
                    if not outperform_days.empty:
                        st.dataframe(outperform_days[
                            ['Calendar Day', '2024 Blocks', '2025 ACT+DEF', 'Difference', '% Change']
                        ], use_container_width=True, hide_index=True)
                    else:
                        st.info("No days where 2025 significantly outperforms 2024 (>50% improvement)")
                    
                    # Show days where 2024 significantly outperformed 2025
                    st.write("**üìâ Days Where 2024 Significantly Outperformed 2025:**")
                    underperform_days = active_days[
                        (active_days['Difference'] < 0) & (active_days['% Change'] <= -50)
                    ].sort_values('% Change').head(10)
                    if not underperform_days.empty:
                        st.dataframe(underperform_days[
                            ['Calendar Day', '2024 Blocks', '2025 ACT+DEF', 'Difference', '% Change']
                        ], use_container_width=True, hide_index=True)
                    else:
                        st.info("No days where 2024 significantly outperformed 2025 (>50% decline)")
                    
                    # Summary metrics - Same Day Year-over-Year
                    st.subheader("üìä Same Day Year-over-Year Performance Summary")
                    col1, col2, col3, col4 = st.columns(4)
                    
                    # Calculate metrics from the aligned comparison data
                    total_2024 = comparison_table['BlockSize_2024'].sum()
                    total_2025 = comparison_table['BlockSize_2025'].sum()
                    total_diff = total_2025 - total_2024
                    pct_change_total = (total_diff / total_2024 * 100) if total_2024 > 0 else 0
                    
                    # Days with activity for both years
                    common_days = comparison_table[
                        (comparison_table['BlockSize_2024'] > 0) & (comparison_table['BlockSize_2025'] > 0)
                    ]
                    
                    with col1:
                        st.metric(
                            "2024 Total Blocks", 
                            f"{total_2024:,}",
                            help="Total blocks across all matched calendar days in 2024"
                        )
                        
                        # Peak day in 2024
                        if total_2024 > 0:
                            peak_2024_idx = comparison_table['BlockSize_2024'].idxmax()
                            peak_2024_date = comparison_table.loc[peak_2024_idx, 'XAxisDate']
                            peak_2024_blocks = comparison_table.loc[peak_2024_idx, 'BlockSize_2024']
                            st.metric(
                                "2024 Peak Day", 
                                f"{peak_2024_date.strftime('%d %b')}: {peak_2024_blocks:,}",
                                help="Highest single day in 2024"
                            )
                    
                    with col2:
                        st.metric(
                            "2025 Total Blocks (ACT+DEF)", 
                            f"{total_2025:,}",
                            help="Total ACT+DEF blocks across all matched calendar days in 2025"
                        )
                        
                        # Peak day in 2025
                        if total_2025 > 0:
                            peak_2025_idx = comparison_table['BlockSize_2025'].idxmax()
                            peak_2025_date = comparison_table.loc[peak_2025_idx, 'XAxisDate']
                            peak_2025_blocks = comparison_table.loc[peak_2025_idx, 'BlockSize_2025']
                            st.metric(
                                "2025 Peak Day", 
                                f"{peak_2025_date.strftime('%d %b')}: {peak_2025_blocks:,}",
                                help="Highest single day in 2025"
                            )
                    
                    with col3:
                        st.metric(
                            "Year-over-Year Difference", 
                            f"{total_diff:+,}",
                            delta=f"{pct_change_total:+.1f}%",
                            help="2025 vs 2024 same calendar days comparison"
                        )
                        
                        # Days where 2025 beats 2024
                        winning_days = len(comparison_table[comparison_table['BlockSize_2025'] > comparison_table['BlockSize_2024']])
                        total_comparison_days = len(comparison_table[(comparison_table['BlockSize_2024'] > 0) | (comparison_table['BlockSize_2025'] > 0)])
                        win_rate = (winning_days / total_comparison_days * 100) if total_comparison_days > 0 else 0
                        
                        st.metric(
                            "2025 Winning Days", 
                            f"{winning_days} of {total_comparison_days}",
                            delta=f"{win_rate:.1f}% win rate",
                            help="Days where 2025 ACT+DEF exceeds 2024 actuals"
                        )
                    
                    with col4:
                        # Average performance comparison
                        avg_2024 = comparison_table[comparison_table['BlockSize_2024'] > 0]['BlockSize_2024'].mean()
                        avg_2025 = comparison_table[comparison_table['BlockSize_2025'] > 0]['BlockSize_2025'].mean()
                        avg_diff = avg_2025 - avg_2024 if not np.isnan(avg_2024) and not np.isnan(avg_2025) else 0
                        
                        st.metric(
                            "Avg Blocks per Active Day", 
                            f"2025: {avg_2025:.0f}" if not np.isnan(avg_2025) else "2025: 0",
                            delta=f"vs 2024: {avg_2024:.0f}" if not np.isnan(avg_2024) else "vs 2024: 0",
                            help="Average blocks per day (excluding zero-activity days)"
                        )
                        
                        # Common active days performance
                        if len(common_days) > 0:
                            common_avg_2024 = common_days['BlockSize_2024'].mean()
                            common_avg_2025 = common_days['BlockSize_2025'].mean()
                            common_improvement = ((common_avg_2025 - common_avg_2024) / common_avg_2024 * 100) if common_avg_2024 > 0 else 0
                            
                            st.metric(
                                "Common Days Performance", 
                                f"{len(common_days)} shared active days",
                                delta=f"{common_improvement:+.1f}% avg improvement",
                                help="Performance on days with activity in both years"
                            )
                    
                else:
                    st.info("üí° No 2025 ACT+DEF block data available for comparison")
                    
            else:
                st.info("üí° No current block data available from Block EDA for comparison")
                
        except Exception as e:
            st.error(f"Error creating monthly trend comparison: {str(e)}")
        
        st.markdown("---")
        
        # === SECTION 4: SALES REPRESENTATIVE PERFORMANCE ===
        st.subheader("üë• Sales Representative Performance - 2024")
        
        sales_rep_data = block_data_2024.groupby('SrepCode').agg({
            'BlockSize': 'sum',
            'CompanyName': 'nunique',
            'AllotmentCode': 'count'
        }).reset_index().sort_values('BlockSize', ascending=False)
        
        col1, col2 = st.columns(2)
        
        with col1:
            fig_sales_blocks = px.pie(sales_rep_data.head(8), 
                                     values='BlockSize', 
                                     names='SrepCode',
                                     title="Block Size Distribution by Sales Rep")
            st.plotly_chart(fig_sales_blocks, use_container_width=True)
        
        with col2:
            fig_sales_companies = px.bar(sales_rep_data, 
                                        x='SrepCode', 
                                        y='CompanyName',
                                        title="Companies Managed per Sales Rep",
                                        color='CompanyName', 
                                        color_continuous_scale='plasma')
            st.plotly_chart(fig_sales_companies, use_container_width=True)
        
        # Sales rep performance table
        sales_rep_display = sales_rep_data.copy()
        sales_rep_display.columns = ['Sales Rep Code', 'Total Blocks', 'Unique Companies', 'Total Bookings']
        sales_rep_display['Avg Blocks per Company'] = (sales_rep_display['Total Blocks'] / sales_rep_display['Unique Companies']).round(1)
        st.dataframe(sales_rep_display, use_container_width=True, hide_index=True)
        
        st.markdown("---")
        
        # === SECTION 5: TIMELINE ANALYSIS ===
        st.subheader("‚è∞ 2024 Booking Timeline Analysis")
        
        # Daily blocks over time
        daily_data = block_data_2024.groupby('AllotmentDate')['BlockSize'].sum().reset_index()
        
        fig_timeline = px.line(daily_data, 
                              x='AllotmentDate', 
                              y='BlockSize',
                              title="Daily Block Size Timeline - 2024",
                              line_shape='spline')
        fig_timeline.update_traces(line=dict(width=2, color='#e74c3c'))
        fig_timeline.update_layout(
            xaxis_title="Date",
            yaxis_title="Block Size",
            showlegend=False
        )
        st.plotly_chart(fig_timeline, use_container_width=True)
        
        # Peak booking periods
        st.subheader("üìä Peak Booking Analysis")
        peak_data = daily_data.nlargest(10, 'BlockSize')
        peak_data['AllotmentDate'] = peak_data['AllotmentDate'].dt.date
        peak_data.columns = ['Date', 'Block Size']
        
        col1, col2 = st.columns([1, 1])
        with col1:
            st.write("**Top 10 Peak Booking Days:**")
            st.dataframe(peak_data, use_container_width=True, hide_index=True)
        
        with col2:
            # Weekly pattern analysis
            block_data_2024_copy = block_data_2024.copy()
            block_data_2024_copy['DayOfWeek'] = block_data_2024_copy['AllotmentDate'].dt.day_name()
            weekly_pattern = block_data_2024_copy.groupby('DayOfWeek')['BlockSize'].sum().reset_index()
            
            # Reorder days
            day_order = ['Monday', 'Tuesday', 'Wednesday', 'Thursday', 'Friday', 'Saturday', 'Sunday']
            weekly_pattern['DayOfWeek'] = pd.Categorical(weekly_pattern['DayOfWeek'], categories=day_order, ordered=True)
            weekly_pattern = weekly_pattern.sort_values('DayOfWeek')
            
            fig_weekly = px.bar(weekly_pattern, x='DayOfWeek', y='BlockSize',
                               title="Block Size by Day of Week - 2024",
                               color='BlockSize', color_continuous_scale='sunset')
            st.plotly_chart(fig_weekly, use_container_width=True)

def block_dashboard_tab():
    """Block Dashboard tab with KPIs and interactive charts"""
    st.header("üìà Block Dashboard")
    
    # Get block data
    if database_available:
        db = get_database()
        block_data = db.get_block_data()
    else:
        block_data = pd.DataFrame()
    
    if block_data.empty:
        st.warning("‚ö†Ô∏è No block data available. Please load data in the Block Analysis tab first.")
        return
    
    # KPI Dashboard
    st.subheader("üéØ Key Performance Indicators")
    
    # Calculate KPIs
    total_blocks = block_data['BlockSize'].sum()
    confirmed_blocks = block_data[block_data['BookingStatus'].isin(['ACT', 'DEF'])]['BlockSize'].sum()
    prospect_blocks = block_data[block_data['BookingStatus'].isin(['PSP', 'TEN'])]['BlockSize'].sum()
    
    conversion_rate = (confirmed_blocks / total_blocks * 100) if total_blocks > 0 else 0
    
    kpi_col1, kpi_col2, kpi_col3, kpi_col4 = st.columns(4)
    
    with kpi_col1:
        st.metric(
            "Total Blocks", 
            f"{total_blocks:,}",
            help="Total number of room blocks"
        )
    
    with kpi_col2:
        st.metric(
            "Confirmed Blocks", 
            f"{confirmed_blocks:,}",
            help="ACT + DEF status blocks"
        )
    
    with kpi_col3:
        st.metric(
            "Prospect Blocks", 
            f"{prospect_blocks:,}",
            help="PSP + TEN status blocks"
        )
    
    with kpi_col4:
        st.metric(
            "Conversion Rate", 
            f"{conversion_rate:.1f}%",
            help="Confirmed blocks / Total blocks"
        )
    
    # Interactive Charts
    st.subheader("üìä Interactive Analytics")
    
    chart_col1, chart_col2 = st.columns(2)
    
    with chart_col1:
        # Time series chart
        st.write("**Block Booking Timeline**")
        daily_blocks = block_data.groupby(['AllotmentDate', 'BookingStatus'])['BlockSize'].sum().reset_index()
        fig = px.line(daily_blocks, x='AllotmentDate', y='BlockSize', 
                      color='BookingStatus', title="Daily Block Bookings by Status")
        st.plotly_chart(fig, use_container_width=True)
    
    with chart_col2:
        # Sales rep performance
        st.write("**Sales Rep Performance**")
        rep_performance = block_data.groupby('SrepCode')['BlockSize'].sum().nlargest(10).reset_index()
        fig = px.bar(rep_performance, x='SrepCode', y='BlockSize', 
                     title="Top 10 Sales Reps by Blocks")
        st.plotly_chart(fig, use_container_width=True)
    
    # Business Mix Analysis
    st.write("**Business Mix Analysis**")
    business_mix = block_data.groupby('BookingStatus').agg({
        'BlockSize': ['sum', 'count', 'mean']
    }).round(2)
    business_mix.columns = ['Total Blocks', 'Number of Bookings', 'Average Block Size']
    business_mix = business_mix.reset_index()
    
    st.dataframe(business_mix, use_container_width=True)
    
    # Forecast Pipeline
    st.subheader("üîÆ Pipeline Analysis")
    
    pipeline_col1, pipeline_col2 = st.columns(2)
    
    with pipeline_col1:
        # Future bookings
        future_bookings = block_data[block_data['BeginDate'] > pd.Timestamp.now()]
        if not future_bookings.empty:
            future_by_month = future_bookings.groupby(future_bookings['BeginDate'].dt.to_period('M'))['BlockSize'].sum().reset_index()
            future_by_month['BeginDate'] = future_by_month['BeginDate'].astype(str)
            fig = px.bar(future_by_month, x='BeginDate', y='BlockSize', 
                         title="Future Bookings by Month")
            st.plotly_chart(fig, use_container_width=True)
        else:
            st.info("No future bookings in the data")
    
    with pipeline_col2:
        # Status progression
        status_order = ['TEN', 'PSP', 'DEF', 'ACT']
        status_progression = block_data['BookingStatus'].value_counts().reindex(status_order, fill_value=0)
        fig = px.funnel(x=status_progression.values, y=status_progression.index)
        fig.update_layout(title="Booking Status Funnel")
        st.plotly_chart(fig, use_container_width=True)

def get_dubai_events():
    """Define Dubai events that impact hotel market"""
    events = [
        {
            'name': 'Dubai International Film Festival (DIFF)',
            'start_date': '2025-08-30',
            'end_date': '2025-08-30',
            'description': 'Premier Arab cinema event attracting filmmakers, celebrities, and tourists.'
        },
        {
            'name': 'Sleep Expo Middle East 2025',
            'start_date': '2025-09-15',
            'end_date': '2025-09-17',
            'description': 'Exhibition focused on bedding, mattresses, and sleep technology.'
        },
        {
            'name': 'Dubai PodFest 2025',
            'start_date': '2025-09-30',
            'end_date': '2025-09-30',
            'description': 'Podcast and digital media industry event.'
        },
        {
            'name': 'Gulf Food Manufacturing 2025',
            'start_date': '2025-09-29',
            'end_date': '2025-10-01',
            'description': 'Major food processing, packaging, and manufacturing exhibition.'
        },
        {
            'name': 'GITEX Global 2025',
            'start_date': '2025-10-13',
            'end_date': '2025-10-17',
            'description': 'Largest technology, AI, and startup event at Dubai World Trade Centre.'
        },
        {
            'name': 'Asia Pacific Cities Summit & Mayors Forum',
            'start_date': '2025-10-27',
            'end_date': '2025-10-29',
            'description': 'Urban development and governance conference at Expo City Dubai.'
        },
        {
            'name': 'Dubai Shopping Festival (DSF) 2025‚Äì2026',
            'start_date': '2025-12-15',
            'end_date': '2026-01-29',
            'description': 'City-wide retail festival drawing millions of shoppers.'
        },
        {
            'name': 'World Sports Summit 2025',
            'start_date': '2025-12-29',
            'end_date': '2025-12-30',
            'description': 'International sports industry conference attracting global professionals.'
        }
    ]
    
    # Convert to DataFrame with proper date parsing
    events_df = pd.DataFrame(events)
    events_df['start_date'] = pd.to_datetime(events_df['start_date'])
    events_df['end_date'] = pd.to_datetime(events_df['end_date'])
    
    return events_df

def events_analysis_tab():
    """Events Analysis tab with occupancy correlation and booking analysis"""
    st.header("üéâ Events Analysis")
    
    # Get data
    if st.session_state.occupancy_data is not None:
        occupancy_data = st.session_state.occupancy_data.copy()
    else:
        if database_available:
            occupancy_data = get_database().get_occupancy_data()
        else:
            occupancy_data = pd.DataFrame()
    
    # Try to get block data if available
    try:
        if database_available:
            db = get_database()
            block_data = db.get_block_data()
        else:
            block_data = pd.DataFrame()
    except:
        block_data = pd.DataFrame()
    
    if occupancy_data.empty and block_data.empty:
        st.warning("‚ö†Ô∏è No data available. Please load occupancy data first.")
        return
    
    # Get Dubai events
    events_df = get_dubai_events()
    
    # Display events calendar
    st.subheader("üìÖ Dubai Events Calendar")
    
    # Create events timeline
    fig = go.Figure()
    
    for idx, event in events_df.iterrows():
        # Calculate event duration
        duration = (event['end_date'] - event['start_date']).days + 1
        
        fig.add_trace(go.Scatter(
            x=[event['start_date'], event['end_date']],
            y=[idx, idx],
            mode='lines+markers',
            name=event['name'],
            line=dict(width=8),
            hovertemplate=f"<b>{event['name']}</b><br>%{{x}}<br>{event['description']}<extra></extra>"
        ))
    
    fig.update_layout(
        title='Dubai Events Timeline (Aug 2025 - Jan 2026)',
        xaxis_title='Date',
        yaxis_title='Events',
        yaxis=dict(
            tickmode='array',
            tickvals=list(range(len(events_df))),
            ticktext=events_df['name'].tolist()
        ),
        height=400,
        showlegend=False
    )
    
    st.plotly_chart(fig, use_container_width=True)
    
    # Events table
    st.subheader("üìã Events Details")
    events_display = events_df.copy()
    events_display['start_date'] = events_display['start_date'].dt.strftime('%Y-%m-%d')
    events_display['end_date'] = events_display['end_date'].dt.strftime('%Y-%m-%d')
    st.dataframe(events_display, use_container_width=True)
    
    # Analysis section
    if not occupancy_data.empty:
        st.subheader("üîç Occupancy & Events Analysis")
        
        # Convert occupancy date column
        if 'Date' in occupancy_data.columns:
            occupancy_data['Date'] = pd.to_datetime(occupancy_data['Date'])
            
            # Find high occupancy dates (adjustable threshold)
            high_occ_threshold = st.slider("Occupancy Threshold (%)", 10, 50, 20)
            
            # Use correct column name - check both possible names
            occ_column = None
            if 'Occ%' in occupancy_data.columns:
                occ_column = 'Occ%'
            elif 'Occ_Pct' in occupancy_data.columns:
                occ_column = 'Occ_Pct'
            
            if occ_column:
                high_occ_dates = occupancy_data[occupancy_data[occ_column] > high_occ_threshold]['Date'].dt.date.tolist()
                
                st.write(f"**Dates with occupancy > {high_occ_threshold}%: {len(high_occ_dates)} days**")
                
                # Check which events coincide with high occupancy
                event_high_occ_overlaps = []
                
                for _, event in events_df.iterrows():
                    event_dates = pd.date_range(event['start_date'], event['end_date']).date.tolist()
                    overlap_dates = [date for date in event_dates if date in high_occ_dates]
                    
                    if overlap_dates:
                        event_high_occ_overlaps.append({
                            'event': event['name'],
                            'overlap_dates': overlap_dates,
                            'total_event_days': len(event_dates),
                            'high_occ_days': len(overlap_dates)
                        })
                
                if event_high_occ_overlaps:
                    st.write("**üö® Events coinciding with high occupancy:**")
                    for overlap in event_high_occ_overlaps:
                        st.write(f"- **{overlap['event']}**: {overlap['high_occ_days']}/{overlap['total_event_days']} days with high occupancy")
                        st.write(f"  High occupancy dates: {[str(date) for date in overlap['overlap_dates']]}")
                
                # Occupancy chart for event periods
                st.subheader("üìä Daily Occupancy During Events")
                
                # Filter occupancy data from today onwards
                today = datetime.now().date()
                occupancy_filtered = occupancy_data[occupancy_data['Date'].dt.date >= today].copy()
                
                if occupancy_filtered.empty:
                    st.warning("No occupancy data available from today onwards.")
                else:
                    # Create occupancy chart with event overlays and block size trend
                    fig = make_subplots(specs=[[{"secondary_y": True}]])
                
                    # Add occupancy line (right axis) - using filtered data
                    fig.add_trace(go.Scatter(
                        x=occupancy_filtered['Date'],
                        y=occupancy_filtered[occ_column],
                        mode='lines',
                        name='Occupancy %',
                        line=dict(color='blue', width=2),
                        yaxis='y2'
                    ))                # Add block size trend line if block data is available (left axis)
                if not block_data.empty and 'AllotmentDate' in block_data.columns and 'BlockSize' in block_data.columns:
                    # Prepare block data - group by date and sum block sizes
                    block_daily = block_data.groupby(block_data['AllotmentDate'].dt.date)['BlockSize'].sum().reset_index()
                    block_daily['AllotmentDate'] = pd.to_datetime(block_daily['AllotmentDate'])
                    
                    fig.add_trace(go.Scatter(
                        x=block_daily['AllotmentDate'],
                        y=block_daily['BlockSize'],
                        mode='lines',
                        name='Total Block Size',
                        line=dict(color='green', width=3),
                        yaxis='y'
                    ))
                
                # Add threshold line (right axis)
                fig.add_hline(y=high_occ_threshold, line_dash="dash", line_color="red", 
                             annotation_text=f"Occupancy Threshold ({high_occ_threshold}%)",
                             secondary_y=True)
                
                # Add event periods as shaded areas
                for _, event in events_df.iterrows():
                    fig.add_vrect(
                        x0=event['start_date'], x1=event['end_date'],
                        fillcolor="rgba(255,0,0,0.1)",
                        layer="below", line_width=0,
                        annotation_text=event['name'],
                        annotation_position="top left"
                    )
                
                # Update layout with dual y-axes
                fig.update_layout(
                    title='Daily Occupancy & Block Size Trends with Event Periods Highlighted',
                    xaxis_title='Date',
                    height=700,  # Made bigger
                    hovermode='x unified',
                    legend=dict(yanchor="top", y=0.99, xanchor="left", x=0.01)
                )
                
                # Set y-axes titles
                fig.update_yaxes(title_text="Block Size", side="left", secondary_y=False)
                fig.update_yaxes(title_text="Occupancy %", side="right", secondary_y=True)
                
                st.plotly_chart(fig, use_container_width=True)
            else:
                st.error("No occupancy percentage column found in data")
    
    # Block data analysis during events
    if not block_data.empty:
        st.subheader("üè® Block Bookings During Events")
        
        # Ensure block data has proper date columns
        try:
            if 'AllotmentDate' in block_data.columns:
                block_data['AllotmentDate'] = pd.to_datetime(block_data['AllotmentDate'])
            if 'BeginDate' in block_data.columns:
                block_data['BeginDate'] = pd.to_datetime(block_data['BeginDate'])
            
            # Find block bookings that fall on event dates
            event_bookings = []
            
            for _, event in events_df.iterrows():
                event_dates = pd.date_range(event['start_date'], event['end_date'])
                
                allotment_bookings = pd.DataFrame()
                stay_bookings = pd.DataFrame()
                
                # Check ALLOTMENT_DATE if it exists
                if 'AllotmentDate' in block_data.columns:
                    allotment_bookings = block_data[
                        block_data['AllotmentDate'].dt.date.isin(event_dates.date)
                    ]
                
                # Check BEGIN_DATE (stay dates) if it exists
                if 'BeginDate' in block_data.columns:
                    stay_bookings = block_data[
                        block_data['BeginDate'].dt.date.isin(event_dates.date)
                    ]
                
                if not allotment_bookings.empty or not stay_bookings.empty:
                    event_bookings.append({
                        'event': event['name'],
                        'event_dates': event_dates.date.tolist(),
                        'allotment_bookings': len(allotment_bookings),
                        'stay_bookings': len(stay_bookings),
                        'total_allotment_blocks': allotment_bookings['BlockSize'].sum() if 'BlockSize' in allotment_bookings.columns else 0,
                        'total_stay_blocks': stay_bookings['BlockSize'].sum() if 'BlockSize' in stay_bookings.columns else 0
                    })
            
            if event_bookings:
                st.write("**üìà Block bookings related to events:**")
                
                for booking in event_bookings:
                    with st.expander(f"üéâ {booking['event']}"):
                        col1, col2 = st.columns(2)
                        
                        with col1:
                            st.write("**Bookings made during event dates:**")
                            st.metric("Allotment bookings", booking['allotment_bookings'])
                            st.metric("Total blocks (allotment)", booking['total_allotment_blocks'])
                        
                        with col2:
                            st.write("**Stays during event dates:**")
                            st.metric("Stay bookings", booking['stay_bookings'])
                            st.metric("Total blocks (stays)", booking['total_stay_blocks'])
            else:
                st.info("No block bookings found coinciding with major events.")
        except Exception as e:
            st.warning(f"Block data analysis not available: {str(e)}")
    else:
        st.info("No block data available for events correlation analysis.")

def entered_on_arrivals_tab():
    """Entered On & Arrivals tab with sub-tabs for entry and arrival analysis"""
    st.header("üìÖ Entered On & Arrivals Analysis")
    
    if not st.session_state.data_loaded:
        st.warning("‚ö†Ô∏è Please load data first using the Dashboard tab")
        return
    
    # Create sub-tabs
    entered_tab, reservations_tab, arrivals_tab, arrivals_data_tab = st.tabs(["üìù Entered On", "üìã Reservations Entered", "üö™ Arrivals", "üìã Arrivals Data"])
    
    with entered_tab:
        st.subheader("üìù Entered On Comprehensive Analysis")
        
        # File upload section with auto-conversion
        st.markdown("### üìÅ Upload Entered On Report")
        uploaded_file = st.file_uploader(
            "Choose an Entered On Excel file (.xlsm)",
            type=['xlsm'],
            help="Upload an Excel file with 'ENTERED ON' sheet - automatic conversion will begin immediately"
        )
        
        # Auto-convert when file is uploaded
        if uploaded_file is not None:
            try:
                # Save uploaded file temporarily
                import tempfile
                import os
                
                with tempfile.NamedTemporaryFile(delete=False, suffix='.xlsm') as tmp_file:
                    tmp_file.write(uploaded_file.getvalue())
                    temp_path = tmp_file.name
                
                # Auto-convert immediately
                conversion_status = st.empty()
                conversion_status.info("üîÑ Auto-converting Excel file...")
                
                try:
                    # Import converter
                    import sys
                    sys.path.append('.')
                    from converters.entered_on_converter import process_entered_on_report, get_summary_stats
                    
                    # Process the file
                    df, csv_path = process_entered_on_report(temp_path)
                    conversion_status.success("‚úÖ Auto-conversion completed successfully!")
                    
                    # Load to database
                    db_status = st.empty()
                    db_status.info("üîÑ Loading data to SQL database...")
                    
                    if database_available:
                        db = get_database()
                        success = db.ingest_entered_on_data(df)
                        
                        if success:
                            st.session_state.entered_on_data = df
                        else:
                            db_status.error("‚ùå Failed to load data to database")
                            st.session_state.entered_on_data = df
                    else:
                        db_status.warning("‚ö†Ô∏è Database not available - data processed but not stored")
                        st.session_state.entered_on_data = df
                    
                except Exception as e:
                    conversion_status.error(f"‚ùå Auto-conversion failed: {str(e)}")
                    conversion_logger.error(f"Entered On conversion error: {e}")
                finally:
                    # Clean up temp file
                    if os.path.exists(temp_path):
                        os.unlink(temp_path)
                        
            except Exception as e:
                st.error(f"Error uploading file: {str(e)}")
        
        # Load and display current data
        entered_on_data = None
        if database_available:
            try:
                db = get_database()
                entered_on_data = db.get_entered_on_data()
                if not entered_on_data.empty:
                    st.session_state.entered_on_data = entered_on_data
            except Exception as e:
                conversion_logger.error(f"Failed to load entered on data from database: {e}")
        
        # Fallback to session state
        if entered_on_data is None or entered_on_data.empty:
            entered_on_data = st.session_state.get('entered_on_data')
        
        if entered_on_data is not None and not entered_on_data.empty:
            # Show data processing info
            
            # Month Filter Control
            st.markdown("---")
            st.subheader("üìÖ Month Filter")
            
            # Get available months from the data - using monthly columns instead of SPLIT_MONTH
            monthly_cols = ['AUG2025', 'SEP2025', 'OCT2025', 'NOV2025', 'DEC2025', 'JAN2026', 'FEB2026', 'MAR2026', 'APR2026', 'MAY2026', 'JUN2026', 'JUL2026', 'AUG2026', 'SEP2026', 'OCT2026', 'NOV2026', 'DEC2026']
            existing_monthly_cols = [col for col in monthly_cols if col in entered_on_data.columns and entered_on_data[col].sum() > 0]
            available_months = ['All Months'] + [col.replace('2025', ' 2025').replace('2026', ' 2026') for col in existing_monthly_cols]
            
            col1, col2 = st.columns([1, 2])
            with col1:
                selected_month = st.selectbox(
                    "Select Month for Analysis:",
                    available_months,
                    index=0,
                    help="Filter all KPIs and charts by selected month. 'All Months' shows combined data."
                )
            
            with col2:
                if selected_month != 'All Months':
                    # Convert display month back to column format (e.g., "AUG 2025" -> "AUG2025")
                    selected_col = selected_month.replace(' ', '')
                    if selected_col in entered_on_data.columns:
                        # Show all bookings that have nights in this month (column > 0)
                        month_data = entered_on_data[entered_on_data[selected_col] > 0]
                        st.info(f"üìä Showing data for **{selected_month}** - {len(month_data)} bookings with nights in this month")
                    else:
                        month_data = entered_on_data
                        st.warning(f"Month column {selected_col} not found, showing all data")
                else:
                    month_data = entered_on_data
                    st.info(f"üìä Showing data for **All Months** - {len(month_data)} records")
            
            # Use filtered data for all subsequent analysis
            entered_on_data = month_data
            
            # Comprehensive EDA Analysis
            st.markdown("---")
            st.markdown("## üìä Comprehensive EDA Analysis")
            st.markdown(f"### Analysis for: **{selected_month}**" if selected_month != 'All Months' else "### Analysis for: **All Months Combined**")
            
            # 6. Main KPI Cards (AMOUNT total and Room nights) - Split vs Total
            st.markdown("### üìà *Key Performance Indicators*")
            
            # Calculate both split (monthly) and original (total booking) metrics
            total_bookings = len(entered_on_data['RESV_ID'].unique()) if 'RESV_ID' in entered_on_data.columns else len(entered_on_data)
            
            # Define all possible monthly columns
            monthly_amount_cols = ['AUG2025_AMT', 'SEP2025_AMT', 'OCT2025_AMT', 'NOV2025_AMT', 'DEC2025_AMT', 'JAN2026_AMT', 'FEB2026_AMT', 'MAR2026_AMT', 'APR2026_AMT', 'MAY2026_AMT', 'JUN2026_AMT', 'JUL2026_AMT', 'AUG2026_AMT', 'SEP2026_AMT', 'OCT2026_AMT', 'NOV2026_AMT', 'DEC2026_AMT']
            monthly_nights_cols = ['AUG2025', 'SEP2025', 'OCT2025', 'NOV2025', 'DEC2025', 'JAN2026', 'FEB2026', 'MAR2026', 'APR2026', 'MAY2026', 'JUN2026', 'JUL2026', 'AUG2026', 'SEP2026', 'OCT2026', 'NOV2026', 'DEC2026']
            
            # Calculate totals based on selected month filter
            if selected_month != 'All Months':
                # For specific month, use only that month's columns
                selected_col = selected_month.replace(' ', '')  # Convert "AUG 2025" to "AUG2025"
                amount_col = f"{selected_col}_AMT"
                nights_col = selected_col
                
                # Set available columns to just the selected month
                available_amount_cols = [amount_col] if amount_col in entered_on_data.columns else []
                available_nights_cols = [nights_col] if nights_col in entered_on_data.columns else []
                
                if amount_col in entered_on_data.columns and nights_col in entered_on_data.columns:
                    split_amount = entered_on_data[amount_col].sum()
                    split_nights = entered_on_data[nights_col].sum()
                else:
                    # Fallback if monthly columns don't exist
                    split_amount = entered_on_data['AMOUNT_IN_MONTH'].sum() if 'AMOUNT_IN_MONTH' in entered_on_data.columns else 0
                    split_nights = entered_on_data['NIGHTS_IN_MONTH'].sum() if 'NIGHTS_IN_MONTH' in entered_on_data.columns else 0
            else:
                # For "All Months", sum all available monthly columns
                available_amount_cols = [col for col in monthly_amount_cols if col in entered_on_data.columns]
                available_nights_cols = [col for col in monthly_nights_cols if col in entered_on_data.columns]
                
                # Calculate totals from monthly matrix columns
                if available_amount_cols:
                    split_amount = entered_on_data[available_amount_cols].sum().sum()
                else:
                    # Fallback to AMOUNT_IN_MONTH if monthly columns don't exist
                    split_amount = entered_on_data['AMOUNT_IN_MONTH'].sum() if 'AMOUNT_IN_MONTH' in entered_on_data.columns else 0
                    
                if available_nights_cols:
                    split_nights = entered_on_data[available_nights_cols].sum().sum()
                else:
                    # Fallback to NIGHTS_IN_MONTH if monthly columns don't exist
                    split_nights = entered_on_data['NIGHTS_IN_MONTH'].sum() if 'NIGHTS_IN_MONTH' in entered_on_data.columns else 0
            
            split_adr = split_amount / split_nights if split_nights > 0 else 0
            
            # Original booking totals (before month splitting)
            original_amount = entered_on_data['AMOUNT'].sum() if 'AMOUNT' in entered_on_data.columns else split_amount
            original_nights = entered_on_data['NIGHTS'].sum() if 'NIGHTS' in entered_on_data.columns else split_nights
            original_adr = entered_on_data['ADR'].mean() if 'ADR' in entered_on_data.columns else split_adr
            
            long_bookings = entered_on_data['LONG_BOOKING_FLAG'].sum() if 'LONG_BOOKING_FLAG' in entered_on_data.columns else 0
            
            # Display both sets of metrics with dynamic labeling
            month_label = selected_month if selected_month != 'All Months' else 'All Months'
            st.markdown(f"#### üóìÔ∏è Split Metrics for {month_label}")
            col1, col2, col3, col4, col5 = st.columns(5)
            
            # Custom CSS for much smaller italic KPI text (40% smaller)
            st.markdown("""
            <style>
            /* Target all metric containers globally */
            [data-testid="metric-container"] {
                font-style: italic !important;
                transform: scale(0.6) !important;
                transform-origin: left top !important;
                margin-bottom: -20px !important;
            }
            
            /* Target metric labels */
            [data-testid="metric-container"] > div:first-child {
                font-size: 0.35rem !important;
                font-style: italic !important;
                color: #666 !important;
            }
            
            /* Target metric values */
            [data-testid="metric-container"] > div:last-child {
                font-size: 0.5rem !important;
                font-weight: bold !important;
                font-style: italic !important;
            }
            
            /* Alternative approach using direct styling */
            .small-kpi {
                font-size: 1.02rem !important;
                font-style: italic !important;
                text-align: center;
                padding: 12px;
            }
            .small-kpi .label {
                font-size: 0.88rem !important;
                color: #666;
                margin-bottom: 4px;
            }
            .small-kpi .value {
                font-size: 1.28rem !important;
                font-weight: bold;
            }
            </style>
            """, unsafe_allow_html=True)
            
            # Monthly Split KPIs
            kpi_html = f"""
            <div style="display: flex; justify-content: space-between; gap: 10px;">
                <div class="small-kpi">
                    <div class="label">Total Bookings</div>
                    <div class="value">{total_bookings:,}</div>
                </div>
                <div class="small-kpi">
                    <div class="label">Split Amount</div>
                    <div class="value">AED {split_amount:,.2f}</div>
                </div>
                <div class="small-kpi">
                    <div class="label">Split Nights</div>
                    <div class="value">{int(split_nights):,}</div>
                </div>
                <div class="small-kpi">
                    <div class="label">Split ADR</div>
                    <div class="value">AED {split_adr:.2f}</div>
                </div>
                <div class="small-kpi">
                    <div class="label">Long Bookings (>10 nights)</div>
                    <div class="value">{long_bookings:,}</div>
                </div>
            </div>
            """
            st.markdown(kpi_html, unsafe_allow_html=True)
            
            
            # 7. Top Companies Analysis (AMOUNT multiplied by 1.1 in converter)
            st.markdown(f"### üè¢ Top Companies by Amount for {month_label} (with 1.1x multiplier)")
            if 'COMPANY_CLEAN' in entered_on_data.columns:
                # Calculate company amounts based on selected month filter
                if selected_month != 'All Months':
                    # For specific month, use only that month's amount column
                    selected_col = selected_month.replace(' ', '')  # Convert "AUG 2025" to "AUG2025"
                    amount_col = f"{selected_col}_AMT"
                    if amount_col in entered_on_data.columns:
                        company_amounts = entered_on_data.groupby('COMPANY_CLEAN')[amount_col].sum().sort_values(ascending=False).head(10)
                    else:
                        # Fallback to AMOUNT column if monthly column not found
                        company_amounts = entered_on_data.groupby('COMPANY_CLEAN')['AMOUNT'].sum().sort_values(ascending=False).head(10)
                else:
                    # For "All Months", sum all available monthly amount columns
                    if available_amount_cols:
                        company_amounts = entered_on_data.groupby('COMPANY_CLEAN')[available_amount_cols].sum().sum(axis=1).sort_values(ascending=False).head(10)
                    elif 'AMOUNT_IN_MONTH' in entered_on_data.columns:
                        company_amounts = entered_on_data.groupby('COMPANY_CLEAN')['AMOUNT_IN_MONTH'].sum().sort_values(ascending=False).head(10)
                    else:
                        company_amounts = entered_on_data.groupby('COMPANY_CLEAN')['AMOUNT'].sum().sort_values(ascending=False).head(10)
                
                col1, col2 = st.columns(2)
                with col1:
                    st.markdown("**Pivoted Table:**")
                    company_table = pd.DataFrame({
                        'Company': company_amounts.index,
                        'Total Amount (AED)': company_amounts.values.round(2)
                    })
                    st.dataframe(company_table)
                
                with col2:
                    st.markdown("**Bar Chart:**")
                    st.bar_chart(company_amounts)
            
            # 8. Bookings by INSERT_USER
            st.markdown("### üë§ Bookings by INSERT_USER")
            if 'INSERT_USER' in entered_on_data.columns:
                user_bookings = entered_on_data['INSERT_USER'].value_counts().head(10)
                
                col1, col2 = st.columns(2)
                with col1:
                    st.markdown("**Table:**")
                    user_table = pd.DataFrame({
                        'User': user_bookings.index,
                        'Booking Count': user_bookings.values
                    })
                    st.dataframe(user_table)
                
                with col2:
                    st.markdown("**Bar Chart:**")
                    st.bar_chart(user_bookings)
            
            # 9. Stay Dates Chart
            st.markdown("### üìÖ Stay Dates Distribution")
            if 'ARRIVAL' in entered_on_data.columns:
                try:
                    arrival_dates = pd.to_datetime(entered_on_data['ARRIVAL'])
                    daily_arrivals = arrival_dates.dt.date.value_counts().sort_index()
                    st.bar_chart(daily_arrivals)
                except Exception as e:
                    st.error(f"Error creating stay dates chart: {e}")
            
            # 10. Room Types Analysis (ROOM column)
            st.markdown("### üè® Room Types Booked")
            if 'ROOM' in entered_on_data.columns:
                room_counts = entered_on_data['ROOM'].value_counts().head(15)
                
                col1, col2 = st.columns(2)
                with col1:
                    st.markdown("**Table:**")
                    room_table = pd.DataFrame({
                        'Room Type': room_counts.index,
                        'Count': room_counts.values
                    })
                    st.dataframe(room_table)
                
                with col2:
                    st.markdown("**Chart:**")
                    st.bar_chart(room_counts)
            
            # 12. Seasonal EDA (SEASON column)
            st.markdown(f"### üåû Seasonal Analysis for {month_label}")
            if 'SEASON' in entered_on_data.columns:
                # Create seasonal analysis with monthly columns
                seasonal_agg_dict = {}
                if available_nights_cols:
                    seasonal_agg_dict.update({col: 'sum' for col in available_nights_cols})
                elif 'NIGHTS_IN_MONTH' in entered_on_data.columns:
                    seasonal_agg_dict['NIGHTS_IN_MONTH'] = 'sum'
                    
                if available_amount_cols:
                    seasonal_agg_dict.update({col: ['sum', 'mean'] for col in available_amount_cols})
                elif 'AMOUNT_IN_MONTH' in entered_on_data.columns:
                    seasonal_agg_dict['AMOUNT_IN_MONTH'] = ['sum', 'mean']
                
                seasonal_analysis = entered_on_data.groupby('SEASON').agg(seasonal_agg_dict).round(2)
                st.dataframe(seasonal_analysis)
                
                # Seasonal distribution chart using monthly columns
                if available_nights_cols:
                    seasonal_nights = entered_on_data.groupby('SEASON')[available_nights_cols].sum().sum(axis=1)
                elif 'NIGHTS_IN_MONTH' in entered_on_data.columns:
                    seasonal_nights = entered_on_data.groupby('SEASON')['NIGHTS_IN_MONTH'].sum()
                else:
                    seasonal_nights = entered_on_data.groupby('SEASON')['NIGHTS'].sum()
                st.bar_chart(seasonal_nights)
            
            # 13. Events Analysis (EVENTS_DATES column)
            st.markdown("### üéâ Bookings During Events")
            if 'EVENTS_DATES' in entered_on_data.columns:
                events_data = entered_on_data[entered_on_data['EVENTS_DATES'].notna() & (entered_on_data['EVENTS_DATES'] != '')]
                if not events_data.empty:
                    events_summary = events_data.groupby('EVENTS_DATES').agg({
                        'RESV_ID': 'count',
                        'NIGHTS': 'sum',
                        'ADR': 'mean'
                    }).round(2)
                    events_summary.columns = ['Bookings', 'Nights', 'Average ADR']
                    st.dataframe(events_summary)
                else:
                    st.info("No bookings found during events.")
            
            # 14. Interactive Booking Lead Times Analysis
            st.markdown("### ‚è∞ Interactive Booking Lead Times")
            if 'BOOKING_LEAD_TIME' in entered_on_data.columns:
                lead_times = entered_on_data['BOOKING_LEAD_TIME'].dropna()
                if not lead_times.empty:
                    try:
                        import plotly.express as px
                        import plotly.graph_objects as go
                        import numpy as np
                        
                        # Create interactive histogram with zoom capabilities
                        fig = go.Figure()
                        
                        fig.add_trace(go.Histogram(
                            x=lead_times,
                            nbinsx=30,
                            name='Lead Times',
                            marker_color='skyblue',
                            marker_line_color='darkblue',
                            marker_line_width=1,
                            opacity=0.7,
                            hovertemplate='Lead Time: %{x} days<br>Count: %{y}<extra></extra>'
                        ))
                        
                        fig.update_layout(
                            title='Interactive Booking Lead Times Distribution',
                            xaxis_title='Lead Time (Days)',
                            yaxis_title='Frequency',
                            height=400,
                            hovermode='closest',
                            title_x=0.5
                        )
                        
                        # Add statistical annotations
                        mean_lead = lead_times.mean()
                        median_lead = lead_times.median()
                        
                        fig.add_vline(x=mean_lead, line_dash="dash", line_color="red", 
                                    annotation_text=f"Mean: {mean_lead:.1f}d")
                        fig.add_vline(x=median_lead, line_dash="dash", line_color="green", 
                                    annotation_text=f"Median: {median_lead:.1f}d")
                        
                        st.plotly_chart(fig, use_container_width=True)
                        
                        # Enhanced summary stats with quartiles
                        col1, col2, col3, col4 = st.columns(4)
                        with col1:
                            st.metric("Average Lead Time", f"{lead_times.mean():.1f} days")
                        with col2:
                            st.metric("Median Lead Time", f"{lead_times.median():.1f} days")
                        with col3:
                            st.metric("25th Percentile", f"{lead_times.quantile(0.25):.1f} days")
                        with col4:
                            st.metric("75th Percentile", f"{lead_times.quantile(0.75):.1f} days")
                        
                        # Lead time distribution table
                        st.markdown("**Lead Time Distribution:**")
                        lead_time_ranges = pd.cut(lead_times, 
                                                bins=[0, 7, 14, 30, 60, 90, float('inf')], 
                                                labels=['0-7 days', '8-14 days', '15-30 days', 
                                                       '31-60 days', '61-90 days', '90+ days'])
                        range_counts = lead_time_ranges.value_counts().sort_index()
                        
                        range_df = pd.DataFrame({
                            'Lead Time Range': range_counts.index,
                            'Count': range_counts.values,
                            'Percentage': (range_counts.values / len(lead_times) * 100).round(1)
                        })
                        st.dataframe(range_df, use_container_width=True)
                        
                    except Exception as e:
                        st.error(f"Error creating interactive lead times chart: {e}")
                        st.bar_chart(lead_times.value_counts().head(20))
            
            # 15. ADR Descriptive Statistics with Error Handling (Column O)
            st.markdown("### üí∞ ADR Descriptive Statistics")
            if 'ADR' in entered_on_data.columns and 'SEASON' in entered_on_data.columns:
                try:
                    import scipy.stats as stats
                    import numpy as np
                    
                    # Overall ADR stats from Column O
                    adr_data = entered_on_data['ADR'].dropna()
                    
                    def safe_stat(func, data, default="N/A"):
                        try:
                            result = func(data)
                            return result if not np.isnan(result) else default
                        except:
                            return default
                    
                    def safe_mode(data):
                        try:
                            mode_result = stats.mode(data, keepdims=True)
                            if len(mode_result.mode) > 0:
                                return mode_result.mode[0]
                            return "N/A"
                        except:
                            return "N/A"
                    
                    stats_dict = {
                        'Mean': safe_stat(np.mean, adr_data),
                        'Standard Error': safe_stat(lambda x: stats.sem(x), adr_data),
                        'Median': safe_stat(np.median, adr_data),
                        'Mode': safe_mode(adr_data),
                        'Standard Deviation': safe_stat(np.std, adr_data),
                        'Sample Variance': safe_stat(np.var, adr_data),
                        'Kurtosis': safe_stat(stats.kurtosis, adr_data),
                        'Skewness': safe_stat(stats.skew, adr_data),
                        'Range': safe_stat(lambda x: np.max(x) - np.min(x), adr_data),
                        'Minimum': safe_stat(np.min, adr_data),
                        'Maximum': safe_stat(np.max, adr_data),
                        'Sum': safe_stat(np.sum, adr_data),
                        'Count': len(adr_data),
                        'Largest(1)': safe_stat(np.max, adr_data),
                        'Smallest(1)': safe_stat(np.min, adr_data),
                        'Confidence Level(95.0%)': safe_stat(lambda x: 1.96 * stats.sem(x), adr_data)
                    }
                    
                    # Format numeric values
                    for key, value in stats_dict.items():
                        if isinstance(value, (int, float)) and value != "N/A":
                            if key in ['Count']:
                                stats_dict[key] = f"{int(value):,}"
                            else:
                                stats_dict[key] = f"{value:.2f}"
                    
                    # Display overall stats
                    st.markdown("**Overall ADR Statistics:**")
                    stats_df = pd.DataFrame(list(stats_dict.items()), columns=['Statistic', 'Value'])
                    st.dataframe(stats_df)
                    
                    # Interactive Seasonal ADR Analysis with Plotly
                    st.markdown("**Interactive Seasonal ADR Analysis:**")
                    try:
                        import plotly.express as px
                        import plotly.graph_objects as go
                        from plotly.subplots import make_subplots
                        
                        # Create subplot with reduced height
                        fig = make_subplots(
                            rows=1, cols=2,
                            subplot_titles=('ADR Distribution by Season', 'ADR Box Plot by Season'),
                            horizontal_spacing=0.15
                        )
                        
                        seasons = entered_on_data['SEASON'].unique()
                        colors = ['#FF6B6B', '#4ECDC4', '#45B7D1', '#FFA07A']
                        
                        # Histogram by season (Column O)
                        for i, season in enumerate(seasons):
                            season_adr = entered_on_data[entered_on_data['SEASON'] == season]['ADR'].dropna()
                            if not season_adr.empty:
                                fig.add_trace(
                                    go.Histogram(
                                        x=season_adr,
                                        name=season,
                                        opacity=0.7,
                                        nbinsx=20,
                                        marker_color=colors[i % len(colors)]
                                    ),
                                    row=1, col=1
                                )
                        
                        # Box plot by season (Column O)
                        for i, season in enumerate(seasons):
                            season_adr = entered_on_data[entered_on_data['SEASON'] == season]['ADR'].dropna()
                            if not season_adr.empty:
                                fig.add_trace(
                                    go.Box(
                                        y=season_adr,
                                        name=season,
                                        marker_color=colors[i % len(colors)],
                                        showlegend=False
                                    ),
                                    row=1, col=2
                                )
                        
                        # Update layout with reduced size and zoom capabilities
                        fig.update_layout(
                            height=350,  # Reduced height
                            title_text="Interactive Seasonal ADR Analysis",
                            title_x=0.5,
                            barmode='overlay',
                            hovermode='closest'
                        )
                        
                        # Update x-axis labels
                        fig.update_xaxes(title_text="ADR (AED)", row=1, col=1)
                        fig.update_xaxes(title_text="Season", row=1, col=2)
                        fig.update_yaxes(title_text="Frequency", row=1, col=1)
                        fig.update_yaxes(title_text="ADR (AED)", row=1, col=2)
                        
                        st.plotly_chart(fig, use_container_width=True)
                        
                        # Quick seasonal summary (Column O)
                        seasonal_summary = entered_on_data.groupby('SEASON')['ADR'].agg(['mean', 'median', 'std', 'count']).round(2)
                        seasonal_summary.columns = ['Mean ADR', 'Median ADR', 'Std Dev', 'Count']
                        st.dataframe(seasonal_summary, use_container_width=True)
                        
                    except Exception as e:
                        st.error(f"Error creating interactive ADR charts: {e}")
                        # Fallback to simple bar chart (Column O)
                        seasonal_adr = entered_on_data.groupby('SEASON')['ADR'].mean()
                        st.bar_chart(seasonal_adr)
                        
                except Exception as e:
                    st.error(f"Error in ADR analysis: {e}")
            
            # 15.5. Top 5 Most Booked Months (by Split Dates)
            st.markdown("### üìÖüî• Top 5 Most Booked Months (by Split Dates)")
            try:
                # Get available monthly columns and calculate total nights for each month
                monthly_cols = ['AUG2025', 'SEP2025', 'OCT2025', 'NOV2025', 'DEC2025', 'JAN2026', 'FEB2026', 'MAR2026', 'APR2026', 'MAY2026', 'JUN2026', 'JUL2026', 'AUG2026', 'SEP2026', 'OCT2026', 'NOV2026', 'DEC2026']
                
                available_monthly_cols = [col for col in monthly_cols if col in entered_on_data.columns]
                
                if available_monthly_cols:
                    # Calculate total nights for each month
                    month_totals = {}
                    for col in available_monthly_cols:
                        total_nights = entered_on_data[col].sum()
                        if total_nights > 0:
                            month_name = col.replace('2025', ' 2025').replace('2026', ' 2026')
                            month_totals[month_name] = total_nights
                    
                    if month_totals:
                        # Sort and get top 5 months
                        top_months = pd.Series(month_totals).sort_values(ascending=False).head(5)
                        
                        col1, col2 = st.columns(2)
                        with col1:
                            st.markdown("**üìä Table:**")
                            months_table = pd.DataFrame({
                                'Month': top_months.index,
                                'Total Nights': top_months.values.astype(int)
                            })
                            st.dataframe(months_table, use_container_width=True)
                        
                        with col2:
                            st.markdown("**üìà Chart:**")
                            st.bar_chart(top_months)
                    else:
                        st.info("No monthly split data available.")
                else:
                    st.info("Monthly columns not found in data.")
            except Exception as e:
                st.error(f"Error creating top months chart: {e}")
            
            # 16. Top 5 Companies per Month Analysis
            st.markdown("### üè¢üìÖ Top 5 Companies per Month Analysis")
            if 'COMPANY_CLEAN' in entered_on_data.columns:
                try:
                    # Get available monthly columns
                    monthly_cols = ['AUG2025', 'SEP2025', 'OCT2025', 'NOV2025', 'DEC2025', 'JAN2026', 'FEB2026', 'MAR2026', 'APR2026', 'MAY2026', 'JUN2026', 'JUL2026', 'AUG2026', 'SEP2026', 'OCT2026', 'NOV2026', 'DEC2026']
                    available_monthly_cols = [col for col in monthly_cols if col in entered_on_data.columns and entered_on_data[col].sum() > 0]
                    
                    if available_monthly_cols:
                        # Create a comprehensive table showing top 5 companies for each month
                        monthly_company_data = {}
                        
                        for month_col in available_monthly_cols:
                            # Get top 5 companies for this month (based on nights)
                            month_companies = entered_on_data[entered_on_data[month_col] > 0].groupby('COMPANY_CLEAN')[month_col].sum().nlargest(5)
                            month_name = month_col.replace('2025', ' 2025').replace('2026', ' 2026')
                            monthly_company_data[month_name] = month_companies
                        
                        if monthly_company_data:
                            # Create a comprehensive pivot table
                            all_companies = set()
                            for month_data in monthly_company_data.values():
                                all_companies.update(month_data.index)
                            
                            # Create matrix for display
                            company_month_matrix = pd.DataFrame(index=sorted(list(all_companies)), columns=sorted(monthly_company_data.keys()))
                            
                            for month, companies in monthly_company_data.items():
                                for company, nights in companies.items():
                                    company_month_matrix.loc[company, month] = int(nights)
                            
                            company_month_matrix = company_month_matrix.fillna(0).astype(int)
                            
                            # Show only companies that appear in top 5 for at least one month
                            active_companies = company_month_matrix[(company_month_matrix > 0).any(axis=1)]
                            
                            col1, col2 = st.columns([3, 2])
                            
                            with col1:
                                st.markdown("**üìä Top 5 Companies per Month (Nights):**")
                                st.dataframe(active_companies, use_container_width=True)
                            
                            with col2:
                                st.markdown("**üìà Interactive Chart:**")
                                # Create individual month breakdown
                                for i, (month, companies) in enumerate(list(monthly_company_data.items())[:3]):  # Show first 3 months
                                    if not companies.empty:
                                        st.markdown(f"**{month}:**")
                                        companies_df = pd.DataFrame({
                                            'Company': companies.index,
                                            'Nights': companies.values
                                        })
                                        st.bar_chart(companies, height=200)
                                        if i < 2:  # Add spacing except for last
                                            st.markdown("---")
                        else:
                            st.info("No monthly company data available.")
                    else:
                        st.info("No monthly split data found.")
                        
                except Exception as e:
                    st.error(f"Error creating company analysis: {e}")
                    # Fallback to simple analysis
                    if 'COMPANY_CLEAN' in entered_on_data.columns:
                        top_companies = entered_on_data.groupby('COMPANY_CLEAN')['NIGHTS'].sum().nlargest(5)
                        st.bar_chart(top_companies)
            
            
            # 18. Monthly Matrix View - Aug 2025 to Dec 2026
            st.markdown("### üìä Monthly Matrix View (Aug 2025 - Dec 2026)")
            st.markdown("**Note:** This view obeys the Month Filter selection from above. Use 'All Months' to see full matrix.")
            
            # Define all monthly columns
            all_monthly_columns = ['AUG2025', 'SEP2025', 'OCT2025', 'NOV2025', 'DEC2025', 'JAN2026', 'FEB2026', 'MAR2026', 'APR2026', 'MAY2026', 'JUN2026', 'JUL2026', 'AUG2026', 'SEP2026', 'OCT2026', 'NOV2026', 'DEC2026']
            all_amount_columns = ['AUG2025_AMT', 'SEP2025_AMT', 'OCT2025_AMT', 'NOV2025_AMT', 'DEC2025_AMT', 'JAN2026_AMT', 'FEB2026_AMT', 'MAR2026_AMT', 'APR2026_AMT', 'MAY2026_AMT', 'JUN2026_AMT', 'JUL2026_AMT', 'AUG2026_AMT', 'SEP2026_AMT', 'OCT2026_AMT', 'NOV2026_AMT', 'DEC2026_AMT']
            
            # Apply month filter logic to determine which columns to show
            if selected_month != 'All Months':
                # Show only the selected month
                selected_col = selected_month.replace(' ', '')
                if selected_col in all_monthly_columns:
                    monthly_columns = [selected_col]
                    amount_columns = [f"{selected_col}_AMT"]
                else:
                    monthly_columns = all_monthly_columns
                    amount_columns = all_amount_columns
            else:
                # Show all months
                monthly_columns = all_monthly_columns
                amount_columns = all_amount_columns
            
            has_monthly_data = any(col in entered_on_data.columns for col in monthly_columns)
            has_amount_data = any(col in entered_on_data.columns for col in amount_columns)
            
            if has_monthly_data or has_amount_data:
                matrix_type = st.selectbox("Select Matrix Type", ["Nights", "Revenue", "Both"], key="matrix_type")
                
                # Prepare data based on unique reservations
                if 'RESV_ID' in entered_on_data.columns:
                    matrix_data = entered_on_data.drop_duplicates(subset=['RESV_ID'])
                else:
                    matrix_data = entered_on_data.drop_duplicates(subset=['FULL_NAME'])
                
                if matrix_type == "Nights" and has_monthly_data:
                    available_nights_cols = [col for col in monthly_columns if col in matrix_data.columns]
                    if available_nights_cols:
                        nights_matrix = matrix_data[['COMPANY_CLEAN'] + available_nights_cols].groupby('COMPANY_CLEAN').sum()
                        nights_matrix = nights_matrix.loc[(nights_matrix != 0).any(axis=1)]  # Remove rows with all zeros
                        nights_matrix = nights_matrix.head(15)  # Show top 15 companies
                        
                        st.markdown("**Room Nights by Company and Month:**")
                        st.dataframe(nights_matrix, use_container_width=True)
                        
                        # Create a heatmap for nights with RED color and show numbers
                        try:
                            import plotly.express as px
                            import plotly.graph_objects as go
                            
                            # Create heatmap with custom colors and text
                            fig = go.Figure(data=go.Heatmap(
                                z=nights_matrix.values,
                                x=nights_matrix.columns,
                                y=nights_matrix.index,
                                colorscale='Reds',  # Changed to red
                                text=nights_matrix.values,  # Show numbers
                                texttemplate="%{text}",
                                textfont={"size": 10},
                                hoverongaps=False,
                                colorbar=dict(title="Number of Nights")
                            ))
                            
                            fig.update_layout(
                                title="Room Nights Heatmap",
                                height=500,
                                xaxis_title="Month",
                                yaxis_title="Company"
                            )
                            st.plotly_chart(fig, use_container_width=True)
                        except Exception as e:
                            st.warning(f"Could not create heatmap: {e}")
                
                elif matrix_type == "Revenue" and has_amount_data:
                    available_amount_cols = [col for col in amount_columns if col in matrix_data.columns]
                    if available_amount_cols:
                        amount_matrix = matrix_data[['COMPANY_CLEAN'] + available_amount_cols].groupby('COMPANY_CLEAN').sum()
                        amount_matrix = amount_matrix.loc[(amount_matrix != 0).any(axis=1)]  # Remove rows with all zeros
                        amount_matrix = amount_matrix.head(15)  # Show top 15 companies
                        
                        # Format for display (with AED labels)
                        display_matrix = amount_matrix.copy()
                        for col in display_matrix.columns:
                            display_matrix[col] = display_matrix[col].apply(lambda x: f"AED {x:,.0f}" if x != 0 else "")
                        
                        st.markdown("**Revenue by Company and Month:**")
                        st.dataframe(display_matrix, use_container_width=True)
                        
                        # Create a heatmap for revenue with RED color and show numbers
                        try:
                            import plotly.express as px
                            import plotly.graph_objects as go
                            
                            # Create heatmap with custom colors and text
                            fig = go.Figure(data=go.Heatmap(
                                z=amount_matrix.values,
                                x=amount_matrix.columns,
                                y=amount_matrix.index,
                                colorscale='Reds',  # Changed to red
                                text=amount_matrix.values,  # Show numbers
                                texttemplate="%{text:,.0f}",  # Format numbers with commas
                                textfont={"size": 10},
                                hoverongaps=False,
                                colorbar=dict(title="Revenue (AED)")
                            ))
                            
                            fig.update_layout(
                                title="Revenue Heatmap (AED)",
                                height=500,
                                xaxis_title="Month",
                                yaxis_title="Company"
                            )
                            st.plotly_chart(fig, use_container_width=True)
                        except Exception as e:
                            st.warning(f"Could not create revenue heatmap: {e}")
                
                elif matrix_type == "Both" and has_monthly_data and has_amount_data:
                    available_nights_cols = [col for col in monthly_columns if col in matrix_data.columns]
                    available_amount_cols = [col for col in amount_columns if col in matrix_data.columns]
                    
                    if available_nights_cols and available_amount_cols:
                        combined_data = matrix_data[['COMPANY_CLEAN'] + available_nights_cols + available_amount_cols].groupby('COMPANY_CLEAN').sum()
                        combined_data = combined_data.loc[(combined_data != 0).any(axis=1)].head(10)  # Top 10 for both views
                        
                        col1, col2 = st.columns(2)
                        with col1:
                            st.markdown("**Nights Matrix:**")
                            nights_display = combined_data[available_nights_cols]
                            st.dataframe(nights_display, use_container_width=True)
                        
                        with col2:
                            st.markdown("**Revenue Matrix:**")
                            amount_display = combined_data[available_amount_cols].copy()
                            for col in amount_display.columns:
                                amount_display[col] = amount_display[col].apply(lambda x: f"AED {x:,.0f}" if x != 0 else "")
                            st.dataframe(amount_display, use_container_width=True)
            else:
                st.info("üìã Monthly matrix data not available. This requires processing with the updated converter.")
            
            
        else:
            st.info("No Entered On data available. Please upload an Excel file to get started.")
    
    with reservations_tab:
        st.subheader("üìã Reservations Entered - SQL Data View")
        st.info("View and analyze converted reservation data loaded into SQL database with conditional formatting.")
        
        # Load data from database
        entered_on_data = None
        if database_available:
            try:
                db = get_database()
                entered_on_data = db.get_entered_on_data()
                if not entered_on_data.empty:
                    st.success(f"‚úÖ Loaded {len(entered_on_data)} reservations from SQL database")
                else:
                    st.warning("‚ö†Ô∏è No reservations found in database")
            except Exception as e:
                st.error(f"‚ùå Failed to load from database: {e}")
        else:
            # Fallback to session state
            entered_on_data = st.session_state.get('entered_on_data')
            if entered_on_data is not None and not entered_on_data.empty:
                st.info("üìä Showing data from session state")
        
        if entered_on_data is not None and not entered_on_data.empty:
            # Display key metrics
            col1, col2, col3, col4 = st.columns(4)
            with col1:
                total_reservations = len(entered_on_data)
                st.metric("Total Reservations", f"{total_reservations:,}")
            with col2:
                # Calculate total revenue from monthly columns
                if available_amount_cols:
                    total_revenue = entered_on_data[available_amount_cols].sum().sum()
                elif 'AMOUNT_IN_MONTH' in entered_on_data.columns:
                    total_revenue = entered_on_data['AMOUNT_IN_MONTH'].sum()
                else:
                    total_revenue = entered_on_data['AMOUNT'].sum()
                st.metric("Total Revenue", f"AED {total_revenue:,.2f}")
            with col3:
                avg_adr = entered_on_data['ADR'].mean()
                st.metric("Average ADR", f"AED {avg_adr:.2f}")
            with col4:
                avg_nights = entered_on_data['NIGHTS'].mean()
                st.metric("Avg Stay Length", f"{avg_nights:.1f} nights")
            
            st.markdown("---")
            
            # Filters for data view
            st.markdown("### üîç Data Filters")
            col1, col2, col3 = st.columns(3)
            
            with col1:
                # Company filter
                companies = ['All'] + sorted(entered_on_data['COMPANY_CLEAN'].unique().tolist())
                selected_company = st.selectbox("Filter by Company:", companies, key="res_company_filter")
            
            with col2:
                # Season filter
                seasons = ['All'] + sorted(entered_on_data['SEASON'].unique().tolist())
                selected_season = st.selectbox("Filter by Season:", seasons, key="res_season_filter")
            
            with col3:
                # Booking status filter (if available)
                if 'SHORT_RESV_STATUS' in entered_on_data.columns:
                    statuses = ['All'] + sorted(entered_on_data['SHORT_RESV_STATUS'].unique().tolist())
                    selected_status = st.selectbox("Filter by Status:", statuses, key="res_status_filter")
                else:
                    selected_status = 'All'
            
            # Apply filters
            filtered_data = entered_on_data.copy()
            
            if selected_company != 'All':
                filtered_data = filtered_data[filtered_data['COMPANY_CLEAN'] == selected_company]
            
            if selected_season != 'All':
                filtered_data = filtered_data[filtered_data['SEASON'] == selected_season]
            
            if selected_status != 'All' and 'SHORT_RESV_STATUS' in filtered_data.columns:
                filtered_data = filtered_data[filtered_data['SHORT_RESV_STATUS'] == selected_status]
            
            st.markdown(f"### üìä Filtered Data View ({len(filtered_data):,} reservations)")
            
            # Display columns selector - use formatted date columns if available
            all_columns = filtered_data.columns.tolist()
            
            # Prefer formatted date columns for display
            arrival_col = 'ARRIVAL_FORMATTED' if 'ARRIVAL_FORMATTED' in all_columns else 'ARRIVAL'
            departure_col = 'DEPARTURE_FORMATTED' if 'DEPARTURE_FORMATTED' in all_columns else 'DEPARTURE'
            
            key_columns = ['FULL_NAME', arrival_col, departure_col, 'NIGHTS', 'AMOUNT', 'ADR', 
                          'COMPANY_CLEAN', 'SEASON', 'SHORT_RESV_STATUS', 'ROOM', 'SPLIT_MONTH']
            available_key_columns = [col for col in key_columns if col in all_columns]
            
            with st.expander("üîß Customize Display Columns"):
                selected_columns = st.multiselect(
                    "Select columns to display:",
                    options=all_columns,
                    default=available_key_columns,
                    key="res_columns_selector"
                )
            
            if not selected_columns:
                selected_columns = available_key_columns
            
            # Prepare data for display with proper conditional formatting
            display_data = filtered_data[selected_columns].copy()
            
            # Keep original data for conditional formatting logic
            original_data = display_data.copy()
            
            # Conditional formatting function
            def highlight_reservations(row):
                """Apply conditional formatting to reservations using original numeric values"""
                styles = [''] * len(row)
                
                # Get corresponding original row for numeric comparisons
                row_idx = row.name
                orig_row = original_data.loc[row_idx] if row_idx in original_data.index else row
                
                # Highlight long bookings (>10 nights)
                if 'NIGHTS' in orig_row.index and pd.notna(orig_row['NIGHTS']):
                    try:
                        nights_val = float(orig_row['NIGHTS'])
                        if nights_val > 10:
                            nights_idx = row.index.get_loc('NIGHTS') if 'NIGHTS' in row.index else None
                            if nights_idx is not None:
                                styles[nights_idx] = 'background-color: #ffcccc; font-weight: bold;'  # Light red
                    except (ValueError, TypeError):
                        pass
                
                # Highlight high ADR (>400 AED)
                if 'ADR' in orig_row.index and pd.notna(orig_row['ADR']):
                    try:
                        adr_val = float(str(orig_row['ADR']).replace('AED ', '').replace(',', ''))
                        if adr_val > 400:
                            adr_idx = row.index.get_loc('ADR') if 'ADR' in row.index else None
                            if adr_idx is not None:
                                styles[adr_idx] = 'background-color: #ccffcc; font-weight: bold;'  # Light green
                    except (ValueError, TypeError):
                        pass
                
                # Highlight cancelled bookings
                if 'SHORT_RESV_STATUS' in orig_row.index and pd.notna(orig_row['SHORT_RESV_STATUS']):
                    if 'CXL' in str(orig_row['SHORT_RESV_STATUS']).upper():
                        status_idx = row.index.get_loc('SHORT_RESV_STATUS') if 'SHORT_RESV_STATUS' in row.index else None
                        if status_idx is not None:
                            styles[status_idx] = 'background-color: #ffffcc; font-weight: bold;'  # Light yellow
                
                # Highlight winter season
                if 'SEASON' in orig_row.index and pd.notna(orig_row['SEASON']):
                    if str(orig_row['SEASON']).lower() == 'winter':
                        season_idx = row.index.get_loc('SEASON') if 'SEASON' in row.index else None
                        if season_idx is not None:
                            styles[season_idx] = 'background-color: #e6f3ff; font-weight: bold;'  # Light blue
                
                # Highlight high amounts (>5000 AED)
                amount_cols_to_check = ['AMOUNT', 'AMOUNT_IN_MONTH', 'AUG2025_AMT', 'SEP2025_AMT', 'OCT2025_AMT', 'NOV2025_AMT', 'DEC2025_AMT', 'JAN2026_AMT', 'FEB2026_AMT', 'MAR2026_AMT', 'APR2026_AMT', 'MAY2026_AMT', 'JUN2026_AMT', 'JUL2026_AMT', 'AUG2026_AMT', 'SEP2026_AMT', 'OCT2026_AMT', 'NOV2026_AMT', 'DEC2026_AMT']
                for amount_col in amount_cols_to_check:
                    if amount_col in orig_row.index and pd.notna(orig_row[amount_col]):
                        try:
                            amount_val = float(str(orig_row[amount_col]).replace('AED ', '').replace(',', ''))
                            if amount_val > 5000:
                                amount_idx = row.index.get_loc(amount_col) if amount_col in row.index else None
                                if amount_idx is not None:
                                    styles[amount_idx] = 'background-color: #f0e6ff; font-weight: bold;'  # Light purple
                        except (ValueError, TypeError):
                            pass
                
                return styles
            
            # Format numeric columns for better display AFTER conditional formatting setup
            if 'AMOUNT' in display_data.columns:
                display_data['AMOUNT'] = display_data['AMOUNT'].apply(lambda x: f"AED {x:,.2f}" if pd.notna(x) else "")
            if 'ADR' in display_data.columns:
                display_data['ADR'] = display_data['ADR'].apply(lambda x: f"AED {x:,.2f}" if pd.notna(x) else "")
            if 'AMOUNT_IN_MONTH' in display_data.columns:
                display_data['AMOUNT_IN_MONTH'] = display_data['AMOUNT_IN_MONTH'].apply(lambda x: f"AED {x:,.2f}" if pd.notna(x) else "")
            
            # Format monthly amount columns
            amount_columns = ['AUG2025_AMT', 'SEP2025_AMT', 'OCT2025_AMT', 'NOV2025_AMT', 'DEC2025_AMT', 'JAN2026_AMT', 'FEB2026_AMT', 'MAR2026_AMT', 'APR2026_AMT', 'MAY2026_AMT', 'JUN2026_AMT', 'JUL2026_AMT', 'AUG2026_AMT', 'SEP2026_AMT', 'OCT2026_AMT', 'NOV2026_AMT', 'DEC2026_AMT']
            for amount_col in amount_columns:
                if amount_col in display_data.columns:
                    display_data[amount_col] = display_data[amount_col].apply(lambda x: f"AED {x:,.2f}" if pd.notna(x) and x != 0 else "")
            
            try:
                # Apply conditional formatting
                styled_data = display_data.style.apply(highlight_reservations, axis=1)
                st.dataframe(styled_data, use_container_width=True, height=600)
                
                # Show formatting success indicator
                st.success("‚úÖ Conditional formatting applied successfully!")
                
            except Exception as e:
                # Fallback without styling if there are issues
                st.warning(f"‚ö†Ô∏è Conditional formatting failed: {str(e)}")
                st.dataframe(display_data, use_container_width=True, height=600)
            
            # Formatting legend
            st.markdown("#### üé® Conditional Formatting Legend:")
            legend_cols = st.columns(5)
            with legend_cols[0]:
                st.markdown('<div style="background-color: #ffcccc; padding: 5px; border-radius: 3px; margin: 2px;">üî¥ Long Bookings (>10 nights)</div>', unsafe_allow_html=True)
            with legend_cols[1]:
                st.markdown('<div style="background-color: #ccffcc; padding: 5px; border-radius: 3px; margin: 2px;">üü¢ High ADR (>400 AED)</div>', unsafe_allow_html=True)
            with legend_cols[2]:
                st.markdown('<div style="background-color: #ffffcc; padding: 5px; border-radius: 3px; margin: 2px;">üü° Cancelled Bookings</div>', unsafe_allow_html=True)
            with legend_cols[3]:
                st.markdown('<div style="background-color: #e6f3ff; padding: 5px; border-radius: 3px; margin: 2px;">üîµ Winter Season</div>', unsafe_allow_html=True)
            with legend_cols[4]:
                st.markdown('<div style="background-color: #f0e6ff; padding: 5px; border-radius: 3px; margin: 2px;">üü£ High Amount (>5000 AED)</div>', unsafe_allow_html=True)
            
            # Export option
            st.markdown("---")
            if st.button("üì• Download Filtered Data as CSV"):
                csv = display_data.to_csv(index=False)
                st.download_button(
                    label="Download CSV",
                    data=csv,
                    file_name=f"reservations_filtered_{len(filtered_data)}_records.csv",
                    mime="text/csv"
                )
            
        else:
            st.info("üìù No reservation data available. Please upload data in the 'Entered On' tab first.")
    
    with arrivals_tab:
        st.subheader("üö™ Arrivals Comprehensive Analysis")
        st.info("Upload and analyze Arrival Report Excel files with automatic conversion and comprehensive analytics.")
        
        # File upload section with auto-conversion
        st.markdown("### üìÅ Upload Arrival Report")
        uploaded_file = st.file_uploader(
            "Choose an Arrival Report Excel file (.xlsm)",
            type=['xlsm'],
            help="Upload an Excel file with 'ARRIVAL CHECK' sheet - automatic conversion will begin immediately",
            key="arrivals_uploader"
        )
        
        # Auto-convert when file is uploaded
        if uploaded_file is not None:
            try:
                # Save uploaded file temporarily
                import tempfile
                import os
                
                with tempfile.NamedTemporaryFile(delete=False, suffix='.xlsm') as tmp_file:
                    tmp_file.write(uploaded_file.getvalue())
                    temp_path = tmp_file.name
                
                # Auto-convert immediately
                conversion_status = st.empty()
                conversion_status.info("üîÑ Auto-converting Arrival Report...")
                
                try:
                    # Import converter
                    import sys
                    sys.path.append('.')
                    from converters.arrival_converter import process_arrival_report, get_arrival_summary_stats
                    
                    # Process the file
                    df, csv_path = process_arrival_report(temp_path)
                    conversion_status.success("‚úÖ Auto-conversion completed successfully!")
                    
                    # Clear any old cached data and store fresh data
                    if 'arrivals_data' in st.session_state:
                        del st.session_state.arrivals_data
                    st.session_state.arrivals_data = df
                    
                    # Load to database if available
                    if database_available:
                        db_status = st.empty()
                        db_status.info("üîÑ Loading data to SQL database...")
                        
                        try:
                            db = get_database()
                            success = db.ingest_arrivals_data(df)
                            
                            if success:
                                pass
                            else:
                                db_status.error("‚ùå Failed to load data to database")
                        except Exception as e:
                            db_status.warning(f"‚ö†Ô∏è Database storage not available: {str(e)}")
                    
                except Exception as e:
                    conversion_status.error(f"‚ùå Auto-conversion failed: {str(e)}")
                    conversion_logger.error(f"Arrival conversion error: {e}")
                finally:
                    # Clean up temp file
                    if os.path.exists(temp_path):
                        os.unlink(temp_path)
                        
            except Exception as e:
                st.error(f"Error uploading file: {str(e)}")
        
        # Load and display current data
        arrivals_data = st.session_state.get('arrivals_data')
        
        # Try to load from database first, then CSV as fallback
        if arrivals_data is None:
            if database_available:
                try:
                    db = get_database()
                    arrivals_data = db.get_arrivals_data()
                    if not arrivals_data.empty:
                        st.session_state.arrivals_data = arrivals_data
                        st.info(f"‚úÖ Loaded arrival data from database: {len(arrivals_data)} records")
                except Exception as e:
                    conversion_logger.error(f"Failed to load arrivals data from database: {e}")
            
            # Fallback to CSV if database not available or empty
            if arrivals_data is None or arrivals_data.empty:
                try:
                    csv_path = "data/processed/arrival_check.csv"
                    if os.path.exists(csv_path):
                        arrivals_data = pd.read_csv(csv_path)
                        # Convert date columns
                        date_cols = ['ARRIVAL', 'DEPARTURE']
                        for col in date_cols:
                            if col in arrivals_data.columns:
                                arrivals_data[col] = pd.to_datetime(arrivals_data[col])
                        st.session_state.arrivals_data = arrivals_data
                        st.info(f"‚úÖ Loaded existing arrival data from CSV: {len(arrivals_data)} records")
                except Exception as e:
                    conversion_logger.error(f"Failed to load existing arrival data: {e}")
        
        if arrivals_data is not None and not arrivals_data.empty:
            # Comprehensive Analysis Section
            st.markdown("---")
            st.markdown("## üìä Comprehensive Arrival Analytics")
            
            # KPI Cards for Arrival Dates
            st.markdown("### üìà *Key Performance Indicators*")
            col1, col2, col3, col4, col5 = st.columns(5)
            
            total_arrivals = len(arrivals_data)
            unique_companies = arrivals_data['COMPANY_NAME_CLEAN'].nunique()
            total_amount = arrivals_data['AMOUNT'].sum()
            total_deposit = arrivals_data['DEPOSIT_PAID_CLEAN'].sum()
            avg_adr = arrivals_data['CALCULATED_ADR'].mean()
            
            with col1:
                st.metric("Total Arrivals", f"{total_arrivals:,}")
            with col2:
                st.metric("Unique Companies", f"{unique_companies:,}")
            with col3:
                st.metric("Total Revenue", f"AED {total_amount:,.0f}")
            with col4:
                st.metric("Total Deposits", f"AED {total_deposit:,.0f}")
            with col5:
                st.metric("Average ADR", f"AED {avg_adr:.0f}")
            
            # 1. Highest Arrival Count by Company (Horizontal Bar Chart)
            st.markdown("### üè¢ Highest Arrival Count by Company")
            company_arrivals = arrivals_data.groupby('COMPANY_NAME_CLEAN')['ARRIVAL_COUNT'].sum().sort_values(ascending=True).tail(15)
            
            fig_company = px.bar(
                x=company_arrivals.values,
                y=company_arrivals.index,
                orientation='h',
                title="Top 15 Companies by Arrival Count",
                labels={'x': 'Number of Arrivals', 'y': 'Company Name'}
            )
            fig_company.update_layout(height=500, showlegend=False)
            # Simple blue color for all bars
            fig_company.update_traces(marker_color='#1f77b4')
            st.plotly_chart(fig_company, use_container_width=True)
            
            # 2. Company Deposit Analysis with T-Company Flagging
            st.markdown("### üí∞ Company Deposit Analysis")
            col1, col2 = st.columns(2)
            
            with col1:
                # Deposit pivot table
                deposit_pivot = arrivals_data.groupby('COMPANY_NAME_CLEAN').agg({
                    'DEPOSIT_PAID_CLEAN': ['sum', 'count'],
                    'COMPANY_FLAGGED': 'first',
                    'AMOUNT': 'sum'
                }).round(2)
                deposit_pivot.columns = ['Total_Deposit', 'Booking_Count', 'Flagged', 'Total_Amount']
                deposit_pivot = deposit_pivot.sort_values('Total_Deposit', ascending=False)
                
                # Flag T-companies
                t_companies = deposit_pivot[deposit_pivot.index.str.startswith('T-', na=False)]
                if not t_companies.empty:
                    st.markdown("**üö© T-Companies Flagged:**")
                    st.dataframe(t_companies)
                
                st.markdown("**üí∏ All Companies - Deposit Summary:**")
                st.dataframe(deposit_pivot.head(20))
            
            with col2:
                # Deposit payment distribution
                deposit_dist = arrivals_data.groupby(['COMPANY_NAME_CLEAN', 'HAS_DEPOSIT']).size().unstack(fill_value=0)
                if 1 in deposit_dist.columns and 0 in deposit_dist.columns:
                    deposit_dist.columns = ['No_Deposit', 'Has_Deposit']
                    deposit_dist['Total'] = deposit_dist.sum(axis=1)
                    deposit_dist = deposit_dist.sort_values('Total', ascending=False).head(10)
                    
                    fig_deposit = px.bar(
                        deposit_dist,
                        x=['No_Deposit', 'Has_Deposit'],
                        title="Deposit Payment Status by Top Companies",
                        labels={'value': 'Number of Bookings', 'variable': 'Deposit Status'}
                    )
                    st.plotly_chart(fig_deposit, use_container_width=True)
            
            # 3. Booking Lead Time Analysis (>10 days flagging)
            st.markdown("### ‚è∞ Booking Lead Time Analysis")
            if 'LONG_BOOKING_FLAG' in arrivals_data.columns:
                long_bookings = arrivals_data['LONG_BOOKING_FLAG'].sum()
                total_bookings = len(arrivals_data)
                long_booking_pct = (long_bookings / total_bookings) * 100
                
                col1, col2 = st.columns(2)
                with col1:
                    st.metric("Long Bookings (>10 days)", f"{long_bookings:,}", f"{long_booking_pct:.1f}%")
                with col2:
                    st.metric("Regular Bookings (‚â§10 days)", f"{total_bookings - long_bookings:,}")
            
            # 4. Check-out Trend Curve by Company Count
            st.markdown("### üìÖ Check-out Trends by Company Count")
            
            # Daily departure trends only (check-in trend removed since arrival dates are same)
            if 'DEPARTURE' in arrivals_data.columns:
                daily_departures = arrivals_data.groupby(arrivals_data['DEPARTURE'].dt.date).agg({
                    'ARRIVAL_COUNT': 'sum',
                    'COMPANY_NAME_CLEAN': 'nunique'
                }).rename(columns={'ARRIVAL_COUNT': 'DEPARTURE_COUNT', 'COMPANY_NAME_CLEAN': 'Unique_Companies_Departure'})
                
                col1, col2 = st.columns(2)
                with col1:
                    fig_departure = px.line(
                        x=daily_departures.index,
                        y=daily_departures['DEPARTURE_COUNT'],
                        title="Daily Check-out Count Trend",
                        labels={'x': 'Date', 'y': 'Number of Check-outs'},
                        color_discrete_sequence=['#ff7f0e']
                    )
                    st.plotly_chart(fig_departure, use_container_width=True)
                
                with col2:
                    # Show table
                    st.markdown("**üìä Daily Check-outs Table:**")
                    st.dataframe(daily_departures.tail(10))
            
            # 5. Length of Stay Distribution
            st.markdown("### üè® Length of Stay Distribution")
            if 'NIGHTS' in arrivals_data.columns:
                col1, col2 = st.columns(2)
                
                with col1:
                    # Histogram
                    fig_hist = px.histogram(
                        arrivals_data,
                        x='NIGHTS',
                        nbins=20,
                        title="Length of Stay Distribution (Histogram)",
                        labels={'x': 'Number of Nights', 'y': 'Frequency'}
                    )
                    st.plotly_chart(fig_hist, use_container_width=True)
                
                with col2:
                    # Box plot
                    fig_box = px.box(
                        arrivals_data,
                        y='NIGHTS',
                        title="Length of Stay Distribution (Box Plot)",
                        labels={'y': 'Number of Nights'}
                    )
                    st.plotly_chart(fig_box, use_container_width=True)
                
                # Statistics
                col1, col2, col3, col4 = st.columns(4)
                with col1:
                    st.metric("Avg Nights", f"{arrivals_data['NIGHTS'].mean():.1f}")
                with col2:
                    st.metric("Median Nights", f"{arrivals_data['NIGHTS'].median():.0f}")
                with col3:
                    st.metric("Min Nights", f"{arrivals_data['NIGHTS'].min():.0f}")
                with col4:
                    st.metric("Max Nights", f"{arrivals_data['NIGHTS'].max():.0f}")
            
            # 6. Additional Analysis
            st.markdown("### üìä Additional Insights")
            
            # Room type analysis
            if 'ROOM_CATEGORY_LABEL' in arrivals_data.columns:
                room_analysis = arrivals_data.groupby('ROOM_CATEGORY_LABEL').agg({
                    'ARRIVAL_COUNT': 'sum',
                    'AMOUNT': 'sum',
                    'CALCULATED_ADR': 'mean'
                }).round(2)
                
                st.markdown("**üè® Room Category Analysis:**")
                st.dataframe(room_analysis.sort_values('ARRIVAL_COUNT', ascending=False))
        
        else:
            st.info("üö™ No arrival data available. Please upload an Arrival Report Excel file to begin analysis.")
    
    with arrivals_data_tab:
        st.subheader("üìã Arrivals Data Table")
        st.info("View and explore the converted arrival data in tabular format")
        
        # Load arrivals data
        arrivals_data = st.session_state.get('arrivals_data')
        
        # Try to load from database first, then CSV as fallback
        if arrivals_data is None:
            if database_available:
                try:
                    db = get_database()
                    arrivals_data = db.get_arrivals_data()
                    if not arrivals_data.empty:
                        st.session_state.arrivals_data = arrivals_data
                except Exception as e:
                    conversion_logger.error(f"Failed to load arrivals data from database: {e}")
            
            # Fallback to CSV if database not available or empty
            if arrivals_data is None or arrivals_data.empty:
                try:
                    csv_path = "data/processed/arrival_check.csv"
                    if os.path.exists(csv_path):
                        arrivals_data = pd.read_csv(csv_path)
                        # Convert date columns
                        date_cols = ['ARRIVAL', 'DEPARTURE']
                        for col in date_cols:
                            if col in arrivals_data.columns:
                                arrivals_data[col] = pd.to_datetime(arrivals_data[col])
                        st.session_state.arrivals_data = arrivals_data
                except Exception as e:
                    st.error(f"Failed to load arrival data: {e}")
        
        if arrivals_data is not None and not arrivals_data.empty:
            # Data summary
            st.markdown("### üìä Data Summary")
            col1, col2, col3, col4 = st.columns(4)
            with col1:
                st.metric("Total Records", len(arrivals_data))
            with col2:
                st.metric("Total Columns", len(arrivals_data.columns))
            with col3:
                st.metric("Date Range", f"{arrivals_data['ARRIVAL'].min().strftime('%Y-%m-%d')} to {arrivals_data['ARRIVAL'].max().strftime('%Y-%m-%d')}")
            with col4:
                st.metric("Unique Companies", arrivals_data['COMPANY_NAME_CLEAN'].nunique())
            
            # Filters
            st.markdown("### üîç Data Filters")
            col1, col2, col3 = st.columns(3)
            
            with col1:
                # Company filter
                companies = ['All'] + sorted(arrivals_data['COMPANY_NAME_CLEAN'].unique().tolist())
                selected_company = st.selectbox("Filter by Company", companies)
            
            with col2:
                # Date range filter
                min_date = arrivals_data['ARRIVAL'].min().date()
                max_date = arrivals_data['ARRIVAL'].max().date()
                date_range = st.date_input(
                    "Filter by Date Range",
                    value=(min_date, max_date),
                    min_value=min_date,
                    max_value=max_date
                )
            
            with col3:
                # Deposit filter
                deposit_filter = st.selectbox("Filter by Deposit Status", ['All', 'Has Deposit', 'No Deposit'])
            
            # Apply filters
            filtered_data = arrivals_data.copy()
            
            if selected_company != 'All':
                filtered_data = filtered_data[filtered_data['COMPANY_NAME_CLEAN'] == selected_company]
            
            if len(date_range) == 2:
                start_date, end_date = date_range
                filtered_data = filtered_data[
                    (filtered_data['ARRIVAL'].dt.date >= start_date) & 
                    (filtered_data['ARRIVAL'].dt.date <= end_date)
                ]
            
            if deposit_filter == 'Has Deposit':
                filtered_data = filtered_data[filtered_data['HAS_DEPOSIT'] == 1]
            elif deposit_filter == 'No Deposit':
                filtered_data = filtered_data[filtered_data['HAS_DEPOSIT'] == 0]
            
            # Show filtered results
            st.markdown(f"### üìã Filtered Data ({len(filtered_data)} records)")
            
            # Column selector
            all_columns = filtered_data.columns.tolist()
            key_columns = [
                'COMPANY_NAME_CLEAN', 'ARRIVAL', 'DEPARTURE', 'NIGHTS', 
                'PERSONS', 'AMOUNT', 'DEPOSIT_PAID_CLEAN', 'CALCULATED_ADR',
                'RATE_CODE_CLEAN', 'SEASON', 'COMPANY_FLAGGED', 'LONG_BOOKING_FLAG'
            ]
            # Only include columns that exist in the data
            default_columns = [col for col in key_columns if col in all_columns]
            
            selected_columns = st.multiselect(
                "Select Columns to Display",
                all_columns,
                default=default_columns
            )
            
            if selected_columns:
                display_data = filtered_data[selected_columns]
            else:
                display_data = filtered_data
            
            # Display data with pagination
            if len(display_data) > 0:
                # Pagination
                records_per_page = st.slider("Records per page", 10, 100, 25)
                total_pages = (len(display_data) - 1) // records_per_page + 1
                
                if total_pages > 1:
                    page = st.number_input(
                        f"Page (1 to {total_pages})",
                        min_value=1,
                        max_value=total_pages,
                        value=1
                    )
                    start_idx = (page - 1) * records_per_page
                    end_idx = start_idx + records_per_page
                    paginated_data = display_data.iloc[start_idx:end_idx]
                else:
                    paginated_data = display_data
                
                # Display table
                st.dataframe(
                    paginated_data,
                    use_container_width=True,
                    height=600
                )
                
                # Download button
                csv_buffer = io.StringIO()
                filtered_data.to_csv(csv_buffer, index=False)
                csv_data = csv_buffer.getvalue()
                
                st.download_button(
                    label="üì• Download Filtered Data as CSV",
                    data=csv_data,
                    file_name=f"arrival_data_filtered_{datetime.now().strftime('%Y%m%d_%H%M%S')}.csv",
                    mime="text/csv"
                )
                
                # Show summary statistics for filtered data
                if len(filtered_data) > 0:
                    st.markdown("### üìà Filtered Data Statistics")
                    col1, col2, col3, col4 = st.columns(4)
                    
                    with col1:
                        st.metric("Total Amount", f"AED {filtered_data['AMOUNT'].sum():,.0f}")
                    with col2:
                        st.metric("Total Nights", f"{filtered_data['NIGHTS'].sum():,.0f}")
                    with col3:
                        st.metric("Avg ADR", f"AED {filtered_data['CALCULATED_ADR'].mean():.0f}")
                    with col4:
                        st.metric("Total Deposits", f"AED {filtered_data['DEPOSIT_PAID_CLEAN'].sum():,.0f}")
            else:
                st.warning("No data matches the selected filters.")
        
        else:
            st.info("üìã No arrival data available. Please upload an Arrival Report in the 'Arrivals' tab first.")

def historical_forecast_tab():
    """Historical & Forecast tab with sub-tabs for analysis and forecasting"""
    st.header("üìä Historical & Forecast Analysis")
    
    # Initialize historical data if not already loaded
    if 'historical_data_loaded' not in st.session_state:
        st.session_state.historical_data_loaded = False
    
    # Load historical data into SQLite
    if not st.session_state.historical_data_loaded:
        load_historical_data()
        st.session_state.historical_data_loaded = True
    
    # Create sub-tabs
    tab1, tab2 = st.tabs(["üìä Trend Analysis", "üîÆ Time Series Forecast"])
    
    with tab1:
        trend_analysis_subtab()
    
    with tab2:
        time_series_forecast_subtab()

def trend_analysis_subtab():
    """Trend Analysis sub-tab - existing functionality"""
    # Display static KPIs at the top with smaller font
    display_historical_kpis()
    
    st.divider()
    
    # Large trend charts section
    st.subheader("üìà Daily Occupancy Trends (2022-2025)")
    display_occupancy_trends()
    
    st.divider()
    
    st.subheader("üí∞ ADR Trends (2022-2025)")
    display_adr_trends()
    
    st.divider()
    
    # Month filter section
    st.subheader("üìä Monthly Comparison Analysis")
    
    # Month selection
    months = [
        "January", "February", "March", "April", "May", "June",
        "July", "August", "September", "October", "November", "December"
    ]
    
    selected_month = st.selectbox(
        "Select Month for Comparison:",
        months,
        index=7,  # Default to August
        help="Compare data across years for the selected month"
    )
    
    # Display responsive KPIs for selected month
    display_monthly_kpis(selected_month)
    
    # Monthly comparison charts - Occupancy above, ADR below
    st.write("##### Monthly Occupancy Comparison")
    display_monthly_occupancy_comparison(selected_month)
    
    st.divider()
    
    st.write("##### Monthly ADR Comparison")
    display_monthly_adr_comparison(selected_month)

def time_series_forecast_subtab():
    """Time Series Forecast sub-tab - advanced forecasting"""
    st.subheader("üîÆ Time Series Forecasting")
    
    # Display forecast preparation status
    if prepare_forecast_data():
        # Forecast horizon selection
        st.write("**Recommended Forecast Horizons (Per Documentation):**")
        col1, col2 = st.columns(2)
        
        with col1:
            st.info("üìÖ **90-Day Operational Forecast**\nDaily/weekly rolling forecast for operations\n‚Ä¢ Rate decisions and yield management\n‚Ä¢ Tactical staffing and resource planning")
        with col2:
            st.info("üìÖ **12-Month Strategic Forecast**\nMonthly refreshed scenario forecast\n‚Ä¢ Annual budgeting and capital planning\n‚Ä¢ Long-term strategic decisions")
        
        st.divider()
        
        # Generate forecasts
        if st.button("üöÄ Generate Forecasts", use_container_width=True):
            with st.spinner("Generating forecasts... This may take a few minutes."):
                generate_all_forecasts()
        
        # Display existing forecasts if available
        display_forecast_results()
    else:
        st.error("‚ùå Unable to prepare forecast data. Please ensure historical data is properly loaded.")

def load_historical_data():
    """Load historical data files into SQLite database"""
    try:
        db = get_database()
        
        # Historical occupancy files
        occupancy_files = [
            "/home/gee_devops254/Downloads/Revenue Architecture/data/processed/historical_occupancy_2022_040906 - historical_occupancy_2022_040906.csv.csv",
            "/home/gee_devops254/Downloads/Revenue Architecture/data/processed/historical_occupancy_2023_040911 - historical_occupancy_2023_040911.csv.csv",
            "/home/gee_devops254/Downloads/Revenue Architecture/data/processed/historical_occupancy_2024_040917 - historical_occupancy_2024_040917.csv.csv"
        ]
        
        # Historical segment files
        segment_files = [
            "/home/gee_devops254/Downloads/Revenue Architecture/data/processed/Historical-segemtent_2022_ 032622 - Historical-segemtent_2022_ 032622.csv.csv",
            "/home/gee_devops254/Downloads/Revenue Architecture/data/processed/Historical_segment_2023_032649 - Historical_segment_2023_032649.csv.csv",
            "/home/gee_devops254/Downloads/Revenue Architecture/data/processed/Historical_segment_2024_045642.csv (1).csv"
        ]
        
        # Load occupancy data
        for file_path in occupancy_files:
            if os.path.exists(file_path):
                df = pd.read_csv(file_path)
                df['Year'] = pd.to_datetime(df['Date']).dt.year
                
                # Calculate occupancy percentage
                df['Occupancy_Pct'] = (df['Rm Sold'] / 339) * 100
                
                # Save updated CSV with occupancy percentage
                year = df['Year'].iloc[0]
                updated_file_path = file_path.replace('.csv', '_updated.csv')
                df.to_csv(updated_file_path, index=False)
                
                table_name = f"historical_occupancy_{year}"
                db.save_historical_occupancy_data(df, table_name)
        
        # Load segment data
        for file_path in segment_files:
            if os.path.exists(file_path):
                df = pd.read_csv(file_path)
                df['Year'] = pd.to_datetime(df['Month']).dt.year
                table_name = f"historical_segment_{df['Year'].iloc[0]}"
                db.save_historical_segment_data(df, table_name)
        
        st.success("‚úÖ Historical data loaded successfully into SQLite database")
        
    except Exception as e:
        st.error(f"Error loading historical data: {str(e)}")

def display_historical_kpis():
    """Display KPIs for revenue, ADR, and occupancy by year with smaller fonts"""
    try:
        db = get_database()
        
        # Add custom CSS for smaller metrics
        st.markdown("""
        <style>
        .small-metric {
            font-size: 0.8rem;
        }
        .small-metric .metric-value {
            font-size: 1.2rem;
            font-weight: 600;
        }
        .small-metric .metric-label {
            font-size: 0.7rem;
            color: #666;
        }
        </style>
        """, unsafe_allow_html=True)
        
        # Create 4 columns for KPIs (2022, 2023, 2024, 2025)
        col1, col2, col3, col4 = st.columns(4)
        
        years = [2022, 2023, 2024, 2025]
        columns = [col1, col2, col3, col4]
        
        for year, col in zip(years, columns):
            with col:
                st.markdown(f"**{year}**")
                
                if year < 2025:
                    # Get historical data
                    occupancy_data = db.get_historical_occupancy_data(f"historical_occupancy_{year}")
                    
                    if not occupancy_data.empty:
                        total_revenue = occupancy_data['Revenue'].sum()
                        avg_adr = occupancy_data['ADR'].mean()
                        total_rooms_sold = occupancy_data['Rm Sold'].sum()
                        total_days = len(occupancy_data)
                        avg_occupancy_pct = (total_rooms_sold / (total_days * 339)) * 100 if total_days > 0 else 0
                        
                        # Use smaller metrics
                        st.markdown(f'<div class="small-metric"><div class="metric-label">Revenue</div><div class="metric-value">AED {total_revenue:,.0f}</div></div>', unsafe_allow_html=True)
                        st.markdown(f'<div class="small-metric"><div class="metric-label">Avg ADR</div><div class="metric-value">AED {avg_adr:.0f}</div></div>', unsafe_allow_html=True)
                        st.markdown(f'<div class="small-metric"><div class="metric-label">Occupancy</div><div class="metric-value">{avg_occupancy_pct:.1f}%</div></div>', unsafe_allow_html=True)
                    else:
                        st.markdown('<div class="small-metric"><div class="metric-value">No Data</div></div>', unsafe_allow_html=True)
                else:
                    # 2025 - Current year data from main tables
                    current_data = db.get_occupancy_data()
                    if not current_data.empty:
                        # Filter for 2025 data
                        current_data['Date'] = pd.to_datetime(current_data['Date'])
                        current_2025 = current_data[current_data['Date'].dt.year == 2025]
                        
                        if not current_2025.empty:
                            total_revenue = current_2025['Revenue'].sum()
                            avg_adr = current_2025['ADR'].mean()
                            total_rooms_sold = current_2025['Rm_Sold'].sum()
                            total_days = len(current_2025)
                            avg_occupancy_pct = (total_rooms_sold / (total_days * 339)) * 100 if total_days > 0 else 0
                            
                            st.markdown(f'<div class="small-metric"><div class="metric-label">Revenue</div><div class="metric-value">AED {total_revenue:,.0f}</div></div>', unsafe_allow_html=True)
                            st.markdown(f'<div class="small-metric"><div class="metric-label">Avg ADR</div><div class="metric-value">AED {avg_adr:.0f}</div></div>', unsafe_allow_html=True)
                            st.markdown(f'<div class="small-metric"><div class="metric-label">Occupancy</div><div class="metric-value">{avg_occupancy_pct:.1f}%</div></div>', unsafe_allow_html=True)
                        else:
                            st.markdown('<div class="small-metric"><div class="metric-value">No Data</div></div>', unsafe_allow_html=True)
                    else:
                        st.markdown('<div class="small-metric"><div class="metric-value">No Data</div></div>', unsafe_allow_html=True)
        
    except Exception as e:
        st.error(f"Error displaying KPIs: {str(e)}")

def display_occupancy_trends():
    """Display occupancy trends with all years as trend lines"""
    try:
        db = get_database()
        fig = go.Figure()
        
        # Add trend lines for 2022-2024
        for year in [2022, 2023, 2024]:
            occupancy_data = db.get_historical_occupancy_data(f"historical_occupancy_{year}")
            if not occupancy_data.empty:
                occupancy_data['Date'] = pd.to_datetime(occupancy_data['Date'])
                occupancy_data = occupancy_data.sort_values('Date')
                # Calculate occupancy percentage
                occupancy_data['Occupancy_Pct'] = (occupancy_data['Rm Sold'] / 339) * 100
                
                fig.add_trace(go.Scatter(
                    x=occupancy_data['Date'],
                    y=occupancy_data['Occupancy_Pct'],
                    mode='lines',
                    name=f'{year} Occupancy',
                    line=dict(width=2)
                ))
        
        # Add 2025 data as trend line
        current_data = db.get_occupancy_data()
        if not current_data.empty:
            current_data['Date'] = pd.to_datetime(current_data['Date'])
            current_2025 = current_data[current_data['Date'].dt.year == 2025].sort_values('Date')
            
            if not current_2025.empty:
                # Calculate occupancy percentage for 2025
                current_2025['Occupancy_Pct'] = (current_2025['Rm_Sold'] / 339) * 100
                
                fig.add_trace(go.Scatter(
                    x=current_2025['Date'],
                    y=current_2025['Occupancy_Pct'],
                    mode='lines',
                    name='2025 Occupancy',
                    line=dict(width=3, color='orange')
                ))
        
        fig.update_layout(
            title="Daily Occupancy Trends (2022-2025)",
            xaxis_title="Date",
            yaxis_title="Occupancy Percentage (%)",
            hovermode='x unified',
            height=600,
            legend=dict(
                orientation="h",
                yanchor="bottom",
                y=1.02,
                xanchor="right",
                x=1
            )
        )
        
        st.plotly_chart(fig, use_container_width=True)
        
    except Exception as e:
        st.error(f"Error displaying occupancy trends: {str(e)}")

def display_adr_trends():
    """Display ADR trends with all years as trend lines"""
    try:
        db = get_database()
        fig = go.Figure()
        
        # Add trend lines for 2022-2024
        for year in [2022, 2023, 2024]:
            occupancy_data = db.get_historical_occupancy_data(f"historical_occupancy_{year}")
            if not occupancy_data.empty:
                occupancy_data['Date'] = pd.to_datetime(occupancy_data['Date'])
                occupancy_data = occupancy_data.sort_values('Date')
                
                fig.add_trace(go.Scatter(
                    x=occupancy_data['Date'],
                    y=occupancy_data['ADR'],
                    mode='lines',
                    name=f'{year} ADR',
                    line=dict(width=2)
                ))
        
        # Add 2025 data as trend line
        current_data = db.get_occupancy_data()
        if not current_data.empty:
            current_data['Date'] = pd.to_datetime(current_data['Date'])
            current_2025 = current_data[current_data['Date'].dt.year == 2025].sort_values('Date')
            
            if not current_2025.empty:
                fig.add_trace(go.Scatter(
                    x=current_2025['Date'],
                    y=current_2025['ADR'],
                    mode='lines',
                    name='2025 ADR',
                    line=dict(width=3, color='green')
                ))
        
        fig.update_layout(
            title="ADR Trends (2022-2025)",
            xaxis_title="Date",
            yaxis_title="ADR (AED)",
            hovermode='x unified',
            height=600,
            legend=dict(
                orientation="h",
                yanchor="bottom",
                y=1.02,
                xanchor="right",
                x=1
            )
        )
        
        st.plotly_chart(fig, use_container_width=True)
        
    except Exception as e:
        st.error(f"Error displaying ADR trends: {str(e)}")

def display_monthly_kpis(selected_month):
    """Display responsive KPIs for selected month with very small text"""
    try:
        db = get_database()
        month_num = ["January", "February", "March", "April", "May", "June",
                     "July", "August", "September", "October", "November", "December"].index(selected_month) + 1
        
        # Add custom CSS for responsive metrics matching static KPIs
        st.markdown("""
        <style>
        .responsive-metric {
            font-size: 0.9rem;
            text-align: center;
            padding: 8px;
            margin: 3px;
        }
        .responsive-metric .metric-value {
            font-size: 1.4rem;
            font-weight: 700;
            color: #000000;
            margin-bottom: 2px;
        }
        .responsive-metric .metric-label {
            font-size: 0.8rem;
            color: #333;
            font-weight: 600;
            margin-bottom: 3px;
        }
        .responsive-kpi-container {
            display: flex;
            justify-content: space-around;
            margin: 15px 0;
            background: #f8f9fa;
            padding: 15px;
            border-radius: 8px;
            border: 1px solid #e9ecef;
        }
        </style>
        """, unsafe_allow_html=True)
        
        # Create KPI container
        kpi_data = []
        
        # Get data for each year
        for year in [2022, 2023, 2024, 2025]:
            if year < 2025:
                # Historical data
                occupancy_data = db.get_historical_occupancy_data(f"historical_occupancy_{year}")
                if not occupancy_data.empty:
                    occupancy_data['Date'] = pd.to_datetime(occupancy_data['Date'])
                    month_data = occupancy_data[occupancy_data['Date'].dt.month == month_num]
                    
                    if not month_data.empty:
                        revenue = month_data['Revenue'].sum()
                        adr = month_data['ADR'].mean()
                        occupancy_pct = (month_data['Rm Sold'].sum() / (len(month_data) * 339)) * 100
                    else:
                        revenue = 0
                        adr = 0
                        occupancy_pct = 0
                else:
                    revenue = 0
                    adr = 0
                    occupancy_pct = 0
            else:
                # 2025 current data
                current_data = db.get_occupancy_data()
                if not current_data.empty:
                    current_data['Date'] = pd.to_datetime(current_data['Date'])
                    month_data = current_data[(current_data['Date'].dt.year == 2025) & 
                                            (current_data['Date'].dt.month == month_num)]
                    
                    if not month_data.empty:
                        revenue = month_data['Revenue'].sum()
                        adr = month_data['ADR'].mean()
                        occupancy_pct = (month_data['Rm_Sold'].sum() / (len(month_data) * 339)) * 100
                    else:
                        revenue = 0
                        adr = 0
                        occupancy_pct = 0
                else:
                    revenue = 0
                    adr = 0
                    occupancy_pct = 0
            
            kpi_data.append({
                'year': year,
                'revenue': revenue,
                'adr': adr,
                'occupancy': occupancy_pct
            })
        
        # Display KPIs in a compact format
        st.markdown(f"**KPIs for {selected_month} (All Years)**")
        
        # Revenue KPIs
        revenue_html = '<div class="responsive-kpi-container">'
        revenue_html += '<div class="responsive-metric"><div class="metric-label">Revenue</div></div>'
        for data in kpi_data:
            revenue_html += f'<div class="responsive-metric"><div class="metric-label">{data["year"]}</div><div class="metric-value">AED {data["revenue"]:,.0f}</div></div>'
        revenue_html += '</div>'
        
        # ADR KPIs
        adr_html = '<div class="responsive-kpi-container">'
        adr_html += '<div class="responsive-metric"><div class="metric-label">ADR</div></div>'
        for data in kpi_data:
            adr_html += f'<div class="responsive-metric"><div class="metric-label">{data["year"]}</div><div class="metric-value">AED {data["adr"]:.0f}</div></div>'
        adr_html += '</div>'
        
        # Occupancy KPIs
        occupancy_html = '<div class="responsive-kpi-container">'
        occupancy_html += '<div class="responsive-metric"><div class="metric-label">Occupancy</div></div>'
        for data in kpi_data:
            occupancy_html += f'<div class="responsive-metric"><div class="metric-label">{data["year"]}</div><div class="metric-value">{data["occupancy"]:.1f}%</div></div>'
        occupancy_html += '</div>'
        
        st.markdown(revenue_html, unsafe_allow_html=True)
        st.markdown(adr_html, unsafe_allow_html=True)
        st.markdown(occupancy_html, unsafe_allow_html=True)
        
    except Exception as e:
        st.error(f"Error displaying monthly KPIs: {str(e)}")

def display_monthly_occupancy_comparison(selected_month):
    """Display monthly occupancy comparison: 2025 bars + historical trend lines"""
    try:
        db = get_database()
        month_num = ["January", "February", "March", "April", "May", "June",
                     "July", "August", "September", "October", "November", "December"].index(selected_month) + 1
        
        fig = go.Figure()
        
        # Add historical trend lines (2022-2024)
        for year in [2022, 2023, 2024]:
            occupancy_data = db.get_historical_occupancy_data(f"historical_occupancy_{year}")
            if not occupancy_data.empty:
                occupancy_data['Date'] = pd.to_datetime(occupancy_data['Date'])
                month_data = occupancy_data[occupancy_data['Date'].dt.month == month_num].sort_values('Date')
                
                if not month_data.empty:
                    month_data['Occupancy_Pct'] = (month_data['Rm Sold'] / 339) * 100
                    
                    fig.add_trace(go.Scatter(
                        x=month_data['Date'].dt.day,
                        y=month_data['Occupancy_Pct'],
                        mode='lines',
                        name=f'{year}',
                        line=dict(width=2)
                    ))
        
        # Add 2025 data as bars
        current_data = db.get_occupancy_data()
        if not current_data.empty:
            current_data['Date'] = pd.to_datetime(current_data['Date'])
            month_2025 = current_data[(current_data['Date'].dt.year == 2025) & 
                                    (current_data['Date'].dt.month == month_num)].sort_values('Date')
            
            if not month_2025.empty:
                month_2025['Occupancy_Pct'] = (month_2025['Rm_Sold'] / 339) * 100
                
                fig.add_trace(go.Bar(
                    x=month_2025['Date'].dt.day,
                    y=month_2025['Occupancy_Pct'],
                    name='2025',
                    opacity=0.7,
                    marker_color='orange'
                ))
        
        fig.update_layout(
            title=f"{selected_month} Occupancy Comparison",
            xaxis_title="Day of Month",
            yaxis_title="Occupancy %",
            hovermode='x unified',
            height=400,
            showlegend=True
        )
        
        st.plotly_chart(fig, use_container_width=True)
        
    except Exception as e:
        st.error(f"Error displaying monthly occupancy comparison: {str(e)}")

def display_monthly_adr_comparison(selected_month):
    """Display monthly ADR comparison: 2025 bars + historical trend lines"""
    try:
        db = get_database()
        month_num = ["January", "February", "March", "April", "May", "June",
                     "July", "August", "September", "October", "November", "December"].index(selected_month) + 1
        
        fig = go.Figure()
        
        # Add historical trend lines (2022-2024)
        for year in [2022, 2023, 2024]:
            occupancy_data = db.get_historical_occupancy_data(f"historical_occupancy_{year}")
            if not occupancy_data.empty:
                occupancy_data['Date'] = pd.to_datetime(occupancy_data['Date'])
                month_data = occupancy_data[occupancy_data['Date'].dt.month == month_num].sort_values('Date')
                
                if not month_data.empty:
                    fig.add_trace(go.Scatter(
                        x=month_data['Date'].dt.day,
                        y=month_data['ADR'],
                        mode='lines',
                        name=f'{year}',
                        line=dict(width=2)
                    ))
        
        # Add 2025 data as bars
        current_data = db.get_occupancy_data()
        if not current_data.empty:
            current_data['Date'] = pd.to_datetime(current_data['Date'])
            month_2025 = current_data[(current_data['Date'].dt.year == 2025) & 
                                    (current_data['Date'].dt.month == month_num)].sort_values('Date')
            
            if not month_2025.empty:
                fig.add_trace(go.Bar(
                    x=month_2025['Date'].dt.day,
                    y=month_2025['ADR'],
                    name='2025',
                    opacity=0.7,
                    marker_color='gold'
                ))
        
        fig.update_layout(
            title=f"{selected_month} ADR Comparison",
            xaxis_title="Day of Month",
            yaxis_title="ADR (AED)",
            hovermode='x unified',
            height=400,
            showlegend=True
        )
        
        st.plotly_chart(fig, use_container_width=True)
        
    except Exception as e:
        st.error(f"Error displaying monthly ADR comparison: {str(e)}")

def prepare_forecast_data():
    """Prepare and combine all historical data for forecasting, store in SQL"""
    try:
        db = get_database()
        
        # Check if combined data already exists
        combined_data = db.get_combined_forecast_data()
        if not combined_data.empty:
            st.session_state.forecast_data = combined_data
            return True
        
        # Combine all historical data
        all_data = []
        
        # Historical data (2022-2024)
        for year in [2022, 2023, 2024]:
            historical_data = db.get_historical_occupancy_data(f"historical_occupancy_{year}")
            if not historical_data.empty:
                historical_data['Date'] = pd.to_datetime(historical_data['Date'])
                all_data.append(historical_data[['Date', 'Rm Sold', 'Revenue', 'ADR', 'RevPar']])
        
        # Current year data (2025)
        current_data = db.get_occupancy_data()
        if not current_data.empty:
            current_data['Date'] = pd.to_datetime(current_data['Date'])
            current_2025 = current_data[current_data['Date'].dt.year == 2025]
            if not current_2025.empty:
                # Rename column to match historical data
                current_2025 = current_2025.rename(columns={'Rm_Sold': 'Rm Sold'})
                all_data.append(current_2025[['Date', 'Rm Sold', 'Revenue', 'ADR', 'RevPar']])
        
        if not all_data:
            return False
        
        # Combine all data
        combined_data = pd.concat(all_data, ignore_index=True)
        combined_data = combined_data.sort_values('Date').reset_index(drop=True)
        
        # Fill missing dates
        date_range = pd.date_range(start=combined_data['Date'].min(), 
                                 end=combined_data['Date'].max(), 
                                 freq='D')
        full_df = pd.DataFrame({'Date': date_range})
        combined_data = full_df.merge(combined_data, on='Date', how='left')
        
        # Forward fill missing values
        for col in ['Rm Sold', 'Revenue', 'ADR', 'RevPar']:
            combined_data[col] = combined_data[col].fillna(method='ffill')
        
        # Calculate occupancy percentage
        combined_data['Occupancy_Pct'] = (combined_data['Rm Sold'] / 339) * 100
        
        # Add calendar features for analysis
        combined_data['Year'] = combined_data['Date'].dt.year
        combined_data['Month'] = combined_data['Date'].dt.month
        combined_data['DayOfWeek'] = combined_data['Date'].dt.dayofweek
        combined_data['DayOfYear'] = combined_data['Date'].dt.dayofyear
        combined_data['Quarter'] = combined_data['Date'].dt.quarter
        
        # Save to SQL for future use
        db.save_combined_forecast_data(combined_data)
        
        # Store in session state
        st.session_state.forecast_data = combined_data
        return True
        
    except Exception as e:
        st.error(f"Error preparing forecast data: {str(e)}")
        return False

def generate_all_forecasts():
    """Generate forecasts for all horizons using appropriate models"""
    try:
        if 'forecast_data' not in st.session_state:
            st.error("Forecast data not prepared")
            return
        
        data = st.session_state.forecast_data.copy()
        
        # Prepare data for forecasting
        data.set_index('Date', inplace=True)
        
        # Get current date
        current_date = datetime.now()
        
        # Generate forecasts for recommended horizons
        forecasts = {}
        
        # 90-day operational forecast (SARIMA/Prophet with occupancy regressors)
        forecasts['90_day'] = generate_operational_forecast(data, current_date, 90)
        
        # 12-month strategic forecast (Seasonal decomposition/ensemble)
        forecasts['12_month'] = generate_strategic_forecast(data, current_date, 365)
        
        # Store forecasts
        st.session_state.forecasts = forecasts
        
        st.success("‚úÖ All forecasts generated successfully!")
        
    except Exception as e:
        st.error(f"Error generating forecasts: {str(e)}")

def display_forecast_results():
    """Display forecast results in KPI cards and charts"""
    if 'forecasts' not in st.session_state:
        st.info("No forecasts available. Click 'Generate Forecasts' to create predictions.")
        return
    
    forecasts = st.session_state.forecasts
    
    # Display KPI cards
    st.subheader("üéØ Forecast KPIs")
    
    col1, col2 = st.columns(2)
    
    # 90-day Operational KPI
    if forecasts.get('90_day'):
        forecast_90d = forecasts['90_day']
        with col1:
            st.metric(
                label="üìÖ 90-Day Operational Forecast",
                value=f"AED {forecast_90d['revenue_total']:,.0f}",
                delta=f"Model: {forecast_90d['model']}"
            )
            st.metric(
                label="Average ADR",
                value=f"AED {forecast_90d['avg_adr']:.0f}"
            )
            st.metric(
                label="Average Occupancy",
                value=f"{forecast_90d['avg_occupancy']:.1f}%"
            )
    
    # 12-month Strategic KPI
    if forecasts.get('12_month'):
        forecast_12m = forecasts['12_month']
        with col2:
            st.metric(
                label="üìÖ 12-Month Strategic Forecast",
                value=f"AED {forecast_12m['revenue_total']:,.0f}",
                delta=f"Model: {forecast_12m['model']}"
            )
            st.metric(
                label="Average ADR",
                value=f"AED {forecast_12m['avg_adr']:.0f}"
            )
            st.metric(
                label="Average Occupancy",
                value=f"{forecast_12m['avg_occupancy']:.1f}%"
            )
    
    st.divider()
    
    # Display forecast charts
    st.subheader("üìà Forecast Visualization")
    
    display_forecast_charts(forecasts)

def generate_operational_forecast(data, current_date, days):
    """Generate 3-month forecast using SARIMA or Prophet"""
    try:
        # Use Revenue for forecasting
        revenue_series = data['Revenue'].dropna()
        
        if PROPHET_AVAILABLE:
            # Use Prophet for short-term forecasting
            df_prophet = pd.DataFrame({
                'ds': revenue_series.index,
                'y': revenue_series.values
            })
            
            model = Prophet(
                yearly_seasonality=True,
                weekly_seasonality=True,
                daily_seasonality=False,
                changepoint_prior_scale=0.05
            )
            
            model.fit(df_prophet)
            
            # Create future dates
            future = model.make_future_dataframe(periods=days)
            forecast = model.predict(future)
            
            # Extract forecast for the requested period
            forecast_period = forecast.tail(days)
            
            return {
                'model': 'Prophet',
                'forecast': forecast_period['yhat'].values,
                'lower': forecast_period['yhat_lower'].values,
                'upper': forecast_period['yhat_upper'].values,
                'dates': pd.date_range(start=current_date, periods=days, freq='D'),
                'revenue_total': forecast_period['yhat'].sum(),
                'avg_adr': data['ADR'].tail(30).mean(),  # Use recent average
                'avg_occupancy': data['Occupancy_Pct'].tail(30).mean()
            }
        
        elif TS_AVAILABLE:
            # Use SARIMA as fallback
            model = SARIMAX(revenue_series, order=(1,1,1), seasonal_order=(1,1,1,12))
            fitted_model = model.fit(disp=False)
            
            forecast = fitted_model.forecast(steps=days)
            conf_int = fitted_model.get_forecast(steps=days).conf_int()
            
            return {
                'model': 'SARIMA',
                'forecast': forecast.values,
                'lower': conf_int.iloc[:, 0].values,
                'upper': conf_int.iloc[:, 1].values,
                'dates': pd.date_range(start=current_date, periods=days, freq='D'),
                'revenue_total': forecast.sum(),
                'avg_adr': data['ADR'].tail(30).mean(),
                'avg_occupancy': data['Occupancy_Pct'].tail(30).mean()
            }
        
        else:
            # Simple seasonal naive forecast
            seasonal_avg = revenue_series.tail(365).mean()
            forecast_values = [seasonal_avg] * days
            
            return {
                'model': 'Seasonal Naive',
                'forecast': forecast_values,
                'lower': [v * 0.8 for v in forecast_values],
                'upper': [v * 1.2 for v in forecast_values],
                'dates': pd.date_range(start=current_date, periods=days, freq='D'),
                'revenue_total': sum(forecast_values),
                'avg_adr': data['ADR'].tail(30).mean(),
                'avg_occupancy': data['Occupancy_Pct'].tail(30).mean()
            }
            
    except Exception as e:
        st.error(f"Error in short-term forecast: {str(e)}")
        return None

def generate_strategic_forecast(data, current_date, days):
    """Generate 12-month forecast using ensemble methods"""
    try:
        # For long-term, use simpler but more robust approaches
        revenue_series = data['Revenue'].dropna()
        
        # Seasonal decomposition
        if len(revenue_series) >= 365*2:  # Need at least 2 years
            decomposition = seasonal_decompose(revenue_series, model='additive', period=365)
            trend = decomposition.trend.dropna()
            seasonal = decomposition.seasonal.dropna()
            
            # Project trend
            trend_slope = (trend.tail(30).mean() - trend.head(30).mean()) / len(trend)
            
            # Generate forecast
            forecast_values = []
            for i in range(days):
                future_date = current_date + timedelta(days=i)
                day_of_year = future_date.timetuple().tm_yday
                
                # Get seasonal component (cycle through year)
                seasonal_idx = (day_of_year - 1) % len(seasonal)
                seasonal_component = seasonal.iloc[seasonal_idx]
                
                # Project trend
                trend_component = trend.iloc[-1] + (trend_slope * (i + 1))
                
                forecast_value = trend_component + seasonal_component
                forecast_values.append(max(0, forecast_value))  # Ensure non-negative
            
            return {
                'model': 'Seasonal Decomposition',
                'forecast': forecast_values,
                'lower': [v * 0.75 for v in forecast_values],
                'upper': [v * 1.25 for v in forecast_values],
                'dates': pd.date_range(start=current_date, periods=days, freq='D'),
                'revenue_total': sum(forecast_values),
                'avg_adr': data['ADR'].tail(90).mean(),
                'avg_occupancy': data['Occupancy_Pct'].tail(90).mean()
            }
        
        else:
            # Simple trend projection
            recent_avg = revenue_series.tail(90).mean()
            yearly_growth = 0.05  # Assume 5% growth
            
            forecast_values = []
            for i in range(days):
                growth_factor = (1 + yearly_growth) ** (i / 365)
                forecast_value = recent_avg * growth_factor
                forecast_values.append(forecast_value)
            
            return {
                'model': 'Trend Projection',
                'forecast': forecast_values,
                'lower': [v * 0.7 for v in forecast_values],
                'upper': [v * 1.3 for v in forecast_values],
                'dates': pd.date_range(start=current_date, periods=days, freq='D'),
                'revenue_total': sum(forecast_values),
                'avg_adr': data['ADR'].tail(90).mean(),
                'avg_occupancy': data['Occupancy_Pct'].tail(90).mean()
            }
            
    except Exception as e:
        st.error(f"Error in strategic forecast: {str(e)}")
        return generate_operational_forecast(data, current_date, days)

def display_forecast_charts(forecasts):
    """Display interactive forecast charts"""
    try:
        fig = go.Figure()
        
        # Historical data
        if 'forecast_data' in st.session_state:
            historical = st.session_state.forecast_data.copy()
            historical['Date'] = pd.to_datetime(historical['Date'])
            historical = historical.set_index('Date')
            
            # Show last 2 years of historical data
            cutoff_date = datetime.now() - timedelta(days=730)
            recent_historical = historical[historical.index >= cutoff_date]
            
            fig.add_trace(go.Scatter(
                x=recent_historical.index,
                y=recent_historical['Revenue'],
                mode='lines',
                name='Historical Revenue',
                line=dict(color='blue', width=2)
            ))
        
        # Add forecast lines
        colors = ['#FF8C00', '#8A2BE2']  # Orange, Purple in hex
        names = ['90-Day Operational', '12-Month Strategic']
        
        for i, (key, color, name) in enumerate(zip(['90_day', '12_month'], colors, names)):
            if forecasts.get(key):
                forecast = forecasts[key]
                
                # Main forecast line
                fig.add_trace(go.Scatter(
                    x=forecast['dates'],
                    y=forecast['forecast'],
                    mode='lines',
                    name=f'{name} Forecast',
                    line=dict(color=color, width=2, dash='dash')
                ))
                
                # Convert hex to rgba for confidence intervals
                if color == '#FF8C00':  # Orange
                    rgba_color = 'rgba(255, 140, 0, 0.1)'
                else:  # Purple
                    rgba_color = 'rgba(138, 43, 226, 0.1)'
                
                # Confidence intervals
                fig.add_trace(go.Scatter(
                    x=list(forecast['dates']) + list(forecast['dates'][::-1]),
                    y=list(forecast['upper']) + list(forecast['lower'][::-1]),
                    fill='tonexty' if i == 0 else 'toself',
                    fillcolor=rgba_color,
                    line=dict(color='rgba(255,255,255,0)'),
                    name=f'{name} Confidence Interval',
                    showlegend=False
                ))
        
        fig.update_layout(
            title="Revenue Forecasts with Confidence Intervals",
            xaxis_title="Date",
            yaxis_title="Revenue (AED)",
            hovermode='x unified',
            height=600,
            legend=dict(
                orientation="h",
                yanchor="bottom",
                y=1.02,
                xanchor="right",
                x=1
            )
        )
        
        st.plotly_chart(fig, use_container_width=True)
        
        # Model information
        st.subheader("üîç Model Information")
        
        info_col1, info_col2 = st.columns(2)
        
        with info_col1:
            if forecasts.get('90_day'):
                st.info(f"""
                **90-Day Operational Forecast**
                - Model: {forecasts['90_day']['model']}
                - Best for: Daily/weekly operations
                - Accuracy: High (recent patterns)
                - Use case: Rate decisions, yield management, staffing
                - Update frequency: Daily/weekly rolling
                """)
        
        with info_col2:
            if forecasts.get('12_month'):
                st.info(f"""
                **12-Month Strategic Forecast**
                - Model: {forecasts['12_month']['model']}
                - Best for: Annual planning
                - Accuracy: Lower (wider intervals)
                - Use case: Budgets, capital planning, scenarios
                - Update frequency: Monthly refresh
                """)
        
    except Exception as e:
        st.error(f"Error displaying forecast charts: {str(e)}")

def enhanced_forecasting_tab():
    """Enhanced Forecasting Tab with 3-month weighted forecasts and year-end predictions"""
    st.header("üîÆ Enhanced Forecasting & Predictions")
    
    if not st.session_state.data_loaded:
        show_loading_requirements()
        return
    
    # Get data
    if st.session_state.segment_data is not None:
        segment_data = st.session_state.segment_data
    else:
        if database_available:
            segment_data = get_database().get_segment_data()
        else:
            segment_data = pd.DataFrame()
            
    if st.session_state.occupancy_data is not None:
        occupancy_data = st.session_state.occupancy_data
    else:
        if database_available:
            occupancy_data = get_database().get_occupancy_data()
        else:
            occupancy_data = pd.DataFrame()
    
    if segment_data.empty and occupancy_data.empty:
        st.error("No data available for forecasting")
        return
    
    if not forecasting_available:
        st.warning("‚ö†Ô∏è Advanced forecasting module not available")
        st.info("Install the advanced forecasting module to access 3-month forecasts, year-end predictions, and current month close predictions.")
        return
        
    forecaster = get_advanced_forecaster()
    
    # Create tabs for different forecasting types
    forecast_tab1, forecast_tab2, forecast_tab3 = st.tabs(["3-Month Forecast", "Year-End Prediction", "Current Month Close"])
    
    with forecast_tab1:
        st.subheader("üìÖ Next 3 Months Weighted Forecast")
        st.info("Forecasts for September, October, November with budget weighting. More weight on budget for current month and historical data for future months.")
        
        if st.button("Generate 3-Month Forecast", type="primary"):
            with st.spinner("Generating weighted 3-month forecast..."):
                try:
                    forecast_df = forecaster.forecast_three_months_weighted(segment_data, occupancy_data)
                    
                    if not forecast_df.empty:
                        st.success("‚úÖ 3-Month forecast generated successfully!")
                        
                        # Display forecast summary
                        col1, col2, col3 = st.columns(3)
                        
                        for i, (_, row) in enumerate(forecast_df.iterrows()):
                            with [col1, col2, col3][i]:
                                st.metric(
                                    f"{row['month']} Revenue",
                                    f"AED {row['total_revenue_forecast']:,.0f}",
                                    f"Budget: {row['budget_weight']:.0%}, Historical: {row['historical_weight']:.0%}"
                                )
                        
                        # Detailed breakdown
                        st.subheader("üìä Detailed Forecast Breakdown")
                        
                        # Create visualization
                        fig_forecast = go.Figure()
                        
                        # Add total revenue bars
                        fig_forecast.add_trace(go.Bar(
                            x=forecast_df['month'],
                            y=forecast_df['total_revenue_forecast'],
                            name='Total Forecast',
                            marker_color='lightblue'
                        ))
                        
                        # Add budget component
                        fig_forecast.add_trace(go.Bar(
                            x=forecast_df['month'],
                            y=forecast_df['budget_component'],
                            name='Budget Component',
                            marker_color='green',
                            opacity=0.7
                        ))
                        
                        # Add historical component
                        fig_forecast.add_trace(go.Bar(
                            x=forecast_df['month'],
                            y=forecast_df['historical_component'],
                            name='Historical Component',
                            marker_color='orange',
                            opacity=0.7
                        ))
                        
                        fig_forecast.update_layout(
                            title="3-Month Revenue Forecast with Components",
                            xaxis_title="Month",
                            yaxis_title="Revenue (AED)",
                            barmode='overlay',
                            height=500
                        )
                        
                        st.plotly_chart(fig_forecast, use_container_width=True)
                        
                        # Forecast table
                        st.subheader("üìã Forecast Details")
                        
                        display_df = forecast_df.copy()
                        display_df['total_revenue_forecast'] = display_df['total_revenue_forecast'].apply(lambda x: f"AED {x:,.0f}")
                        display_df['budget_component'] = display_df['budget_component'].apply(lambda x: f"AED {x:,.0f}")
                        display_df['historical_component'] = display_df['historical_component'].apply(lambda x: f"AED {x:,.0f}")
                        display_df['budget_weight'] = display_df['budget_weight'].apply(lambda x: f"{x:.0%}")
                        display_df['historical_weight'] = display_df['historical_weight'].apply(lambda x: f"{x:.0%}")
                        display_df['avg_occupancy_forecast'] = display_df['avg_occupancy_forecast'].apply(lambda x: f"{x:.1f}%")
                        
                        st.dataframe(display_df[[
                            'month', 'total_revenue_forecast', 'budget_component', 'historical_component',
                            'budget_weight', 'historical_weight', 'avg_occupancy_forecast'
                        ]], use_container_width=True)
                        
                    else:
                        st.error("‚ùå Could not generate 3-month forecast")
                except Exception as e:
                    st.error(f"‚ùå Error generating 3-month forecast: {str(e)}")
    
    with forecast_tab2:
        st.subheader("üéØ Year-End Revenue Prediction")
        st.info("Compare against AED 38M budget and AED 33M last year performance")
        
        if st.button("Predict Year-End Revenue", type="primary"):
            with st.spinner("Calculating year-end prediction..."):
                try:
                    prediction = forecaster.predict_year_end_revenue(segment_data, occupancy_data)
                    
                    if prediction:
                        st.success("‚úÖ Year-end prediction calculated!")
                        
                        # Key metrics - Use 2 rows to avoid clashing
                        st.subheader("üìà Year-End Prediction Summary")
                        
                        # First row
                        col1, col2 = st.columns(2)
                        
                        with col1:
                            st.metric(
                                "Predicted Year-End Revenue",
                                f"AED {prediction['year_end_prediction']:,.0f}"
                            )
                        
                        with col2:
                            st.metric(
                                "Months Remaining in Year",
                                prediction['months_remaining']
                            )
                        
                        # Second row
                        col3, col4 = st.columns(2)
                        
                        with col3:
                            st.metric(
                                "vs Budget Target (38M)",
                                f"AED {prediction['budget_variance']:+,.0f}",
                                f"{prediction['budget_performance_pct']:.1f}% of budget"
                            )
                        
                        with col4:
                            st.metric(
                                "vs Last Year Total (33M)", 
                                f"AED {prediction['vs_last_year']:+,.0f}",
                                f"{prediction['vs_last_year_growth_pct']:+.1f}% growth"
                            )
                        
                        # Visual comparison
                        st.subheader("üìä Performance Comparison")
                        
                        comparison_data = {
                            'Metric': ['Last Year Actual', 'This Year Budget', 'This Year Prediction'],
                            'Revenue': [prediction['last_year_total'], prediction['budget_target'], prediction['year_end_prediction']],
                            'Color': ['lightcoral', 'lightgreen', 'lightblue']
                        }
                        
                        fig_comparison = go.Figure(data=[
                            go.Bar(
                                x=comparison_data['Metric'],
                                y=comparison_data['Revenue'],
                                marker_color=comparison_data['Color'],
                                text=[f"AED {x:,.0f}" for x in comparison_data['Revenue']],
                                textposition='auto'
                            )
                        ])
                        
                        fig_comparison.update_layout(
                            title="Year-End Revenue: Budget vs Last Year vs Prediction",
                            xaxis_title="",
                            yaxis_title="Revenue (AED)",
                            height=500,
                            showlegend=False
                        )
                        
                        st.plotly_chart(fig_comparison, use_container_width=True)
                        
                        # Breakdown
                        st.subheader("üìã Prediction Breakdown")
                        
                        breakdown_data = {
                            'Component': ['Year-to-Date', 'Remaining Forecast', 'Total Prediction'],
                            'Amount (AED)': [
                                f"{prediction['ytd_revenue']:,.0f}",
                                f"{prediction['remaining_forecast']:,.0f}",
                                f"{prediction['year_end_prediction']:,.0f}"
                            ]
                        }
                        
                        st.table(pd.DataFrame(breakdown_data))
                        
                    else:
                        st.error("‚ùå Could not generate year-end prediction")
                except Exception as e:
                    st.error(f"‚ùå Error generating year-end prediction: {str(e)}")
    
    with forecast_tab3:
        st.subheader("üìà Current Month Close Prediction")
        st.info("Predict current month close using last year data and moving average analysis")
        
        if st.button("Predict Current Month Close", type="primary"):
            with st.spinner("Analyzing current month performance..."):
                try:
                    month_prediction = forecaster.predict_current_month_close(segment_data, occupancy_data)
                    
                    if month_prediction:
                        st.success("‚úÖ Current month prediction calculated!")
                        
                        # Key metrics
                        col1, col2, col3 = st.columns(3)
                        
                        with col1:
                            st.metric(
                                "Business on Books",
                                f"AED {month_prediction.get('business_on_books', 0):,.0f}"
                            )
                        
                        with col2:
                            st.metric(
                                "Predicted Month Close",
                                f"AED {month_prediction.get('final_prediction', 0):,.0f}"
                            )
                        
                        with col3:
                            st.metric(
                                "MTD Pickup",
                                f"AED {month_prediction.get('mtd_pickup', 0):,.0f}"
                            )
                        
                        # Last year comparison
                        st.subheader("üìä Last Year Comparison Analysis")
                        
                        col1, col2, col3 = st.columns(3)
                        
                        with col1:
                            st.metric(
                                "Same Time Last Year",
                                f"AED {month_prediction.get('last_year_same_time', 0):,.0f}"
                            )
                        
                        with col2:
                            st.metric(
                                "Full Month Last Year",
                                f"AED {month_prediction.get('last_year_full_month', 0):,.0f}"
                            )
                        
                        with col3:
                            st.metric(
                                "Last Year Remainder",
                                f"AED {month_prediction.get('last_year_remainder', 0):,.0f}"
                            )
                        
                        # Visual analysis
                        prediction_data = {
                            'Method': ['BOB + Last Year Remainder', 'Weighted Prediction'],
                            'Prediction': [month_prediction.get('bob_plus_remainder_prediction', 0), month_prediction.get('weighted_prediction', 0)]
                        }
                        
                        fig_methods = go.Figure(data=[
                            go.Bar(
                                x=prediction_data['Method'],
                                y=prediction_data['Prediction'],
                                marker_color=['lightblue', 'lightgreen'],
                                text=[f"AED {x:,.0f}" for x in prediction_data['Prediction']],
                                textposition='auto'
                            )
                        ])
                        
                        fig_methods.update_layout(
                            title="Current Month Close: Prediction Methods Comparison",
                            xaxis_title="Prediction Method",
                            yaxis_title="Predicted Revenue (AED)",
                            height=400
                        )
                        
                        st.plotly_chart(fig_methods, use_container_width=True)
                        
                        # Additional info
                        st.info(f"üìÖ Current day: {month_prediction.get('current_day', 'N/A')}, Days remaining: {month_prediction.get('days_remaining', 'N/A')}")
                        
                    else:
                        st.error("‚ùå Could not generate current month prediction")
                except Exception as e:
                    st.error(f"‚ùå Error generating current month prediction: {str(e)}")

def machine_learning_tab():
    """Machine Learning Analysis Tab"""
    st.header("ü§ñ Machine Learning Revenue Analysis")
    
    if not st.session_state.data_loaded:
        show_loading_requirements()
        return
    
    # Get data
    if st.session_state.segment_data is not None:
        segment_data = st.session_state.segment_data
    else:
        if database_available:
            segment_data = get_database().get_segment_data()
        else:
            segment_data = pd.DataFrame()
            
    if st.session_state.occupancy_data is not None:
        occupancy_data = st.session_state.occupancy_data
    else:
        if database_available:
            occupancy_data = get_database().get_occupancy_data()
        else:
            occupancy_data = pd.DataFrame()
    
    if segment_data.empty:
        st.error("No segment data available for ML analysis")
        return
    
    if not forecasting_available:
        st.warning("‚ö†Ô∏è Advanced forecasting module not available")
        st.info("Install the advanced forecasting module to access ML models like XGBoost, Random Forest, Linear & Ridge Regression.")
        return
    
    forecaster = get_advanced_forecaster()
    
    # Create tabs for different ML analyses
    ml_tab1, ml_tab2, ml_tab3 = st.tabs(["Multi-Model Analysis", "Correlation Heatmap", "Model Performance"])
    
    with ml_tab1:
        st.subheader("üéØ Multi-Model Revenue Driver Analysis")
        st.info("Using multiple ML models (XGBoost, Random Forest, Linear & Ridge Regression) to determine what influences Business on the Books Revenue the most")
        
        if st.button("Run Multi-Model Analysis", type="primary"):
            with st.spinner("Training multiple ML models and analyzing revenue drivers..."):
                try:
                    ml_results = forecaster.analyze_revenue_drivers_multiple_models(segment_data, occupancy_data)
                    
                    if 'error' in ml_results:
                        st.error(f"‚ùå ML Analysis failed: {ml_results['error']}")
                    else:
                        st.success("‚úÖ Multi-model analysis completed successfully!")
                        
                        # Model comparison
                        st.subheader("üèÜ Model Performance Comparison")
                        
                        model_results = ml_results['model_results']
                        best_model = ml_results['best_model']
                        
                        # Create performance comparison table
                        performance_data = []
                        for model_name, result in model_results.items():
                            if 'performance' in result:
                                perf = result['performance']
                                performance_data.append({
                                    'Model': model_name + (" üèÜ" if model_name == best_model else ""),
                                    'R¬≤ Score': f"{perf['r2_score']:.3f}",
                                    'MAE': f"{perf['mae']:,.0f}",
                                    'RMSE': f"{perf['rmse']:,.0f}",
                                    'CV Mean': f"{perf['cv_mean']:.3f}",
                                    'CV Std': f"{perf['cv_std']:.3f}"
                                })
                        
                        if performance_data:
                            st.dataframe(pd.DataFrame(performance_data), use_container_width=True)
                            
                            # Best model feature importance
                            if best_model and best_model in model_results:
                                best_result = model_results[best_model]
                                if 'feature_importance' in best_result and best_result['feature_importance'] is not None:
                                    st.subheader(f"üìä Feature Importance - {best_model} (Best Model)")
                                    
                                    importance_df = best_result['feature_importance']
                                    top_features = importance_df.head(10)
                                    
                                    fig_importance = go.Figure(data=[
                                        go.Bar(
                                            y=top_features['feature'],
                                            x=top_features['importance'],
                                            orientation='h',
                                            marker_color='lightblue'
                                        )
                                    ])
                                    
                                    fig_importance.update_layout(
                                        title=f"Top 10 Revenue Drivers - {best_model}",
                                        xaxis_title="Importance Score",
                                        yaxis_title="Features",
                                        height=500,
                                        yaxis={'categoryorder': 'total ascending'}
                                    )
                                    
                                    st.plotly_chart(fig_importance, use_container_width=True)
                                    
                                    # Feature importance table
                                    st.subheader("üìã Complete Feature Importance Rankings")
                                    
                                    display_importance = importance_df.copy()
                                    display_importance['importance'] = display_importance['importance'].apply(lambda x: f"{x:.4f}")
                                    display_importance.index = range(1, len(display_importance) + 1)
                                    
                                    st.dataframe(display_importance, use_container_width=True)
                        
                        # Store results in session state for other tabs
                        st.session_state.ml_results = ml_results
                except Exception as e:
                    st.error(f"‚ùå Error in multi-model analysis: {str(e)}")
    
    with ml_tab2:
        st.subheader("üî• Correlation Heatmap")
        st.info("Correlation analysis between revenue and various factors")
        
        if st.button("Generate Correlation Heatmap", type="primary"):
            with st.spinner("Calculating correlations..."):
                try:
                    correlation_matrix = forecaster.generate_correlation_matrix(segment_data, occupancy_data)
                    
                    if correlation_matrix is not None:
                        st.success("‚úÖ Correlation matrix generated!")
                        
                        # Create heatmap using plotly
                        fig_heatmap = go.Figure(data=go.Heatmap(
                            z=correlation_matrix.values,
                            x=correlation_matrix.columns,
                            y=correlation_matrix.index,
                            colorscale='RdBu_r',
                            zmid=0,
                            text=correlation_matrix.round(3).values,
                            texttemplate='%{text}',
                            textfont={"size": 10},
                            hoverongaps=False
                        ))
                        
                        fig_heatmap.update_layout(
                            title="Revenue Correlation Heatmap",
                            xaxis_title="Variables",
                            yaxis_title="Variables",
                            height=600,
                            width=800
                        )
                        
                        st.plotly_chart(fig_heatmap, use_container_width=True)
                        
                        # Correlation insights
                        st.subheader("üîç Key Correlation Insights")
                        
                        # Find strongest correlations with revenue
                        revenue_corr = correlation_matrix['Business_on_the_Books_Revenue'].drop('Business_on_the_Books_Revenue')
                        strongest_positive = revenue_corr.nlargest(3)
                        strongest_negative = revenue_corr.nsmallest(3)
                        
                        col1, col2 = st.columns(2)
                        
                        with col1:
                            st.write("**Strongest Positive Correlations:**")
                            for var, corr in strongest_positive.items():
                                st.write(f"‚Ä¢ {var}: {corr:.3f}")
                        
                        with col2:
                            st.write("**Strongest Negative Correlations:**")
                            for var, corr in strongest_negative.items():
                                st.write(f"‚Ä¢ {var}: {corr:.3f}")
                        
                    else:
                        st.error("‚ùå Could not generate correlation matrix")
                except Exception as e:
                    st.error(f"‚ùå Error generating correlation heatmap: {str(e)}")
    
    with ml_tab3:
        st.subheader("üìà Model Performance Evaluation")
        
        if 'ml_results' in st.session_state and 'model_results' in st.session_state.ml_results:
            ml_results = st.session_state.ml_results
            best_model = ml_results['best_model']
            
            if best_model and best_model in ml_results['model_results']:
                performance = ml_results['model_results'][best_model]['performance']
                
                st.success(f"‚úÖ Model performance metrics available for {best_model}!")
                
                # Performance metrics
                col1, col2, col3, col4 = st.columns(4)
                
                with col1:
                    st.metric("R¬≤ Score", f"{performance['r2_score']:.3f}")
                
                with col2:
                    st.metric("MAE", f"{performance['mae']:,.0f}")
                
                with col3:
                    st.metric("RMSE", f"{performance['rmse']:,.0f}")
                
                with col4:
                    st.metric("Cross-Val R¬≤", f"{performance['cv_mean']:.3f} ¬± {performance['cv_std']:.3f}")
                
                # Model interpretation
                st.subheader("üìä Model Performance Analysis")
                
                if performance['r2_score'] > 0.8:
                    st.success("üéâ Excellent model performance! The model explains over 80% of revenue variance.")
                elif performance['r2_score'] > 0.6:
                    st.info("üëç Good model performance. The model explains a significant portion of revenue variance.")
                elif performance['r2_score'] > 0.4:
                    st.warning("‚ö†Ô∏è Moderate model performance. Consider feature engineering or more data.")
                else:
                    st.error("‚ùå Poor model performance. Model may need significant improvements.")
                
                # Actual vs Predicted plot
                if 'y_test' in ml_results and best_model in ml_results['model_results']:
                    st.subheader(f"üéØ Actual vs Predicted Revenue - {best_model}")
                    
                    y_test = ml_results['y_test']
                    y_pred = ml_results['model_results'][best_model]['predictions']
                    
                    fig_pred = go.Figure()
                    
                    # Add scatter plot
                    fig_pred.add_trace(go.Scatter(
                        x=y_test,
                        y=y_pred,
                        mode='markers',
                        name='Predictions',
                        marker=dict(color='lightblue', size=8)
                    ))
                    
                    # Add perfect prediction line
                    min_val = min(y_test.min(), y_pred.min())
                    max_val = max(y_test.max(), y_pred.max())
                    fig_pred.add_trace(go.Scatter(
                        x=[min_val, max_val],
                        y=[min_val, max_val],
                        mode='lines',
                        name='Perfect Prediction',
                        line=dict(color='red', dash='dash')
                    ))
                    
                    fig_pred.update_layout(
                        title=f"Actual vs Predicted Revenue - {best_model}",
                        xaxis_title="Actual Revenue (AED)",
                        yaxis_title="Predicted Revenue (AED)",
                        height=500
                    )
                    
                    st.plotly_chart(fig_pred, use_container_width=True)
                    
                    # Residuals analysis
                    st.subheader("üìä Residuals Analysis")
                    
                    residuals = y_test - y_pred
                    
                    fig_residuals = go.Figure()
                    fig_residuals.add_trace(go.Scatter(
                        x=y_pred,
                        y=residuals,
                        mode='markers',
                        marker=dict(color='lightgreen', size=6)
                    ))
                    fig_residuals.add_hline(y=0, line_dash="dash", line_color="red")
                    
                    fig_residuals.update_layout(
                        title=f"Residuals vs Predicted Values - {best_model}",
                        xaxis_title="Predicted Revenue (AED)",
                        yaxis_title="Residuals (AED)",
                        height=400
                    )
                    
                    st.plotly_chart(fig_residuals, use_container_width=True)
        else:
            st.info("‚è≥ Run Multi-Model Analysis first to see model performance metrics")

def insights_analysis_tab():
    """Insights Analysis Tab - Segment performance analysis"""
    st.header("üéØ Insights & Performance Analysis")
    
    if not st.session_state.data_loaded:
        show_loading_requirements()
        return
    
    # Get data
    segment_data = st.session_state.segment_data if st.session_state.segment_data is not None else get_database().get_segment_data()
    
    if segment_data.empty:
        st.error("No segment data available for insights analysis")
        return
    
    if forecasting_available:
        forecaster = get_advanced_forecaster()
        
        st.info("Analysis of segment performance compared to full month last year and budget targets")
        
        if st.button("Generate Insights Analysis", type="primary"):
            with st.spinner("Analyzing segment performance..."):
                insights = forecaster.analyze_segment_performance(segment_data)
                
                if 'error' in insights:
                    st.error(f"‚ùå Insights analysis failed: {insights['error']}")
                else:
                    st.success("‚úÖ Insights analysis completed successfully!")
                    
                    # Summary metrics
                    summary = insights['summary']
                    st.subheader("üìä Performance Summary")
                    
                    col1, col2, col3, col4 = st.columns(4)
                    
                    with col1:
                        st.metric("Total Segments", summary['total_segments'])
                    
                    with col2:
                        st.metric("Top Performers", summary['top_performers'], f"{summary['top_performer_pct']:.1f}%")
                    
                    with col3:
                        st.metric("Good Performers", summary['good_performers'])
                    
                    with col4:
                        st.metric("Need Attention", summary['attention_needed'], f"{summary['attention_needed_pct']:.1f}%")
                    
                    analysis_results = insights['analysis_results']
                    
                    # Performance flags section
                    st.subheader("üö® Performance Alerts")
                    
                    # Group segments by performance
                    top_performers = [r for r in analysis_results if "Top Performer" in r['overall_status']]
                    attention_needed = [r for r in analysis_results if "Critical Attention Needed" in r['overall_status']]
                    below_expectations = [r for r in analysis_results if "Below Expectations" in r['overall_status']]
                    
                    if top_performers:
                        st.success("üåü **Top Performing Segments:**")
                        for segment in top_performers:
                            st.write(f"‚Ä¢ **{segment['segment']}**: {segment['vs_full_month_ly_pct']:+.1f}% vs LY, {segment['vs_budget_pct']:+.1f}% vs Budget")
                    
                    if attention_needed:
                        st.error("üö® **Segments Needing Critical Attention:**")
                        for segment in attention_needed:
                            st.write(f"‚Ä¢ **{segment['segment']}**: {segment['vs_full_month_ly_pct']:+.1f}% vs LY, {segment['vs_budget_pct']:+.1f}% vs Budget")
                            for flag in segment['performance_flags']:
                                st.write(f"  - {flag}")
                    
                    if below_expectations:
                        st.warning("‚ö†Ô∏è **Segments Below Expectations:**")
                        for segment in below_expectations:
                            st.write(f"‚Ä¢ **{segment['segment']}**: {segment['vs_full_month_ly_pct']:+.1f}% vs LY, {segment['vs_budget_pct']:+.1f}% vs Budget")
                    
                    # Detailed performance table
                    st.subheader("üìã Complete Performance Table")
                    
                    # Create display dataframe
                    display_data = []
                    for result in analysis_results:
                        display_data.append({
                            'Segment': result['segment'],
                            'Status': result['overall_status'],
                            'Current BOB (AED)': f"{result['current_bob_revenue']:,.0f}",
                            'vs LY Full Month (%)': f"{result['vs_full_month_ly_pct']:+.1f}%",
                            'vs Budget (%)': f"{result['vs_budget_pct']:+.1f}%",
                            'vs Same Time LY (%)': f"{result['vs_same_time_ly_pct']:+.1f}%",
                            'Budget (AED)': f"{result['budget_revenue']:,.0f}",
                            'Full Month LY (AED)': f"{result['full_month_ly_revenue']:,.0f}"
                        })
                    
                    st.dataframe(pd.DataFrame(display_data), use_container_width=True)
                    
                    # Revenue comparison chart
                    st.subheader("üí∞ Revenue Comparison")
                    
                    segments = [r['segment'] for r in analysis_results]
                    revenue_comparison = pd.DataFrame({
                        'Segment': segments,
                        'Current BOB': [r['current_bob_revenue'] for r in analysis_results],
                        'Budget': [r['budget_revenue'] for r in analysis_results],
                        'Full Month LY': [r['full_month_ly_revenue'] for r in analysis_results]
                    })
                    
                    fig_revenue = go.Figure()
                    
                    fig_revenue.add_trace(go.Bar(
                        name='Current Business on Books',
                        x=revenue_comparison['Segment'],
                        y=revenue_comparison['Current BOB'],
                        marker_color='blue'
                    ))
                    
                    fig_revenue.add_trace(go.Bar(
                        name='Budget',
                        x=revenue_comparison['Segment'],
                        y=revenue_comparison['Budget'],
                        marker_color='green'
                    ))
                    
                    fig_revenue.add_trace(go.Bar(
                        name='Full Month Last Year',
                        x=revenue_comparison['Segment'],
                        y=revenue_comparison['Full Month LY'],
                        marker_color='orange'
                    ))
                    
                    fig_revenue.update_layout(
                        title="Revenue Comparison by Segment",
                        xaxis_title="Segments",
                        yaxis_title="Revenue (AED)",
                        barmode='group',
                        height=500,
                        xaxis_tickangle=45
                    )
                    
                    st.plotly_chart(fig_revenue, use_container_width=True)
    else:
        st.warning("‚ö†Ô∏è Advanced forecasting module not available")
        st.info("Install the advanced forecasting module to access insights analysis features.")

def controls_logs_tab():
    """Controls and Logs Tab"""
    st.header("‚öôÔ∏è Controls & Logs")
    
    # Re-run section
    st.subheader("üîÑ Re-run Loading")
    if st.button("Re-run Data Loading", type="secondary"):
        st.session_state.data_loaded = False
        st.session_state.segment_data = None
        st.session_state.occupancy_data = None
        st.session_state.last_run_timestamp = None
        st.success("Cache cleared. Please go to Dashboard tab to reload data.")
    
    # Database statistics
    st.subheader("üìä Database Statistics")
    
    if database_available:
        try:
            db_stats = get_database().get_database_stats()
            
            col1, col2 = st.columns(2)
            with col1:
                st.metric("Segment Records", db_stats.get('segment_analysis_rows', 0))
                st.metric("Occupancy Records", db_stats.get('occupancy_analysis_rows', 0))
            
            with col2:
                if db_stats.get('segment_last_updated'):
                    st.info(f"Segment Updated: {db_stats['segment_last_updated']}")
                if db_stats.get('occupancy_last_updated'):
                    st.info(f"Occupancy Updated: {db_stats['occupancy_last_updated']}")
        except Exception as e:
            st.error(f"Database connection error: {str(e)}")
    else:
        st.warning("Database module not available")
    
    # Log viewers
    st.subheader("üìù Recent Logs")
    
    if loggers_available:
        tab1, tab2 = st.tabs(["Conversion Log", "App Log"])
        
        with tab1:
            st.text("Last 100 lines from conversion.log:")
            try:
                conversion_log = get_log_content('conversion', 100)
                st.code(conversion_log, language="text")
            except Exception as e:
                st.error(f"Error reading conversion log: {str(e)}")
        
        with tab2:
            st.text("Last 100 lines from app.log:")
            try:
                app_log = get_log_content('app', 100)
                st.code(app_log, language="text")
            except Exception as e:
                st.error(f"Error reading app log: {str(e)}")
    else:
        st.warning("Logging module not available")
    
    # System status
    st.subheader("üìä System Status")
    col1, col2, col3 = st.columns(3)
    
    with col1:
        if st.session_state.data_loaded:
            st.success("‚úÖ Data Loaded")
        else:
            st.error("‚ùå No Data")
    
    with col2:
        if st.session_state.last_run_timestamp:
            st.info(f"üïí Last Run: {st.session_state.last_run_timestamp.strftime('%Y-%m-%d %H:%M')}")
        else:
            st.info("üïí Never Run")
    
    with col3:
        try:
            if database_available:
                db_stats = get_database().get_database_stats()
                if db_stats:
                    st.info(f"üìä DB: {db_stats.get('segment_analysis_rows', 0)} seg, {db_stats.get('occupancy_analysis_rows', 0)} occ")
            else:
                st.info("üìä DB: Module not available")
        except:
            st.info("üìä DB: Not available")

def gpt_tab():
    """GPT AI Assistant Tab for Natural Language SQL Queries"""
    
    st.title("ü§ñ GPT AI Assistant")
    st.markdown("Ask questions about your revenue data in natural language and get SQL-powered answers.")
    
    # Check if Gemini is available
    if not GEMINI_AVAILABLE:
        st.error("‚ö†Ô∏è Gemini AI backend is not available. Please install google-generativeai package.")
        st.code("pip install google-generativeai", language="bash")
        return
    
    # API Key configuration
    api_key = "AIzaSyBqgrOIUjZTEJxd7o1JUxVzMoknYrzQs08"  # Your provided API key
    
    # Initialize session state for chat history
    if 'gpt_messages' not in st.session_state:
        st.session_state.gpt_messages = []
    
    if 'gemini_backend' not in st.session_state:
        try:
            st.session_state.gemini_backend = create_gemini_backend(api_key)
            if not st.session_state.gemini_backend.connected:
                st.error(f"Failed to connect to Gemini AI: {st.session_state.gemini_backend.error_message}")
                return
        except Exception as e:
            st.error(f"Error initializing Gemini backend: {str(e)}")
            return
    
    # Create two columns for layout
    col1, col2 = st.columns([2, 1])
    
    with col1:
        st.subheader("üí¨ Ask Your Question")
        
        # Question input
        question = st.text_area(
            "Type your question about arrivals, revenue, occupancy, or any other data:",
            height=100,
            placeholder="Example: What was the total revenue for the last 30 days?\nExample: Show me the top 5 segments by occupancy this month\nExample: What is the average ADR for weekends vs weekdays?"
        )
        
        # Ask button
        col_btn1, col_btn2, col_btn3 = st.columns([1, 1, 4])
        
        with col_btn1:
            ask_button = st.button("üöÄ Ask", type="primary", use_container_width=True)
        
        with col_btn2:
            clear_button = st.button("üóëÔ∏è Clear", use_container_width=True)
    
    with col2:
        st.subheader("‚ÑπÔ∏è Tips")
        st.markdown("""
        **Example Questions:**
        - "What was the total revenue last month?"
        - "Show top 5 segments by occupancy"
        - "Average ADR for weekends"
        - "Revenue trends over last 6 months"
        - "Occupancy rate by room type"
        """)
    
    # Clear chat history
    if clear_button:
        st.session_state.gpt_messages = []
        st.rerun()
    
    # Process question
    if ask_button:
        if not question or question.strip() == "":
            st.warning("‚ö†Ô∏è Please enter a question before clicking Ask.")
        else:
            # Add user message to chat
            st.session_state.gpt_messages.append({
                "role": "user",
                "content": question,
                "timestamp": datetime.now()
            })
            
            # Show loading spinner
            with st.spinner("ü§ñ AI is thinking and generating SQL query..."):
                try:
                    # Process the question
                    result = st.session_state.gemini_backend.process_question(question)
                    
                    # Add AI response to chat
                    st.session_state.gpt_messages.append({
                        "role": "assistant",
                        "content": result,
                        "timestamp": datetime.now()
                    })
                    
                except Exception as e:
                    error_msg = f"Error processing question: {str(e)}"
                    st.session_state.gpt_messages.append({
                        "role": "assistant",
                        "content": {"success": False, "error_message": error_msg},
                        "timestamp": datetime.now()
                    })
            
            st.rerun()
    
    # Display chat history
    if st.session_state.gpt_messages:
        st.markdown("---")
        st.subheader("üí¨ Conversation History")
        
        # Reverse the messages to show newest first
        for i, message in enumerate(reversed(st.session_state.gpt_messages)):
            with st.container():
                if message["role"] == "user":
                    st.markdown(f"**üë§ You asked:** {message['content']}")
                    st.caption(f"‚è∞ {message['timestamp'].strftime('%H:%M:%S')}")
                
                else:  # assistant
                    result = message["content"]
                    
                    if result.get("success", False):
                        st.markdown("**ü§ñ AI Response:**")
                        
                        # Show SQL query
                        st.markdown("**üìù Generated SQL Query:**")
                        st.code(result["sql_query"], language="sql")
                        
                        # Show results
                        if len(result["results"]) > 0:
                            st.markdown(f"**üìä Results ({result['row_count']} rows):**")
                            
                            # Display as dataframe with better formatting
                            st.dataframe(
                                result["results"],
                                use_container_width=True,
                                height=min(400, (len(result["results"]) + 1) * 35)
                            )
                            
                            # Show summary if many rows
                            if result["row_count"] > 10:
                                st.info(f"üìà Showing all {result['row_count']} rows")
                        else:
                            st.info("üì≠ Query executed successfully but returned no results.")
                    
                    else:
                        st.error(f"‚ùå **Error:** {result.get('error_message', 'Unknown error')}")
                    
                    st.caption(f"‚è∞ {message['timestamp'].strftime('%H:%M:%S')}")
                
                st.markdown("---")
    
    else:
        # Show welcome message when no chat history
        st.markdown("---")
        st.info("üëã Welcome! Ask any question about your revenue data above to get started.")


def enhanced_gpt_tab():
    """Enhanced GPT AI Assistant Tab with Conversational Intelligence"""
    
    st.title("üöÄ Enhanced AI Revenue Assistant")
    st.markdown("**Next-generation conversational AI with advanced analytics, insights, and visual storytelling**")
    
    # Check if Enhanced Gemini is available
    if not ENHANCED_GEMINI_AVAILABLE:
        st.error("‚ö†Ô∏è Enhanced Gemini AI backend is not available. Using fallback to basic GPT tab.")
        st.info("üì¶ To enable enhanced features, ensure all dependencies are installed.")
        gpt_tab()  # Fallback to basic version
        return
    
    # API Key configuration
    api_key = "AIzaSyBqgrOIUjZTEJxd7o1JUxVzMoknYrzQs08"  # Your provided API key
    
    # Initialize enhanced backend in session state
    if 'enhanced_gemini_backend' not in st.session_state:
        try:
            st.session_state.enhanced_gemini_backend = create_enhanced_gemini_backend(api_key)
            if not st.session_state.enhanced_gemini_backend.connected:
                st.error(f"Failed to connect to Enhanced Gemini AI: {st.session_state.enhanced_gemini_backend.error_message}")
                return
        except Exception as e:
            st.error(f"Error initializing Enhanced Gemini backend: {str(e)}")
            return
    
    # Render the enhanced interface
    try:
        render_enhanced_gpt_tab(st.session_state.enhanced_gemini_backend)
    except Exception as e:
        st.error(f"Error rendering enhanced interface: {str(e)}")
        st.info("Falling back to basic GPT interface...")
        gpt_tab()


def main():
    """Main application with simple sidebar"""
    
    # Get logo (80px as requested)
    logo_img = '<div style="width:80px;height:80px;background:#fff;border-radius:3px;display:flex;align-items:center;justify-content:center;font-size:32px;">üè®</div>'
    try:
        logo_path = os.path.join(os.path.dirname(os.path.dirname(__file__)), 'Pictures', 'xkrIXuKn_400x400.jpg')
        if not os.path.exists(logo_path):
            logo_path = 'Pictures/xkrIXuKn_400x400.jpg'
        if os.path.exists(logo_path):
            with open(logo_path, 'rb') as f:
                logo_data = base64.b64encode(f.read()).decode()
                logo_img = f'<img src="data:image/jpeg;base64,{logo_data}" alt="Logo" style="width:80px;height:80px;border-radius:3px;object-fit:cover;">'
    except:
        pass
    
    # SIDEBAR - Default Streamlit sidebar
    with st.sidebar:
        # Logo and title
        st.markdown(f"""
        <div style="display: flex; flex-direction: column; align-items: center; gap: 15px; margin: 20px 0;">
            {logo_img}
            <div style="font-size: 18px; font-weight: 600; font-style: italic; color: #333; text-align: center; line-height: 1.2;">
                Grand Millennium<br>Revenue Analytics
            </div>
        </div>
        """, unsafe_allow_html=True)
        
        # Display pickup report date if available
        if st.session_state.pickup_report_date:
            st.markdown(f"""
            <div style="background-color: #1f4e79; color: white; padding: 10px; text-align: center; border-radius: 5px; margin: 10px 0;">
                <strong>üí∞ MHR Pick Up Report 2025 üí∞</strong><br>
                <small>Report Date: {st.session_state.pickup_report_date}</small>
            </div>
            """, unsafe_allow_html=True)
        
        st.markdown("---")
        
        # Navigation with italic styling
        st.markdown("### üìä *Navigation*")
        
        # Add CSS for italic radio button options
        st.markdown("""
        <style>
        .stRadio label {
            font-style: italic !important;
        }
        .stRadio label span {
            font-style: italic !important;
        }
        div[data-testid="stRadio"] label {
            font-style: italic !important;
        }
        div[data-testid="stRadio"] label span {
            font-style: italic !important;
        }
        </style>
        """, unsafe_allow_html=True)
        
        navigation_options = [
            "Dashboard",
            "Daily Occupancy", 
            "Segment Analysis",
            "ADR Analysis",
            "STR Report",
            "Block Analysis",
            "Events Analysis",
            "Entered On & Arrivals",
            "Historical & Forecast",
            "Enhanced Forecasting",
            "Machine Learning",
            "GPT",
            "Insights Analysis",
            "Controls & Logs"
        ]
        
        current_tab = st.session_state.current_tab
        
        # Radio buttons for navigation (now italic)
        selected_tab = st.radio(
            "*Choose a section:*",
            navigation_options,
            index=navigation_options.index(current_tab) if current_tab in navigation_options else 0
        )
        
        # Update session state
        if selected_tab != current_tab:
            st.session_state.current_tab = selected_tab
            st.rerun()
        
        st.markdown("---")
        
        # Status
        if st.session_state.data_loaded:
            st.success("‚úÖ Data Loaded")
        else:
            st.warning("‚ö†Ô∏è No Data")
    
    # Main content
    st.markdown(f"""
    <div style="text-align: center; margin: 20px 0;">
        <div style="display: flex; align-items: center; justify-content: center; gap: 15px; margin-bottom: 10px;">
            {logo_img}
            <h1 style="color: #333; font-style: italic; margin: 0;">Grand Millennium Revenue Analytics</h1>
        </div>
        <p style="color: #666; font-size: 16px;">Current Section: <strong>{st.session_state.current_tab}</strong></p>
    </div>
    """, unsafe_allow_html=True)
    
    # Display pickup report header at the top of main content
    display_pickup_report_header()
    
    # Add hotel exterior image after title
    try:
        hotel_image_path = project_root / "Pictures" / "Grand Millennium Dubai Hotel Exterior 2.jpg"
        if hotel_image_path.exists():
            st.image(str(hotel_image_path), caption="Grand Millennium Dubai", use_container_width=True)
    except:
        pass
    
    # Route to tabs
    current_tab = st.session_state.current_tab
    
    if current_tab == "Dashboard":
        dashboard_tab()
    elif current_tab == "Daily Occupancy":
        daily_occupancy_tab()
    elif current_tab == "Segment Analysis":
        segment_analysis_tab()
    elif current_tab == "ADR Analysis":
        adr_analysis_tab()
    elif current_tab == "STR Report":
        str_report_tab()
    elif current_tab == "Block Analysis":
        block_analysis_tab()
    elif current_tab == "Events Analysis":
        events_analysis_tab()
    elif current_tab == "Entered On & Arrivals":
        entered_on_arrivals_tab()
    elif current_tab == "Historical & Forecast":
        historical_forecast_tab()
    elif current_tab == "Enhanced Forecasting":
        enhanced_forecasting_tab()
    elif current_tab == "Machine Learning":
        machine_learning_tab()
    elif current_tab == "GPT":
        enhanced_gpt_tab()
    elif current_tab == "Insights Analysis":
        insights_analysis_tab()
    elif current_tab == "Controls & Logs":
        controls_logs_tab()

if __name__ == "__main__":
    main()